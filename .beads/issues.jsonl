{"id":"bd-11k","title":"Implement provider streaming tests using VCR cassettes","description":"# Implement provider streaming tests using VCR cassettes\n\n## Goal\nWrite comprehensive provider streaming tests using recorded VCR cassettes (no live network).\n\n## Runtime + Determinism\n- Do not introduce new tokio-only tests.\n- Prefer `#[asupersync::test]` or an explicit `Runtime::new().block_on(...)` wrapper to match the active runtime.\n- Force `VCR_MODE=playback` + `VCR_CASSETTE_DIR` for all tests.\n- Set `PI_CONFIG_PATH` and `PI_SESSIONS_DIR` to temp dirs; assert zero live HTTP calls.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) to log cassette name/path, request summary, event timeline, and diffs.\n- On failure, dump expected vs actual event sequences + stop reasons.\n\n## Test File Structure\n```rust\n// tests/provider_streaming.rs\n\nmod vcr;\nuse vcr::VcrRecorder;\n\nmod anthropic {\n    use super::*;\n\n    #[asupersync::test]\n    async fn test_simple_text_response() {\n        let vcr = VcrRecorder::new(\"anthropic_simple_text\");\n        let provider = AnthropicProvider::new_with_client(vcr.client());\n\n        let stream = provider.stream(&context, &options).await.unwrap();\n        let events: Vec<_> = stream.collect().await;\n\n        assert!(matches!(events[0], StreamEvent::Start { .. }));\n        assert!(matches!(events[1], StreamEvent::TextStart { .. }));\n        // ... verify all events\n        let final_msg = events.last().unwrap();\n        assert_eq!(final_msg.stop_reason, StopReason::Stop);\n    }\n}\n```\n\n## Test Categories\n\n### Streaming Event Sequence Tests\nVerify correct event ordering:\n- Start → TextStart → TextDelta* → TextEnd → Done\n- Start → ThinkingStart → ThinkingDelta* → ThinkingEnd → TextStart → ... → Done\n- Start → ToolCallStart → ToolCallDelta* → ToolCallEnd → Done(ToolUse)\n\n### Content Parsing Tests\nVerify content is parsed correctly:\n- Text content extraction\n- Thinking content extraction\n- Tool call argument parsing (JSON)\n- Multiple content blocks\n\n### Usage Tracking Tests\nVerify token counting:\n- Input tokens\n- Output tokens\n- Cache read/write tokens\n- Cost calculation\n\n### Error Handling Tests\nVerify errors are surfaced correctly:\n- Rate limit with retry-after\n- Auth failure message\n- Bad request details\n- Server error handling\n\n## Providers to Test\n1. Anthropic (primary focus, most complex)\n2. OpenAI (after Anthropic pattern established)\n3. Gemini (different response format)\n4. Azure (similar to OpenAI)\n\n## Dependencies\n- bd-1pf (VCR infrastructure)\n- bd-30u (Anthropic cassettes recorded)\n\n## Files\n- tests/provider_streaming.rs\n- tests/provider_streaming/anthropic.rs\n- tests/provider_streaming/openai.rs\n- tests/provider_streaming/gemini.rs\n- tests/provider_streaming/azure.rs\n\n## Acceptance Criteria\n- [ ] 20+ Anthropic streaming tests\n- [ ] 10+ OpenAI streaming tests\n- [ ] 10+ Gemini streaming tests\n- [ ] 5+ Azure streaming tests\n- [ ] All tests use VCR (no live API)\n- [ ] Event sequences validated\n- [ ] Usage tracking validated\n- [ ] Error handling validated\n- [ ] Logs include cassette path + event timeline\n- [ ] All tests pass in CI","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-03T03:35:00.703077638Z","created_by":"ubuntu","updated_at":"2026-02-03T05:45:59.274654140Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-11k","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T05:45:59.274627610Z","created_by":"ubuntu"},{"issue_id":"bd-11k","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:35:00.714515712Z","created_by":"ubuntu"},{"issue_id":"bd-11k","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T03:35:07.786057110Z","created_by":"ubuntu"},{"issue_id":"bd-11k","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T03:41:01.974079399Z","created_by":"ubuntu"}]}
{"id":"bd-147","title":"Write extension compatibility summary (goals, gaps, next steps)","description":"Background:\n- We need a concise narrative of goals, choices, and known limitations.\n\nSteps:\n- Summarize the rationale for the sample and harness design.\n- List known gaps or incompatible extensions with reasons.\n- Provide a roadmap for closing remaining gaps.\n\nAcceptance:\n- Summary can serve as a handoff for future work.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:26:41.669156765Z","created_by":"ubuntu","updated_at":"2026-02-03T02:41:00.220492671Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-147","depends_on_id":"bd-16v","type":"blocks","created_at":"2026-02-03T02:40:48.427500212Z","created_by":"ubuntu"},{"issue_id":"bd-147","depends_on_id":"bd-1we","type":"blocks","created_at":"2026-02-03T02:40:40.289423449Z","created_by":"ubuntu"},{"issue_id":"bd-147","depends_on_id":"bd-20p","type":"blocks","created_at":"2026-02-03T02:41:00.220467093Z","created_by":"ubuntu"}]}
{"id":"bd-155","title":"Workstream: extension compatibility documentation + evidence binder complete","description":"Purpose:\n- Produce self-contained documentation that maps each sampled extension to evidence of compatibility.\n\nOutputs (artifacts):\n- Updated docs (EXTENSIONS.md + FEATURE_PARITY.md).\n- Extension Conformance Report (per-extension status table).\n- How-to for adding new extensions to the sample + rerunning harness.\n\nDefinition of done:\n- A reader can understand coverage, gaps, and how to reproduce results without consulting the original plan.\n- Docs include links to fixtures and harness commands.\n\nDependencies:\n- Requires sample list, conformance harness results, and benchmarks.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-02-03T02:20:37.035050225Z","created_by":"ubuntu","updated_at":"2026-02-03T02:42:17.142321706Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-155","depends_on_id":"bd-147","type":"blocks","created_at":"2026-02-03T02:32:27.645123408Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-16v","type":"blocks","created_at":"2026-02-03T02:32:09.053103919Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-1rm","type":"blocks","created_at":"2026-02-03T02:32:19.654479128Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-1we","type":"blocks","created_at":"2026-02-03T02:32:00.904715251Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-20p","type":"blocks","created_at":"2026-02-03T02:42:07.022468412Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-269","type":"blocks","created_at":"2026-02-03T02:41:56.895852495Z","created_by":"ubuntu"},{"issue_id":"bd-155","depends_on_id":"bd-29c","type":"blocks","created_at":"2026-02-03T02:42:17.142294004Z","created_by":"ubuntu"}]}
{"id":"bd-15n","title":"Update --continue flag to use SQLite index","description":"# Update --continue flag to use SQLite index\n\n## Goal\nUse SQLite index for fast lookup of most recent session when --continue is used.\n\n## Current Implementation (src/main.rs)\nCurrently scans filesystem for most recent:\n```rust\nif args.continue_session {\n    let session_dir = sessions_dir_for_cwd(&cwd);\n    // Scans all files, sorts by mtime\n    let most_recent = fs::read_dir(&session_dir)?\n        .filter_map(|e| e.ok())\n        .max_by_key(|e| e.metadata().ok()?.modified().ok()?);\n    // ...\n}\n```\n\n## New Implementation\n```rust\nif args.continue_session {\n    let index = SessionIndex::open_default()?;\n    let cwd = std::env::current_dir()?.to_string_lossy().to_string();\n    \n    if let Some(meta) = index.find_recent(&cwd)? {\n        return load_session(&meta.path);\n    }\n    \n    // Fallback to filesystem\n    // ...\n}\n```\n\n## Benefits\n- O(1) lookup instead of O(n) filesystem scan\n- Works across hundreds of sessions instantly\n- Consistent with session picker behavior\n\n## Dependencies\n- bd-3nz (indexing must work first)\n\n## Testing\n- Test: --continue uses index\n- Test: --continue falls back to filesystem\n- Test: Performance improved\n\n## Acceptance Criteria\n- [ ] --continue queries index\n- [ ] Fallback works if index empty\n- [ ] Faster for users with many sessions","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T03:38:59.405457245Z","created_by":"ubuntu","updated_at":"2026-02-03T03:39:16.041645531Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-15n","depends_on_id":"bd-346","type":"parent-child","created_at":"2026-02-03T03:38:59.414630188Z","created_by":"ubuntu"},{"issue_id":"bd-15n","depends_on_id":"bd-3nz","type":"blocks","created_at":"2026-02-03T03:39:16.041620034Z","created_by":"ubuntu"}]}
{"id":"bd-16n","title":"Produce golden fixtures per extension (legacy outputs)","description":"Background:\n- Fixtures are the authoritative reference for conformance testing.\n\nSteps:\n- Run the capture pipeline for each extension scenario.\n- Store normalized outputs as JSON fixtures in a dedicated directory (e.g., tests/conformance/fixtures/extensions).\n- Include provenance metadata (extension version, capture date, legacy commit).\n\nAcceptance:\n- Every sampled extension has a fixture set covering its declared features.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:54.862626673Z","created_by":"ubuntu","updated_at":"2026-02-03T02:35:24.605609771Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-16n","depends_on_id":"bd-1oz","type":"blocks","created_at":"2026-02-03T02:35:24.605588441Z","created_by":"ubuntu"}]}
{"id":"bd-16v","title":"Create Extension Conformance Report (evidence binder)","description":"Background:\n- We need a single place that maps extension -> evidence.\n\nSteps:\n- Generate a table of extensions with version, runtime tier, features tested, and pass/fail.\n- Link to fixture files and harness output logs.\n- Include summary stats (coverage %, failures, gaps).\n\nAcceptance:\n- Report is self-contained and can be regenerated.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:26:16.784315729Z","created_by":"ubuntu","updated_at":"2026-02-03T02:40:15.941384598Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-16v","depends_on_id":"bd-16n","type":"blocks","created_at":"2026-02-03T02:40:15.941355243Z","created_by":"ubuntu"},{"issue_id":"bd-16v","depends_on_id":"bd-31j","type":"blocks","created_at":"2026-02-03T02:40:03.153512049Z","created_by":"ubuntu"}]}
{"id":"bd-17o","title":"RPC tests: replace MockProvider with VCR playback","description":"Goal:\n- Remove MockProvider usage in tests/rpc_mode.rs and use VCR playback (real recorded streams) to validate RPC streaming behavior without mocks.\n\nScope:\n- Replace MockProvider with a VCR-backed provider or adapter that replays recorded SSE chunks.\n- Add cassette naming conventions for RPC scenarios (e.g., rpc_basic.json, rpc_toolcall.json).\n- Validate real event sequences, stop reasons, and error propagation.\n- Force VCR playback mode in tests (no network) and assert zero live HTTP calls.\n- Emit detailed logs on each test: cassette path, expected events, actual events, and diffs.\n\nLogging Requirements:\n- Use TestLogger (bd-3ml) for per-test logs and auto-dump on failure.\n- Log cassette path, parsed event timeline, and mismatch details (first divergent event + context).\n\nAcceptance Criteria:\n- tests/rpc_mode.rs contains no MockProvider/fake stream.\n- All RPC tests run in playback mode with recorded cassettes.\n- Logs include cassette name/path, parsed event timeline, and assertion diffs on failure.\n- CI runs without network and still validates streaming edge cases.\n\nDependencies:\n- Requires VCR infrastructure (bd-1pf).\n- Requires recorded cassette(s) (bd-30u or RPC-specific capture).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:22.325926811Z","created_by":"ubuntu","updated_at":"2026-02-03T05:43:14.356614967Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-17o","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T04:59:49.570826261Z","created_by":"ubuntu"},{"issue_id":"bd-17o","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:22.335029235Z","created_by":"ubuntu"},{"issue_id":"bd-17o","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T04:59:55.584505356Z","created_by":"ubuntu"},{"issue_id":"bd-17o","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:43:14.356590291Z","created_by":"ubuntu"}]}
{"id":"bd-1d3","title":"Implement TUI snapshot testing infrastructure","description":"# Implement TUI snapshot testing infrastructure\n\n## Goal\nCreate infrastructure for testing the interactive TUI by capturing terminal output\nand comparing against golden snapshots, with detailed logging.\n\n## Background\nsrc/interactive.rs is 2842 lines with only 2 trivial tests (<0.1% coverage).\nThis is the most user-visible code and needs comprehensive testing.\n\n## Approach: Snapshot Testing\n\n### Why Snapshots?\n- TUI output is complex (ANSI codes, layout)\n- Pixel-perfect testing impractical\n- Snapshots capture \"expected output\" simply\n- Easy to update when intentional changes made\n\n### Snapshot Format\n```\n// tests/snapshots/tui_initial_state.snap\n┌─────────────────────────────────────┐\n│ Pi - AI Coding Agent                │\n├─────────────────────────────────────┤\n│                                     │\n│ > [cursor]                          │\n│                                     │\n├─────────────────────────────────────┤\n│ Model: claude-sonnet-4   Tokens: 0  │\n└─────────────────────────────────────┘\n```\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) for each snapshot test.\n- Log view size, theme name, state flags, and snapshot name.\n- On mismatch, dump the rendered view (ANSI-stripped) + diff context.\n\n## Determinism Requirements\n- Force terminal size (80x24) and disable time-based animations/spinners in test mode.\n- Strip ANSI codes for snapshots.\n- Use a fixed default theme and locale.\n\n## Implementation\n\n### Snapshot Library\nUse insta crate for Rust snapshot testing:\n```toml\n[dev-dependencies]\ninsta = { version = \"1\", features = [\"filters\"] }\n```\n\n### Test Structure\n```rust\n// tests/tui_snapshot.rs\n\nuse insta::assert_snapshot;\nuse pi::interactive::PiApp;\n\n#[test]\nfn test_initial_state() {\n    let app = PiApp::new(Config::default());\n    let view = app.view();\n    assert_snapshot!(\"initial_state\", strip_ansi(&view));\n}\n```\n\n### ANSI Code Handling\nStrip ANSI codes for deterministic snapshots:\n```rust\nfn strip_ansi(s: &str) -> String {\n    let re = regex::Regex::new(r\"\\x1b\\[[0-9;]*[a-zA-Z]\").unwrap();\n    re.replace_all(s, \"\").to_string()\n}\n```\n\n### Width/Height Normalization\nForce consistent terminal size:\n```rust\nfn normalized_view(app: &PiApp) -> String {\n    app.view_with_size(80, 24)\n}\n```\n\n## Test Scenarios\n\n### Layout Tests\n1. Initial empty state\n2. Single user message\n3. Single assistant message\n4. Conversation with multiple messages\n5. Long message with wrapping\n6. Scrolled viewport\n\n### State Tests\n7. Idle state\n8. Streaming text\n9. Streaming thinking\n10. Tool execution in progress\n11. Error display\n12. Slash command help\n\n### Input Tests\n13. Text in input field\n14. Multi-line input\n15. History navigation\n16. Cursor positioning\n\n## Dependencies\nNone (can start independently)\n\n## Files\n- tests/tui_snapshot.rs\n- tests/snapshots/*.snap (generated)\n\n## Acceptance Criteria\n- [ ] insta crate integrated\n- [ ] ANSI stripping works\n- [ ] Terminal size normalized\n- [ ] 15+ snapshot tests\n- [ ] Logs include snapshot metadata\n- [ ] cargo insta test works\n- [ ] CI validates snapshots","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T03:35:28.554490342Z","created_by":"ubuntu","updated_at":"2026-02-03T08:42:46.796475700Z","closed_at":"2026-02-03T08:42:46.796412182Z","close_reason":"Added tui_snapshot tests + insta snapshots; suite green","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1d3","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:35:28.561095760Z","created_by":"ubuntu"},{"issue_id":"bd-1d3","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:44:35.286107381Z","created_by":"ubuntu"}],"comments":[{"id":17,"issue_id":"bd-1d3","author":"Dicklesworthstone","text":"Progress: added TUI snapshot test harness (tests/tui_snapshot.rs) using TestHarness + insta; added PiApp::set_terminal_size and PI_TEST_MODE init gating for animations; added dev-dep insta. Snapshots pending because cargo check/clippy failing due to removed reqwest/tokio deps still referenced in code; rustfmt still fails on import ordering in src/interactive.rs and provider tests.","created_at":"2026-02-03T06:19:49Z"}]}
{"id":"bd-1e0","title":"Implement extension discovery + install resolution","description":"Background:\n- pi CLI must discover extensions from packages and CLI flags; this is core UX.\n\nSteps:\n- Extend ResourceLoader/PackageManager to resolve extension assets and manifests.\n- Respect CLI flags (--extension/--no-extensions) and precedence rules (project > global).\n- Produce structured diagnostics for missing/invalid/conflicting extensions.\n- Ensure resolution is deterministic and cache-safe for repeatable tests.\n\nLogging requirements:\n- Diagnostics include source, resolution path, and reason codes.\n\nAcceptance:\n- Extensions can be installed, discovered, and enumerated from settings + CLI.\n- Diagnostics are actionable and stable for unit/E2E assertions.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:23:58.695313308Z","created_by":"ubuntu","updated_at":"2026-02-03T04:40:20.054066029Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1e0","depends_on_id":"bd-gqf","type":"blocks","created_at":"2026-02-03T02:36:14.915782038Z","created_by":"ubuntu"}]}
{"id":"bd-1f5","title":"Extensions: QuickJS runtime + Pi event loop (no Node/Bun)","description":"Background:\n- JS compatibility requires deterministic event loop semantics without Node/Bun.\n\nSteps:\n- Embed QuickJS via safe Rust bindings and expose a minimal Pi event loop.\n- Implement microtask + promise ordering and timer scheduling.\n- Map legacy APIs to connector hostcalls; propagate policy errors correctly.\n- Emit structured logs for JS task scheduling and hostcall results.\n\nAcceptance:\n- A representative JS extension runs as-is with deterministic ordering.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:24:24.611922334Z","created_by":"ubuntu","updated_at":"2026-02-03T02:56:52.824405372Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1f5","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:24:58.543354683Z","created_by":"ubuntu"}]}
{"id":"bd-1fg","title":"Implement extension benchmarks (load, tool call, event hook)","description":"Background:\n- Need measurable evidence for runtime overhead.\n\nSteps:\n- Add benchmarks for extension load/init, tool call roundtrip, event hook emission.\n- Ensure benchmarks can run with a representative extension artifact.\n- Record results in BENCHMARKS.md.\n\nAcceptance:\n- `cargo bench` runs extension benchmarks and outputs stable numbers.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:47.669514632Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:20.344701180Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1fg","depends_on_id":"bd-1ii","type":"blocks","created_at":"2026-02-03T02:39:01.542791111Z","created_by":"ubuntu"},{"issue_id":"bd-1fg","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:39:10.545872664Z","created_by":"ubuntu"},{"issue_id":"bd-1fg","depends_on_id":"bd-7cs","type":"blocks","created_at":"2026-02-03T02:58:20.344676604Z","created_by":"ubuntu"}]}
{"id":"bd-1ge","title":"Session tree navigation + branching (CLI/TUI)","description":"Implement tree navigation/branching in session layer and expose in CLI/TUI; add conformance fixtures.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:18:44.440378612Z","created_by":"ubuntu","updated_at":"2026-02-03T02:18:44.440378612Z","compaction_level":0,"original_size":0}
{"id":"bd-1ii","title":"Define performance budgets for extension runtime","description":"Background:\n- We need explicit targets for extension overhead (startup, tool call latency).\n\nSteps:\n- Choose budgets based on existing BENCHMARKS.md style (p95/p99).\n- Consider both cold-start and warmed caches.\n- Document measurement methodology and hardware class.\n\nAcceptance:\n- Budgets are explicit and agreed, with rationale.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:38.338785747Z","created_by":"ubuntu","updated_at":"2026-02-03T02:25:38.338785747Z","compaction_level":0,"original_size":0}
{"id":"bd-1iy","title":"Migrate Gemini provider to asupersync HTTP","description":"# Migrate Gemini provider to asupersync HTTP\n\n## Goal\nReplace reqwest usage in src/providers/gemini.rs with asupersync HTTP client.\n\n## Background\nGemini provider (Google Generative AI):\n- generateContent endpoint with streaming\n- Function declarations (tools)\n- 631 lines, 4 unit tests\n\n## Gemini-Specific Considerations\n1. **Streaming URL**: Uses ?alt=sse query parameter\n2. **Response Format**: Different JSON structure from Anthropic/OpenAI\n3. **Tool Format**: functionDeclarations in tools array\n4. **Content Parts**: text, functionCall, functionResponse\n\n## Dependencies\n- bd-9sa, bd-pwz, bd-37l (follow Anthropic pattern)\n\n## Acceptance Criteria\n- [ ] No reqwest imports\n- [ ] 4 tests pass\n- [ ] Streaming works","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-03T03:33:08.130271194Z","created_by":"ubuntu","updated_at":"2026-02-03T03:33:41.665851795Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1iy","depends_on_id":"bd-37l","type":"blocks","created_at":"2026-02-03T03:33:41.665829753Z","created_by":"ubuntu"},{"issue_id":"bd-1iy","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:33:08.138703827Z","created_by":"ubuntu"},{"issue_id":"bd-1iy","depends_on_id":"bd-pwz","type":"blocks","created_at":"2026-02-03T03:33:41.413699713Z","created_by":"ubuntu"}]}
{"id":"bd-1mh","title":"Update session picker to use SQLite index","description":"# Update session picker to use SQLite index\n\n## Goal\nReplace filesystem walking in session picker with fast SQLite index queries.\n\n## Current Implementation (src/session_picker.rs)\nCurrently scans filesystem:\n```rust\n// Slow: walks all session directories\nlet sessions = walkdir::WalkDir::new(&sessions_dir)\n    .into_iter()\n    .filter_map(|e| e.ok())\n    .filter(|e| e.path().extension() == Some(\"jsonl\"))\n    .collect();\n```\n\n## New Implementation\n```rust\nuse crate::session_index::SessionIndex;\n\nimpl SessionPicker {\n    pub fn load_sessions(cwd: Option<&str>) -> Result<Vec<SessionMeta>> {\n        let index = SessionIndex::open_default()?;\n        index.list_sessions(cwd)\n    }\n}\n```\n\n## UI Changes\n- Display indexed metadata directly (no file reads needed)\n- Show message count from index\n- Show session name from index\n- Faster render (no filesystem I/O)\n\n## Fallback Behavior\nIf index unavailable or empty:\n```rust\nfn load_sessions_with_fallback(cwd: Option<&str>) -> Result<Vec<SessionMeta>> {\n    // Try index first\n    if let Ok(index) = SessionIndex::open_default() {\n        if let Ok(sessions) = index.list_sessions(cwd) {\n            if !sessions.is_empty() {\n                return Ok(sessions);\n            }\n        }\n    }\n    \n    // Fallback to filesystem (and populate index)\n    let sessions = load_sessions_from_filesystem(cwd)?;\n    // Optionally trigger reindex in background\n    Ok(sessions)\n}\n```\n\n## Dependencies\n- bd-3nz (indexing must work first)\n\n## Testing\n- Test: Session picker shows indexed sessions\n- Test: Picker falls back to filesystem if needed\n- Test: Performance improved (measure time)\n\n## Acceptance Criteria\n- [ ] Picker queries index by default\n- [ ] Fallback to filesystem works\n- [ ] UI displays index metadata\n- [ ] Noticeably faster for 50+ sessions","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T03:38:46.861448590Z","created_by":"ubuntu","updated_at":"2026-02-03T03:38:59.101819926Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1mh","depends_on_id":"bd-346","type":"parent-child","created_at":"2026-02-03T03:38:46.870643664Z","created_by":"ubuntu"},{"issue_id":"bd-1mh","depends_on_id":"bd-3nz","type":"blocks","created_at":"2026-02-03T03:38:59.101795250Z","created_by":"ubuntu"}]}
{"id":"bd-1mq","title":"Unit tests: CLI/main selection + system prompt building","description":"Goal:\n- Add unit tests for core CLI/main.rs logic without mocks (real temp dirs + config fixtures) and with detailed logging.\n\nScope:\n- Model selection + thinking resolution (select_model_and_thinking) across provider/model edge cases.\n- System prompt assembly (build_system_prompt) including project context files and skills prompt.\n- File argument handling (prepare_initial_message) for text + images.\n- API key resolution fallbacks and error paths.\n\nLogging Requirements:\n- Use the shared TestHarness/TestLogger (bd-3ml) in each test.\n- On failure, log inputs, resolved model selection, and prompt fragments.\n\nAcceptance Criteria:\n- Tests cover normal + error paths and do not use fake providers.\n- Uses real filesystem temp dirs for context files.\n- Logs include inputs, derived values, and assertion context.\n- Deterministic, no network access.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:29.180313821Z","created_by":"ubuntu","updated_at":"2026-02-03T08:35:31.868787891Z","closed_at":"2026-02-03T08:35:31.868656316Z","close_reason":"Completed: app module + CLI/system prompt tests","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1mq","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:29.191001780Z","created_by":"ubuntu"},{"issue_id":"bd-1mq","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:27:21.769411005Z","created_by":"ubuntu"}]}
{"id":"bd-1nq","title":"Integrate extension conformance harness into tests + CI","description":"Background:\n- Conformance must be automated and gated.\n\nSteps:\n- Add harness tests to `cargo test` default set.\n- Document how to run just extension conformance.\n- Update CI workflow to include these tests and capture logs as artifacts.\n\nAcceptance:\n- CI fails on extension conformance regressions with clear logs and downloadable artifacts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:14.036977202Z","created_by":"ubuntu","updated_at":"2026-02-03T03:07:33.514191537Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1nq","depends_on_id":"bd-2ce","type":"blocks","created_at":"2026-02-03T02:38:24.016957128Z","created_by":"ubuntu"},{"issue_id":"bd-1nq","depends_on_id":"bd-3s2","type":"blocks","created_at":"2026-02-03T02:38:12.549849588Z","created_by":"ubuntu"},{"issue_id":"bd-1nq","depends_on_id":"bd-7al","type":"blocks","created_at":"2026-02-03T02:38:03.398803451Z","created_by":"ubuntu"}]}
{"id":"bd-1o4","title":"E2E CLI scenarios: tool enable/disable + error paths","description":"Goal:\n- Add E2E tests that validate tool enable/disable behavior and common error paths with detailed logging.\n\nScope:\n- `--tools` selection impacts available tool list in system prompt.\n- `--no-tools` disables all tools and confirms tool-call failures are surfaced.\n- Error paths: invalid model/provider, missing API key, rpc mode restrictions.\n- Validate that error messages are clear and actionable.\n\nLogging Requirements:\n- Use CLI E2E harness (bd-1wc) + TestLogger (bd-3ml).\n- Log effective tool list, system prompt excerpt, VCR_MODE, and cassette name/path.\n- Capture stdout/stderr and assertion diffs on failure.\n\nAcceptance Criteria:\n- Tests capture stdout/stderr and confirm error messages.\n- Logs show tool registry inputs + effective tool list + prompt excerpts + cassette id.\n- No network access; VCR playback used where streaming needed.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:59:09.623038612Z","created_by":"ubuntu","updated_at":"2026-02-03T05:42:58.950250159Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1o4","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T05:00:32.353467259Z","created_by":"ubuntu"},{"issue_id":"bd-1o4","depends_on_id":"bd-1wc","type":"blocks","created_at":"2026-02-03T05:00:27.455303348Z","created_by":"ubuntu"},{"issue_id":"bd-1o4","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:59:09.629601854Z","created_by":"ubuntu"},{"issue_id":"bd-1o4","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T05:42:58.950223199Z","created_by":"ubuntu"},{"issue_id":"bd-1o4","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:01:01.836681493Z","created_by":"ubuntu"}]}
{"id":"bd-1oz","title":"Normalize legacy capture outputs (paths/time/randomness)","description":"Background:\n- Captured outputs will contain non-deterministic elements; normalization must be documented and applied.\n\nSteps:\n- Implement normalization rules (path stripping, timestamp canonicalization, UUID masking).\n- Preserve semantic meaning (do not over-normalize).\n- Record the normalization rules alongside fixtures.\n\nAcceptance:\n- Normalized fixtures are stable across repeated captures.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:46.151025259Z","created_by":"ubuntu","updated_at":"2026-02-03T02:35:16.078333301Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1oz","depends_on_id":"bd-3on","type":"blocks","created_at":"2026-02-03T02:35:16.078309798Z","created_by":"ubuntu"}]}
{"id":"bd-1pf","title":"Set up VCR-style test infrastructure for provider streaming","description":"# Set up VCR-style test infrastructure for provider streaming\n\n## Goal\nCreate infrastructure to record and replay real API responses for provider testing.\n\n## Background\nVCR (Video Cassette Recorder) testing pattern:\n1. First run: Make real API call, record response to file\n2. Subsequent runs: Replay recorded response, no network\n\nThis gives us:\n- Real response format testing (not simplified mocks)\n- Deterministic CI (no flaky network tests)\n- Real error response testing (rate limits, auth failures)\n\n## Implementation\n\n### Recording Mode\n```rust\n// tests/vcr/mod.rs\n\npub struct VcrRecorder {\n    cassette_path: PathBuf,\n    mode: VcrMode,\n}\n\npub enum VcrMode {\n    Record,    // Make real calls, save to cassette\n    Playback,  // Replay from cassette, fail if not found\n    Auto,      // Playback if exists, else record\n}\n\nimpl VcrRecorder {\n    pub fn new(test_name: &str) -> Self { ... }\n\n    pub async fn request(&self, req: Request) -> Response {\n        match self.mode {\n            VcrMode::Record => self.record_and_return(req).await,\n            VcrMode::Playback => self.playback(req),\n            VcrMode::Auto => ...\n        }\n    }\n}\n```\n\n### Cassette Format\n```json\n{\n  \"version\": \"1.0\",\n  \"test_name\": \"anthropic_streaming_text\",\n  \"recorded_at\": \"2026-02-02T...\",\n  \"interactions\": [\n    {\n      \"request\": {\n        \"method\": \"POST\",\n        \"url\": \"https://api.anthropic.com/v1/messages\",\n        \"headers\": { ... },\n        \"body\": { ... }\n      },\n      \"response\": {\n        \"status\": 200,\n        \"headers\": { ... },\n        \"body_chunks\": [\n          \"event: message_start\\ndata: {...}\\n\\n\",\n          \"event: content_block_delta\\ndata: {...}\\n\\n\",\n          ...\n        ]\n      }\n    }\n  ]\n}\n```\n\n### SSE Streaming Support\nFor streaming responses, store individual chunks:\n- Each SSE event as separate chunk\n- Preserve timing information (optional replay delay)\n- Support partial responses (stream interruption)\n\n### Sensitive Data Redaction\n```rust\npub fn redact_cassette(cassette: &mut Cassette) {\n    // Replace API keys with placeholder\n    cassette.redact_header(\"x-api-key\", \"[REDACTED]\");\n    cassette.redact_header(\"authorization\", \"[REDACTED]\");\n\n    // Replace sensitive response data\n    cassette.redact_body_field(\"api_key\", \"[REDACTED]\");\n}\n```\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) to log record/playback actions.\n- Log cassette path, mode, request summary (method/url), and redaction summary.\n- On playback mismatch, log expected vs actual interaction keys + diff hints.\n\n## Files to Create\n- tests/vcr/mod.rs - VCR infrastructure\n- tests/vcr/cassette.rs - Cassette format/loading\n- tests/vcr/recorder.rs - Recording logic\n- tests/vcr/playback.rs - Playback logic\n- tests/fixtures/vcr/ - Directory for cassette files\n\n## Testing the VCR System\n- Unit test: Load cassette from JSON\n- Unit test: Match request to interaction\n- Unit test: Redaction works\n- Integration: Record + playback cycle\n\n## Environment Variables\n- VCR_MODE=record|playback|auto\n- VCR_CASSETTE_DIR=path/to/cassettes\n\n## Acceptance Criteria\n- [ ] VCR infrastructure compiles\n- [ ] Recording mode saves cassettes\n- [ ] Playback mode replays cassettes\n- [ ] SSE streaming supported\n- [ ] Sensitive data redacted\n- [ ] Record/playback actions logged with detail\n- [ ] CI uses playback mode only\n\nDependencies:\n  -> bd-26s (parent-child) - Workstream: Comprehensive Test Coverage (No Mocks)","status":"in_progress","priority":0,"issue_type":"task","created_at":"2026-02-03T03:34:26.454610529Z","created_by":"ubuntu","updated_at":"2026-02-03T06:15:11.707394939Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1pf","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:34:26.464972177Z","created_by":"ubuntu"}]}
{"id":"bd-1rm","title":"Document procedure: add new extension to sample + rerun harness","description":"Background:\n- The sample must evolve over time; procedure must be explicit.\n\nSteps:\n- Document how to add an extension (update manifest, fetch artifact, update scenarios, capture legacy, update fixtures).\n- Include checklists and commands.\n\nAcceptance:\n- A new contributor can add an extension without consulting this plan.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:26:29.737520573Z","created_by":"ubuntu","updated_at":"2026-02-03T02:40:28.346435010Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1rm","depends_on_id":"bd-29c","type":"blocks","created_at":"2026-02-03T02:40:28.346408792Z","created_by":"ubuntu"}]}
{"id":"bd-1tz","title":"Unit tests: connector dispatcher + policy engine","description":"Background:\n- The connector dispatcher is the security boundary; policy enforcement must be correct.\n\nSteps:\n- Unit tests for hostcall routing (read/write/exec/http/env).\n- Policy mode tests (strict/prompt/permissive) with allow/deny outcomes.\n- Audit log tests (ensure allow/deny entries contain correlation IDs and reason).\n\nLogging requirements:\n- Tests must assert log content and redaction of secrets.\n\nAcceptance:\n- All policy branches covered; logs are deterministic and audited.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:46:07.082267731Z","created_by":"ubuntu","updated_at":"2026-02-03T02:48:42.185631176Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1tz","depends_on_id":"bd-34f","type":"blocks","created_at":"2026-02-03T02:48:42.185604516Z","created_by":"ubuntu"},{"issue_id":"bd-1tz","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:48:30.049727476Z","created_by":"ubuntu"}]}
{"id":"bd-1u6","title":"Unit tests: tool/command/event wiring","description":"Background:\n- Extension tool/command/event wiring is the user-visible interface.\n\nSteps:\n- Unit tests for tool registration and tool_call routing.\n- Unit tests for slash command dispatch + argument parsing.\n- Event hook emission ordering tests for agent lifecycle events.\n\nLogging requirements:\n- Tests assert ordering and include verbose diagnostic output on failure.\n\nAcceptance:\n- All wiring paths are covered and ordering matches legacy behavior.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:46:46.391673977Z","created_by":"ubuntu","updated_at":"2026-02-03T02:49:50.298707320Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1u6","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:49:50.298681362Z","created_by":"ubuntu"}]}
{"id":"bd-1ub","title":"E2E CLI scenarios: print mode + stdin piping","description":"Goal:\n- Add E2E tests for CLI print mode and stdin piping, with detailed logging of every step and artifact.\n\nScope:\n- `pi -p \"...\"` basic response flow (using VCR playback for provider output).\n- stdin piping (`pi -p` with piped content) and @file expansion.\n- Assert exit codes, stdout/stderr content, and session side-effects (none in print mode).\n- Verify env controls (PI_CONFIG_PATH, PI_SESSIONS_DIR) do not leak sessions in print mode.\n\nLogging Requirements:\n- Use the CLI E2E harness (bd-1wc) + TestLogger (bd-3ml).\n- Log command, env (redacted), cwd, stdin payload, VCR_MODE, and cassette name/path.\n- Capture stdout/stderr snapshots and attach as test artifacts on failure.\n\nAcceptance Criteria:\n- Tests run deterministically with VCR playback only.\n- Logs include command, env, paths, stdin, cassette id, stdout/stderr snapshots, and session dir checks.\n- No network access; failures produce actionable log output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:54.944916343Z","created_by":"ubuntu","updated_at":"2026-02-03T05:42:55.117400394Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1ub","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T05:00:07.232660854Z","created_by":"ubuntu"},{"issue_id":"bd-1ub","depends_on_id":"bd-1wc","type":"blocks","created_at":"2026-02-03T05:00:01.393790701Z","created_by":"ubuntu"},{"issue_id":"bd-1ub","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:54.955307729Z","created_by":"ubuntu"},{"issue_id":"bd-1ub","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T05:42:55.117369216Z","created_by":"ubuntu"},{"issue_id":"bd-1ub","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:00:50.078375834Z","created_by":"ubuntu"}]}
{"id":"bd-1uj","title":"Unit tests: WASM hostcalls + sandbox boundaries","description":"Background:\n- WASM hostcalls must enforce capabilities and sandboxing rigorously.\n\nSteps:\n- Unit tests for each hostcall (read/write/exec/http/env) with allow/deny cases.\n- Ensure errors propagate with correct codes/messages.\n- Validate resource cleanup and cancellation behavior.\n\nLogging requirements:\n- Tests assert hostcall logs include extension id, capability, and decision.\n\nAcceptance:\n- Hostcall behavior matches policy and is stable under error conditions.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:46:20.154969636Z","created_by":"ubuntu","updated_at":"2026-02-03T02:49:07.235498503Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1uj","depends_on_id":"bd-3d1","type":"blocks","created_at":"2026-02-03T02:48:50.949777504Z","created_by":"ubuntu"},{"issue_id":"bd-1uj","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:49:07.235468737Z","created_by":"ubuntu"}]}
{"id":"bd-1uy","title":"Workstream: Rust extension runtime compatibility complete","description":"Purpose:\n- Implement extension runtime support in pi_agent_rust so extensions run *as-is* with correct protocol, capabilities, and event wiring.\n\nOutputs (artifacts):\n- Extension manifest loader + compatibility scanner.\n- WASM host + WIT bindings; JS compatibility pipeline.\n- Runtime wiring for tool_call, slash_command, event_hooks.\n- Configurable policy modes (strict/prompt/permissive) with audit logging.\n\nDefinition of done:\n- The runtime can load sample extensions and expose their tools/commands.\n- Capability policy is enforced consistently and logged.\n- No modifications to extension source are required (as-is).\n\nDependencies:\n- Must align with extension protocol schema + WIT spec.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:20:06.808066704Z","created_by":"ubuntu","updated_at":"2026-02-03T03:06:40.150262092Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1uy","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-03T02:30:12.853964110Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-1tz","type":"blocks","created_at":"2026-02-03T03:00:18.258715350Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-1u6","type":"blocks","created_at":"2026-02-03T03:00:36.779877348Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-1uj","type":"blocks","created_at":"2026-02-03T03:00:22.168660330Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-261","type":"blocks","created_at":"2026-02-03T03:00:08.302159764Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:30:20.201899992Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-2ni","type":"blocks","created_at":"2026-02-03T03:00:42.028402851Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-2tf","type":"blocks","created_at":"2026-02-03T03:06:30.366126679Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-2tp","type":"blocks","created_at":"2026-02-03T03:06:35.962945035Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-320","type":"blocks","created_at":"2026-02-03T02:30:04.339154654Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-34f","type":"blocks","created_at":"2026-02-03T02:30:32.268119518Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-39u","type":"blocks","created_at":"2026-02-03T03:00:32.276841499Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-3d1","type":"blocks","created_at":"2026-02-03T02:29:57.378812015Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-3im","type":"blocks","created_at":"2026-02-03T03:00:14.178023334Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-03T03:00:49.613430040Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T03:00:54.135867074Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:29:38.900373206Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-gqf","type":"blocks","created_at":"2026-02-03T02:29:48.645550131Z","created_by":"ubuntu"},{"issue_id":"bd-1uy","depends_on_id":"bd-gz6","type":"blocks","created_at":"2026-02-03T03:06:40.150235863Z","created_by":"ubuntu"}]}
{"id":"bd-1vo","title":"Migrate OpenAI provider to asupersync HTTP","description":"# Migrate OpenAI provider to asupersync HTTP\n\n## Goal\nReplace reqwest usage in src/providers/openai.rs with asupersync HTTP client.\n\n## Background\nOpenAI provider handles:\n- Chat completions API\n- Function calling (tools)\n- SSE streaming with data: [DONE] termination\n- 645 lines, 3 unit tests\n\n## Implementation\nSame pattern as Anthropic migration:\n1. Replace reqwest::Client with crate::http::Client\n2. Replace request building with asupersync RequestBuilder\n3. Replace SSE streaming with SseStream adapter\n4. Add Cx parameter to async functions\n\n## OpenAI-Specific Considerations\n1. **SSE Format**: Uses \"data: [DONE]\" as termination marker\n2. **Tool Calls**: JSON in function_call field\n3. **Streaming Deltas**: content delta in choices[0].delta.content\n4. **Error Format**: Different error JSON structure from Anthropic\n\n## Dependencies\n- bd-9sa (HTTP client wrapper)\n- bd-pwz (SSE streaming adapter)\n- bd-37l (Anthropic migration first - establishes pattern)\n\n## Testing\n- 3 existing unit tests must pass\n- Integration test with mock server\n\n## Files\n- src/providers/openai.rs\n\n## Acceptance Criteria\n- [ ] No reqwest imports\n- [ ] All tests pass\n- [ ] Streaming works\n- [ ] Tool calls work","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-03T03:32:59.929871005Z","created_by":"ubuntu","updated_at":"2026-02-03T03:33:41.150888038Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1vo","depends_on_id":"bd-37l","type":"blocks","created_at":"2026-02-03T03:33:41.150863292Z","created_by":"ubuntu"},{"issue_id":"bd-1vo","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:32:59.939779889Z","created_by":"ubuntu"},{"issue_id":"bd-1vo","depends_on_id":"bd-pwz","type":"blocks","created_at":"2026-02-03T03:33:40.889506248Z","created_by":"ubuntu"}]}
{"id":"bd-1wc","title":"Implement CLI E2E integration tests with verbose logging","description":"# Implement CLI E2E integration tests with verbose logging\n\n## Goal\nCreate end-to-end tests that invoke the pi binary directly and verify behavior,\nwith detailed logging for debugging failures.\n\n## Background\nsrc/main.rs (1581 lines) and src/cli.rs (332 lines) have minimal testing.\nThe CLI is the primary user interface and needs comprehensive E2E tests.\n\n## Scope Boundary (Important)\n- This bead builds the CLI E2E harness + offline CLI flag coverage.\n- Provider-dependent scenarios live in:\n  - bd-1ub (print mode + stdin)\n  - bd-idw (session lifecycle)\n  - bd-1o4 (tool enable/disable + error paths)\n\n## Approach\n\n### Test Harness\n```rust\n// tests/e2e_cli.rs\n\nuse std::process::{Command, Stdio};\nuse std::time::Instant;\n\nstruct CliTestHarness {\n    binary_path: PathBuf,\n    temp_dir: TempDir,\n    env: HashMap<String, String>,\n    logs: Vec<LogEntry>,\n}\n\nstruct LogEntry {\n    timestamp: Instant,\n    level: LogLevel,\n    message: String,\n    context: HashMap<String, String>,\n}\n\nimpl CliTestHarness {\n    fn new() -> Self {\n        let binary = cargo_bin(\"pi\");\n        let temp = TempDir::new().unwrap();\n        Self {\n            binary_path: binary,\n            temp_dir: temp,\n            env: HashMap::new(),\n            logs: Vec::new(),\n        }\n    }\n\n    fn log(&mut self, level: LogLevel, msg: &str, ctx: &[(&str, &str)]) {\n        self.logs.push(LogEntry {\n            timestamp: Instant::now(),\n            level,\n            message: msg.to_string(),\n            context: ctx.iter().map(|(k,v)| (k.to_string(), v.to_string())).collect(),\n        });\n    }\n\n    fn run(&mut self, args: &[&str]) -> CliResult {\n        self.log(Info, \"Starting CLI\", &[(\"args\", &args.join(\" \"))]);\n\n        let start = Instant::now();\n        let output = Command::new(&self.binary_path)\n            .args(args)\n            .envs(&self.env)\n            .current_dir(self.temp_dir.path())\n            .output()\n            .expect(\"Failed to run pi\");\n\n        let duration = start.elapsed();\n        self.log(Info, \"CLI completed\", &[\n            (\"exit_code\", &output.status.code().unwrap_or(-1).to_string()),\n            (\"duration_ms\", &duration.as_millis().to_string()),\n            (\"stdout_len\", &output.stdout.len().to_string()),\n            (\"stderr_len\", &output.stderr.len().to_string()),\n        ]);\n\n        CliResult {\n            exit_code: output.status.code().unwrap_or(-1),\n            stdout: String::from_utf8_lossy(&output.stdout).to_string(),\n            stderr: String::from_utf8_lossy(&output.stderr).to_string(),\n            duration,\n        }\n    }\n\n    fn dump_logs(&self) -> String {\n        // Format all logs for debugging\n    }\n}\n```\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) in the harness so failures auto-dump logs.\n- Log: command, env (redacted), cwd, duration, stdout/stderr snapshot, and artifact paths.\n- Attach logs + outputs as artifacts on failure (text snapshots).\n\n## Determinism Requirements\n- Offline-only tests here (help/version/list/config). Any provider-dependent test must live in sub-beads and use VCR playback.\n- Ensure environment is fully controlled (PI_CONFIG_PATH, PI_SESSIONS_DIR).\n\n## Test Categories (Offline)\n\n### 1. Basic Invocation Tests\n```rust\n#[test]\nfn test_version_flag() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"--version\"]);\n    assert_eq!(result.exit_code, 0);\n    assert!(result.stdout.contains(\"pi \"));\n    assert!(result.duration < Duration::from_millis(100));\n}\n\n#[test]\nfn test_help_flag() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"--help\"]);\n    assert_eq!(result.exit_code, 0);\n    assert!(result.stdout.contains(\"Usage:\"));\n}\n\n#[test]\nfn test_invalid_flag() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"--invalid-flag\"]);\n    assert_ne!(result.exit_code, 0);\n    assert!(result.stderr.contains(\"error\"));\n}\n```\n\n### 2. Model Listing Tests\n```rust\n#[test]\nfn test_list_models() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"--list-models\"]);\n    assert_eq!(result.exit_code, 0);\n    assert!(result.stdout.contains(\"claude\"));\n}\n\n#[test]\nfn test_list_models_filter() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"--list-models\", \"opus\"]);\n    assert_eq!(result.exit_code, 0);\n    assert!(result.stdout.contains(\"opus\"));\n    assert!(!result.stdout.contains(\"sonnet\"));\n}\n```\n\n### 3. Subcommand Tests\n```rust\n#[test]\nfn test_list_packages() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"list\"]);\n    assert_eq!(result.exit_code, 0);\n}\n\n#[test]\nfn test_config_subcommand() {\n    let mut harness = CliTestHarness::new();\n    let result = harness.run(&[\"config\"]);\n    // Verify output shows config paths\n}\n```\n\n## Logging Format\n```\n[2026-02-02T10:30:45.123Z] INFO  Starting CLI\n    args: --version\n[2026-02-02T10:30:45.135Z] INFO  CLI completed\n    exit_code: 0\n    duration_ms: 12\n    stdout_len: 23\n    stderr_len: 0\n--- STDOUT ---\npi 0.1.0\n--- STDERR ---\n(empty)\n```\n\n## Files\n- tests/e2e_cli.rs\n- tests/e2e_cli/harness.rs\n- tests/e2e_cli/logging.rs\n\n## Acceptance Criteria\n- [ ] Test harness with verbose logging\n- [ ] Offline CLI flags tested (version/help/list/config)\n- [ ] Logs dumped on test failure\n- [ ] Tests run in <30 seconds total\n\nDependencies:\n  -> bd-3ml (blocks) - Implement verbose test logging infrastructure\n  -> bd-26s (parent-child) - Workstream: Comprehensive Test Coverage (No Mocks)","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-03T03:36:23.617355856Z","created_by":"ubuntu","updated_at":"2026-02-03T08:35:29.174672943Z","closed_at":"2026-02-03T08:35:29.174607821Z","close_reason":"Implemented CLI E2E harness + offline coverage","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1wc","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:36:23.624882872Z","created_by":"ubuntu"},{"issue_id":"bd-1wc","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T03:41:01.663200304Z","created_by":"ubuntu"}]}
{"id":"bd-1we","title":"Update EXTENSIONS.md + FEATURE_PARITY with extension compatibility status","description":"Background:\n- Docs must reflect real compatibility and coverage.\n\nSteps:\n- Update EXTENSIONS.md with supported tiers, sample list, and known gaps.\n- Update FEATURE_PARITY.md with extension status and conformance counts.\n\nAcceptance:\n- Docs match the latest conformance report and include links to fixtures.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:26:04.102718613Z","created_by":"ubuntu","updated_at":"2026-02-03T02:39:53.217391087Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1we","depends_on_id":"bd-20p","type":"blocks","created_at":"2026-02-03T02:39:53.217366532Z","created_by":"ubuntu"},{"issue_id":"bd-1we","depends_on_id":"bd-31j","type":"blocks","created_at":"2026-02-03T02:39:43.584592180Z","created_by":"ubuntu"}]}
{"id":"bd-1xf","title":"Migrate providers and streaming to asupersync HTTP/runtime","description":"Replace reqwest/tokio streaming with asupersync HTTP + Cx, maintain SSE behavior and tests.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:18:29.736942712Z","created_by":"ubuntu","updated_at":"2026-02-03T02:19:06.409446427Z","compaction_level":0,"original_size":0}
{"id":"bd-20p","title":"Workstream: extension performance + benchmark evidence complete","description":"Purpose:\n- Prove extension runtime performance meets budgets and compare against legacy pi.\n\nOutputs (artifacts):\n- Benchmarks for extension load/startup, tool-call overhead, and event hook latency.\n- Performance budgets + thresholds documented.\n- Comparison table vs legacy (same machine/CI class).\n\nDefinition of done:\n- Benchmarks run via `cargo bench` and produce stable numbers.\n- Performance budgets documented and met (or justified).\n\nDependencies:\n- Requires Rust runtime and harness stubs.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-02-03T02:20:27.159589474Z","created_by":"ubuntu","updated_at":"2026-02-03T02:41:44.911911769Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-20p","depends_on_id":"bd-1fg","type":"blocks","created_at":"2026-02-03T02:31:44.106612344Z","created_by":"ubuntu"},{"issue_id":"bd-20p","depends_on_id":"bd-1ii","type":"blocks","created_at":"2026-02-03T02:31:34.231567531Z","created_by":"ubuntu"},{"issue_id":"bd-20p","depends_on_id":"bd-1uy","type":"blocks","created_at":"2026-02-03T02:41:44.911889467Z","created_by":"ubuntu"},{"issue_id":"bd-20p","depends_on_id":"bd-uah","type":"blocks","created_at":"2026-02-03T02:31:51.258046226Z","created_by":"ubuntu"}]}
{"id":"bd-22h","title":"Design stratified sampling matrix for extension diversity","description":"Background:\n- The sample must cover extension feature variety, not just popularity.\n\nInclude axes such as:\n- Capabilities used: read/write/exec/http/env.\n- Interaction model: tool-only vs slash commands vs event hooks.\n- Runtime tier: WASM vs JS bundle vs MCP/process.\n- Complexity: single-file vs multi-module; config-heavy vs config-light.\n- I/O patterns: filesystem-heavy, network-heavy, CPU-heavy.\n\nOutput:\n- A sampling matrix/table that maps each candidate extension to axes, with quotas per axis.\n\nAcceptance:\n- Matrix makes it explicit why each selected extension is in the sample.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:21:15.663936275Z","created_by":"ubuntu","updated_at":"2026-02-03T05:47:39.873324254Z","closed_at":"2026-02-03T05:47:39.873260104Z","close_reason":"Stratified sampling matrix documented in docs/EXTENSION_SAMPLING_MATRIX.md","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-22h","depends_on_id":"bd-2uv","type":"blocks","created_at":"2026-02-03T02:33:46.115721353Z","created_by":"ubuntu"},{"issue_id":"bd-22h","depends_on_id":"bd-gx1","type":"blocks","created_at":"2026-02-03T02:33:37.446436457Z","created_by":"ubuntu"}],"comments":[{"id":15,"issue_id":"bd-22h","author":"Dicklesworthstone","text":"Added docs/EXTENSION_SAMPLING_MATRIX.md with axis quotas (target=16) and full candidate tag mapping using docs/EXTENSION_CANDIDATES.md + CONFORMANCE.md criteria.","created_at":"2026-02-03T05:47:28Z"}]}
{"id":"bd-22p","title":"Workstream: Theme System Implementation","description":"# Workstream: Theme System Implementation\n\n## Goal\nImplement theme loading and switching for the TUI, matching Pi Agent's theme system.\n\n## Background\nThe TypeScript Pi Agent supports themes that control:\n- Color palette (foreground, background, accent colors)\n- Syntax highlighting colors\n- Status line appearance\n- Thinking block styling\n\nThemes are stored as JSON files in:\n- ~/.pi/agent/themes/ (global)\n- .pi/themes/ (project)\n- Package themes (installed via pi install)\n\n## Scope\n\n### In Scope\n1. Theme file format definition (JSON schema)\n2. Theme discovery from standard locations\n3. Theme application to TUI components\n4. Theme switching via /theme command\n5. Default themes (dark, light, solarized)\n\n### Out of Scope\n1. Theme creation wizard\n2. Real-time theme editing\n3. Complex inheritance chains\n\n## Theme Format\n```json\n{\n  \"name\": \"ocean-dark\",\n  \"version\": \"1.0\",\n  \"colors\": {\n    \"foreground\": \"#d4d4d4\",\n    \"background\": \"#1e1e1e\",\n    \"accent\": \"#007acc\",\n    \"success\": \"#4ec9b0\",\n    \"warning\": \"#ce9178\",\n    \"error\": \"#f44747\",\n    \"muted\": \"#6a6a6a\"\n  },\n  \"syntax\": {\n    \"keyword\": \"#569cd6\",\n    \"string\": \"#ce9178\",\n    \"number\": \"#b5cea8\",\n    \"comment\": \"#6a9955\",\n    \"function\": \"#dcdcaa\"\n  },\n  \"ui\": {\n    \"border\": \"#3c3c3c\",\n    \"selection\": \"#264f78\",\n    \"cursor\": \"#aeafad\"\n  }\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Theme Loading\n- Parse theme JSON files\n- Discover themes from standard locations\n- Validate theme format\n- Provide default themes\n\n### Phase 2: Theme Application\n- Apply colors to lipgloss styles\n- Wire syntax colors to glamour\n- Update all TUI components\n\n### Phase 3: Theme Switching\n- /theme command to list/switch\n- Persist theme preference in settings\n- Hot-reload on theme file change (optional)\n\n## Success Criteria\n- [ ] Theme files parsed correctly\n- [ ] Default themes work\n- [ ] /theme command works\n- [ ] TUI renders with theme colors\n- [ ] Settings remembers theme preference\n\n## Files to Create\n- src/theme.rs (theme loading/application)\n- themes/dark.json (default dark theme)\n- themes/light.json (default light theme)\n\n## Files to Modify\n- src/interactive.rs (apply theme to TUI)\n- src/tui.rs (apply theme to console output)\n- src/config.rs (theme preference setting)","status":"open","priority":3,"issue_type":"feature","created_at":"2026-02-03T03:39:16.349318511Z","created_by":"ubuntu","updated_at":"2026-02-03T03:39:16.356035177Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-22p","depends_on_id":"bd-2qk","type":"parent-child","created_at":"2026-02-03T03:39:16.356001444Z","created_by":"ubuntu"}]}
{"id":"bd-247","title":"Fix asupersync websocket unused import warning","description":"asupersync emits unused imports warning in net/websocket/client.rs during builds.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-03T01:26:23.304039205Z","created_by":"ubuntu","updated_at":"2026-02-03T01:52:45.712771158Z","closed_at":"2026-02-03T01:52:45.712697421Z","close_reason":"Fixed unused import warning and clippy clean in asupersync","compaction_level":0,"original_size":0}
{"id":"bd-24f","title":"Unit tests: PackageManager path resolution + filters","description":"Goal:\n- Add unit tests for PackageManager path resolution, package identity parsing, and resource filters using real temp dirs, with detailed logging.\n\nScope:\n- parse_source for npm/git/local and identity normalization.\n- Installed path resolution for user/project scopes.\n- Resource filters: extensions/skills/prompts/themes enable/disable behavior.\n- Deterministic resolution ordering and error paths.\n\nLogging Requirements:\n- Use TestHarness/TestLogger (bd-3ml) in each test.\n- Log parsed source components, resolved paths, and filter decisions.\n\nAcceptance Criteria:\n- Tests use real temp dirs and filesystem paths.\n- No mocks; no network access.\n- Edge cases covered (pinned refs, invalid sources, missing dirs).\n- Logs include inputs + resolved outputs for debugging.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:46.313157289Z","created_by":"ubuntu","updated_at":"2026-02-03T09:16:34.775048154Z","closed_at":"2026-02-03T09:16:34.774969117Z","close_reason":"Added deterministic PackageManager tests (identity/installed_path/filters) + ResolveRoots injection","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-24f","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:46.322467059Z","created_by":"ubuntu"},{"issue_id":"bd-24f","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:27:49.086677235Z","created_by":"ubuntu"}]}
{"id":"bd-25q","title":"Extension compatibility proof: popular sample + conformance harness","description":"Goal:\n- Prove that a large, diverse, *popular* sample of existing pi-agent extensions runs \"as-is\" with full behavioral fidelity in pi_agent_rust.\n- Produce evidence that is testable, repeatable, and automated (fixtures + harness + reports).\n\nScope notes:\n- \"As-is\" means no changes to extension source code or packaging, except for standard install/build steps that the legacy pi toolchain already requires.\n- Compatibility must be demonstrated across tools, slash commands, and event hooks where provided.\n- Evidence must include deterministic conformance fixtures and a runner that compares Rust output to legacy output.\n\nKey references (for future self):\n- EXTENSIONS.md (design goals, runtime tiers).\n- docs/schema/extension_protocol.json + docs/wit/extension.wit (protocol spec).\n- EXISTING_PI_STRUCTURE.md sections 7, 9, 10 for CLI/resource flow.\n\nExit criteria:\n- Workstream summaries (sample, capture, runtime, harness, benchmarks, docs) are each marked done.\n- The conformance harness passes for the entire selected sample.\n- A written report maps each extension to a pass/fail status and notes any deviations.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-03T02:19:34.839197122Z","created_by":"ubuntu","updated_at":"2026-02-03T02:33:25.486349564Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-25q","depends_on_id":"bd-155","type":"blocks","created_at":"2026-02-03T02:33:25.486326902Z","created_by":"ubuntu"},{"issue_id":"bd-25q","depends_on_id":"bd-1uy","type":"blocks","created_at":"2026-02-03T02:32:58.178295362Z","created_by":"ubuntu"},{"issue_id":"bd-25q","depends_on_id":"bd-20p","type":"blocks","created_at":"2026-02-03T02:33:15.291926668Z","created_by":"ubuntu"},{"issue_id":"bd-25q","depends_on_id":"bd-269","type":"blocks","created_at":"2026-02-03T02:33:06.528370559Z","created_by":"ubuntu"},{"issue_id":"bd-25q","depends_on_id":"bd-29c","type":"blocks","created_at":"2026-02-03T02:32:36.705432Z","created_by":"ubuntu"},{"issue_id":"bd-25q","depends_on_id":"bd-3oq","type":"blocks","created_at":"2026-02-03T02:32:47.816503957Z","created_by":"ubuntu"}]}
{"id":"bd-261","title":"Unit tests: extension protocol parsing + schema validation","description":"Background:\n- Protocol correctness is foundational; failures here invalidate all runtime/harness results.\n\nSteps:\n- Add unit tests for ExtensionMessage parse/validate (happy path + edge cases).\n- Round-trip serialize/deserialize for every message type.\n- Validate against docs/schema/extension_protocol.json (schema compliance tests).\n- Include negative cases (missing fields, wrong version, invalid types).\n\nLogging requirements:\n- Tests should emit clear context on failure (message type, field, expected vs actual).\n\nAcceptance:\n- All protocol message variants have unit coverage and schema parity tests pass.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:45:39.810448391Z","created_by":"ubuntu","updated_at":"2026-02-03T07:32:32.921367204Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-261","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:48:03.729397152Z","created_by":"ubuntu"}]}
{"id":"bd-269","title":"Workstream: extension conformance harness + automation complete","description":"Purpose:\n- Build the fixture schema and automated harness that proves Rust runtime matches legacy outputs for every sampled extension.\n\nOutputs (artifacts):\n- Extension fixture schema + normalization rules.\n- Rust harness that executes extensions and diffs outputs against golden fixtures.\n- CI integration + human-readable report.\n\nDefinition of done:\n- Harness runs in `cargo test` and passes for the full sample.\n- Failures produce actionable diffs.\n- Normalization rules documented (time, paths, randomness, ANSI).\n\nDependencies:\n- Requires legacy fixtures and Rust runtime wiring.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:20:17.658873350Z","created_by":"ubuntu","updated_at":"2026-02-03T03:06:44.768539680Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-269","depends_on_id":"bd-1nq","type":"blocks","created_at":"2026-02-03T02:31:15.519815411Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-1uy","type":"blocks","created_at":"2026-02-03T02:41:32.939079022Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-2ce","type":"blocks","created_at":"2026-02-03T02:31:04.943117440Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-2lr","type":"blocks","created_at":"2026-02-03T03:06:44.768510717Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-31j","type":"blocks","created_at":"2026-02-03T02:31:24.142364961Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-3oq","type":"blocks","created_at":"2026-02-03T02:41:24.009639209Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-3s2","type":"blocks","created_at":"2026-02-03T02:30:58.256698576Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-7al","type":"blocks","created_at":"2026-02-03T02:30:48.998840738Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-k7i","type":"blocks","created_at":"2026-02-03T03:01:25.087597433Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-vmm","type":"blocks","created_at":"2026-02-03T03:00:03.128040325Z","created_by":"ubuntu"},{"issue_id":"bd-269","depends_on_id":"bd-yd9","type":"blocks","created_at":"2026-02-03T02:30:40.406993169Z","created_by":"ubuntu"}]}
{"id":"bd-26s","title":"Workstream: Comprehensive Test Coverage (No Mocks)","description":"# Workstream: Comprehensive Test Coverage (No Mocks)\n\n## Goal\nAchieve 95%+ test coverage using real implementations wherever possible, with\ndetailed logging for E2E integration tests. Eliminate reliance on mocks for\ncore functionality testing.\n\n## Background\nCurrent test coverage analysis reveals critical gaps:\n\n### Well Tested (Good)\n- Built-in Tools: 100% coverage (122 conformance fixture cases)\n- Session Tree Logic: 11 tests covering branching/navigation\n- SSE Parser: 9 tests covering all edge cases\n- Auth Flow: 3 tests for PKCE/OAuth setup\n\n### Critical Gaps (Bad)\n- **Provider Streaming**: 0 tests with real API/streaming (only unit tests)\n- **Interactive TUI**: 2 tests out of 2842 lines (<0.1%)\n- **CLI/main.rs**: 0 tests for 1581 lines\n- **Compaction**: 0 tests for 903 lines\n- **Configuration**: 0 tests for 332 lines\n- **Session Persistence**: Only serialization tested, not full I/O cycle\n\n### What \"No Mocks\" Means\n- Provider tests: Use VCR-style recorded responses, not fake providers\n- File tests: Use real temp directories (already done)\n- CLI tests: Use actual binary execution\n- TUI tests: Use terminal emulator or snapshot testing\n- Network tests: Use local test server or recorded responses\n\n## Testing Strategy\n\n### 1. Provider Streaming Tests (VCR Style)\nRecord real API responses and replay them:\n- No external network calls during CI\n- Real response parsing (not simplified mocks)\n- Error scenarios from real API errors\n\n### 2. E2E Integration Tests\nFull workflow tests with verbose logging:\n- Start pi binary with arguments\n- Verify output and exit codes\n- Check session files created\n- Log every step for debugging\n\n### 3. Snapshot Testing for TUI\nCapture terminal output and compare:\n- Render TUI components to string\n- Compare against golden snapshots\n- Update snapshots on intentional changes\n\n### 4. Property-Based Testing\nUse proptest for edge cases:\n- Truncation with random inputs\n- Session serialization round-trips\n- Path resolution edge cases\n\n### 5. Compaction Tests\n- Window selection + summary insertion\n- Tool/thinking/image content handling\n- Session invariants preserved after compaction\n\n### 6. Configuration Tests\n- Config discovery + precedence rules\n- Env + CLI override behavior\n- Invalid config errors with actionable messages\n\n## Success Criteria\n- [ ] Provider streaming tested with recorded responses\n- [ ] TUI logic tested (state transitions, rendering)\n- [ ] CLI argument parsing fully tested\n- [ ] Compaction logic tested\n- [ ] Configuration loading tested\n- [ ] Session persistence cycles tested\n- [ ] E2E tests with verbose logging exist\n- [ ] CI runs all tests in <5 minutes\n\n## Files to Create\n- tests/provider_streaming.rs - VCR-style provider tests\n- tests/e2e_cli.rs - CLI integration tests\n- tests/tui_snapshot.rs - TUI snapshot tests\n- tests/compaction.rs - Compaction pipeline tests\n- tests/config_loading.rs - Config discovery/override tests\n- tests/fixtures/vcr/*.json - Recorded API responses\n\n## Dependencies\nNone (can start immediately, independent of HTTP migration)","status":"open","priority":0,"issue_type":"feature","created_at":"2026-02-03T03:34:05.966405126Z","created_by":"ubuntu","updated_at":"2026-02-03T05:46:20.507382886Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-26s","depends_on_id":"bd-2qk","type":"parent-child","created_at":"2026-02-03T03:34:05.973753960Z","created_by":"ubuntu"}]}
{"id":"bd-29c","title":"Workstream: popular extension sample selection + acquisition complete","description":"Purpose:\n- Produce a *large, diverse, popular* extension sample with frozen versions and archived artifacts so conformance tests are repeatable.\n\nOutputs (artifacts):\n- Sample selection criteria + sampling matrix (documented).\n- Final manifest of chosen extensions (name, source, version, checksum, capabilities, categories).\n- Archived artifacts (tarballs/zip) stored under a dedicated fixtures area with checksums.\n\nDefinition of done:\n- Sample list is final and frozen with versions.\n- Artifacts are locally archived with checksums.\n- License/redistribution policy applied to each artifact (OK / restricted / exclude).\n\nDependencies:\n- This workstream blocks legacy capture, harness, and reporting.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:19:44.802403431Z","created_by":"ubuntu","updated_at":"2026-02-03T02:28:15.393814835Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-29c","depends_on_id":"bd-22h","type":"blocks","created_at":"2026-02-03T02:27:48.803635894Z","created_by":"ubuntu"},{"issue_id":"bd-29c","depends_on_id":"bd-2uv","type":"blocks","created_at":"2026-02-03T02:27:27.483930216Z","created_by":"ubuntu"},{"issue_id":"bd-29c","depends_on_id":"bd-2wo","type":"blocks","created_at":"2026-02-03T02:27:56.575435375Z","created_by":"ubuntu"},{"issue_id":"bd-29c","depends_on_id":"bd-3rr","type":"blocks","created_at":"2026-02-03T02:28:15.393785220Z","created_by":"ubuntu"},{"issue_id":"bd-29c","depends_on_id":"bd-gx1","type":"blocks","created_at":"2026-02-03T02:27:40.976426571Z","created_by":"ubuntu"},{"issue_id":"bd-29c","depends_on_id":"bd-ic9","type":"blocks","created_at":"2026-02-03T02:28:06.592012396Z","created_by":"ubuntu"}]}
{"id":"bd-2ce","title":"Add negative conformance tests for denied capabilities","description":"Background:\n- We must prove policy enforcement: denied hostcalls should fail predictably.\n\nSteps:\n- Define fixtures where extensions attempt disallowed capabilities.\n- Ensure outputs match legacy pi behavior (error messages, exit codes).\n- Cover strict/prompt/permissive modes.\n\nAcceptance:\n- Negative tests pass and failures are clear, consistent, and policy-driven.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:04.934329690Z","created_by":"ubuntu","updated_at":"2026-02-03T02:37:54.006418531Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2ce","depends_on_id":"bd-34f","type":"blocks","created_at":"2026-02-03T02:37:45.013467540Z","created_by":"ubuntu"},{"issue_id":"bd-2ce","depends_on_id":"bd-7al","type":"blocks","created_at":"2026-02-03T02:37:54.006392022Z","created_by":"ubuntu"}]}
{"id":"bd-2gn","title":"Unit tests: ResourceLoader discovery + diagnostics","description":"Goal:\n- Add unit/integration tests for ResourceLoader (skills/prompts/themes/extensions) using real files and directories, with detailed logging.\n\nScope:\n- Skill discovery from explicit paths + defaults.\n- Prompt template discovery + metadata parsing.\n- Theme loading with explicit path + package sources.\n- Diagnostics: collisions, invalid files, missing resources, precedence rules.\n\nLogging Requirements:\n- Use TestHarness/TestLogger (bd-3ml) in each test.\n- Log resolved paths, chosen winners for collisions, and diagnostics payloads.\n\nAcceptance Criteria:\n- Tests use real temp dirs and files; no mocks.\n- Diagnostics asserted for collisions + invalid metadata.\n- Logs include inputs, resolution decisions, and outputs.\n- Deterministic ordering and no network usage.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:39.658643959Z","created_by":"ubuntu","updated_at":"2026-02-03T09:18:40.431951432Z","closed_at":"2026-02-03T09:18:40.431888685Z","close_reason":"Added ResourceLoader discovery/diagnostics tests; made resource dedupe deterministic","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2gn","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:39.678553994Z","created_by":"ubuntu"},{"issue_id":"bd-2gn","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:27:35.344117377Z","created_by":"ubuntu"}]}
{"id":"bd-2i5","title":"Wire extension runtime into agent loop (tools/commands/events)","description":"Background:\n- Extensions must integrate with the agent loop so their tools and commands are callable.\n\nSteps:\n- Register extension tools with the ToolRegistry and route tool_call/tool_result.\n- Register slash commands and hook them into interactive mode.\n- Implement event hook emission at appropriate agent lifecycle points.\n- Ensure wiring supports deterministic test hooks (ordering + timing).\n\nLogging requirements:\n- Emit structured logs for tool registration, command invocation, and event hooks (correlation IDs).\n\nAcceptance:\n- An extension-provided tool and slash command can be invoked end-to-end.\n- Logs follow the extension logging spec for conformance/E2E tests.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:12.588180426Z","created_by":"ubuntu","updated_at":"2026-02-03T03:07:05.988120840Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2i5","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-03T02:36:42.381852755Z","created_by":"ubuntu"},{"issue_id":"bd-2i5","depends_on_id":"bd-320","type":"blocks","created_at":"2026-02-03T02:36:33.786661150Z","created_by":"ubuntu"},{"issue_id":"bd-2i5","depends_on_id":"bd-3d1","type":"blocks","created_at":"2026-02-03T02:36:24.409519415Z","created_by":"ubuntu"},{"issue_id":"bd-2i5","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:58:11.702297011Z","created_by":"ubuntu"}]}
{"id":"bd-2jh","title":"Implement error handling path tests","description":"# Implement error handling path tests\n\n## Goal\nTest all error conditions that can occur during normal operation, with detailed logging.\n\n## Background\nError paths are currently untested but critical for UX:\n- Network failures\n- API rate limits\n- Authentication failures\n- Malformed responses\n- File system errors\n- Timeout scenarios\n\n## Runtime + Determinism\n- Do not introduce new tokio-only tests; use `#[asupersync::test]` or a runtime wrapper.\n- All API error cases must use VCR playback (no live network).\n- File system errors must use temp dirs and deterministic paths.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml).\n- Log cassette path, error category, and sanitized error details.\n- On failure, dump expected vs actual error variants + any response body fragments.\n\n## Test Categories\n\n### Network Errors\n```rust\n#[asupersync::test]\nasync fn test_connection_refused() {\n    let vcr = VcrRecorder::new(\"network_connection_refused\");\n    let provider = AnthropicProvider::new_with_client(vcr.client());\n\n    let result = provider.stream(&context, &options).await;\n    assert!(matches!(result, Err(Error::Network { .. })));\n}\n```\n\n### API Errors\n- 429 rate limit (retry-after)\n- 401 auth failure\n- 403 forbidden\n- 400 bad request\n- 500 server error\n- 529 overloaded\n\n### Malformed Response Errors\n- Invalid JSON body\n- Missing required fields\n- Unexpected SSE event type\n- Truncated stream\n\n### File System Errors\n- Read permission denied\n- Write permission denied\n- Disk full (simulate with tempfs limits if feasible)\n- Path too long\n\n### Tool Execution Errors\n- bash command not found\n- bash timeout\n- edit file not found\n\n## Dependencies\n- bd-1pf (VCR infrastructure for API error testing)\n\n## Files\n- tests/error_handling.rs\n\n## Acceptance Criteria\n- [ ] 25+ error handling tests\n- [ ] All network errors covered (via VCR/local simulation)\n- [ ] All API error codes covered\n- [ ] File system errors covered\n- [ ] Tool errors covered\n- [ ] Logs include error category + cassette id\n- [ ] Error messages are helpful\n- [ ] All tests pass","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:40:33.110276433Z","created_by":"ubuntu","updated_at":"2026-02-03T05:43:34.660912407Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2jh","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T03:41:01.345001879Z","created_by":"ubuntu"},{"issue_id":"bd-2jh","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:40:33.123723281Z","created_by":"ubuntu"},{"issue_id":"bd-2jh","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T05:43:34.660884836Z","created_by":"ubuntu"},{"issue_id":"bd-2jh","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:43:32.812857475Z","created_by":"ubuntu"}]}
{"id":"bd-2lg","title":"Implement compaction module unit tests","description":"# Implement compaction module unit tests\n\n## Goal\nAdd comprehensive unit tests for src/compaction.rs (903 lines, currently 0 tests).\n\n## Background\nCompaction is a critical feature that:\n- Summarizes old conversation history to save context tokens\n- Identifies optimal cut points in message history\n- Tracks file operations (read/write/edit) for summary\n- Uses LLM to generate summaries\n\n## Module Analysis (src/compaction.rs)\n\n### Key Types\n```rust\nstruct CompactionContext {\n    entries: Vec<SessionEntry>,\n    config: CompactionConfig,\n    token_estimator: TokenEstimator,\n}\n\nstruct CutPoint {\n    entry_index: usize,\n    reason: CutPointReason,\n    tokens_before: usize,\n    tokens_after: usize,\n}\n\nenum CutPointReason {\n    TokenLimit,\n    UserMessageBoundary,\n    ToolResultBoundary,\n    NaturalBreak,\n}\n\nstruct FileSummary {\n    path: String,\n    operations: Vec<FileOp>,\n}\n```\n\n### Key Functions\n- `estimate_tokens(entry: &SessionEntry) -> usize`\n- `find_cut_points(entries: &[SessionEntry], config: &Config) -> Vec<CutPoint>`\n- `extract_file_operations(entries: &[SessionEntry]) -> Vec<FileSummary>`\n- `prepare_compaction(entries: &[SessionEntry], config: &Config) -> CompactionPlan`\n- `generate_summary_prompt(entries: &[SessionEntry], files: &[FileSummary]) -> String`\n\n## Test Categories\n\n### 1. Token Estimation Tests\n```rust\n#[test]\nfn test_estimate_tokens_simple_text() {\n    let entry = user_message(\"Hello, world!\");\n    let tokens = estimate_tokens(&entry);\n    assert!(tokens > 0 && tokens < 10);\n}\n\n#[test]\nfn test_estimate_tokens_code_block() {\n    let entry = assistant_message(\"```rust\\nfn main() {}\\n```\");\n    let tokens = estimate_tokens(&entry);\n    // Code blocks should estimate higher\n}\n\n#[test]\nfn test_estimate_tokens_tool_result() {\n    let entry = tool_result(\"read\", \"Large file content...\");\n    let tokens = estimate_tokens(&entry);\n    // Verify reasonable estimate\n}\n```\n\n### 2. Cut Point Detection Tests\n```rust\n#[test]\nfn test_find_cut_points_token_limit() {\n    let entries = generate_entries(100, 1000);  // 100 entries, ~1000 tokens each\n    let config = CompactionConfig { max_tokens: 50000 };\n    \n    let cuts = find_cut_points(&entries, &config);\n    \n    // Should find cuts when exceeding limit\n    assert!(!cuts.is_empty());\n    assert!(cuts[0].tokens_after <= config.max_tokens);\n}\n\n#[test]\nfn test_cut_point_prefers_user_message_boundary() {\n    let entries = vec![\n        user_message(\"Q1\"),\n        assistant_message(\"A1\"),\n        user_message(\"Q2\"),  // Preferred cut point\n        assistant_message(\"A2\"),\n    ];\n    \n    let cuts = find_cut_points(&entries, &low_limit_config());\n    \n    // Should cut at user message boundary\n    assert_eq!(cuts[0].reason, CutPointReason::UserMessageBoundary);\n}\n\n#[test]\nfn test_cut_point_preserves_tool_pairs() {\n    let entries = vec![\n        user_message(\"Read file\"),\n        assistant_with_tool_call(\"read\", { \"path\": \"test.txt\" }),\n        tool_result(\"read\", \"File contents...\"),\n        assistant_message(\"The file contains...\"),\n    ];\n    \n    let cuts = find_cut_points(&entries, &config);\n    \n    // Should not cut between tool call and result\n    for cut in cuts {\n        assert_ne!(cut.entry_index, 2);  // Not after tool call\n    }\n}\n```\n\n### 3. File Operation Extraction Tests\n```rust\n#[test]\nfn test_extract_file_operations_read() {\n    let entries = vec![\n        tool_result_with_details(\"read\", json!({\"path\": \"src/main.rs\", \"lines_read\": 100})),\n    ];\n    \n    let files = extract_file_operations(&entries);\n    \n    assert_eq!(files.len(), 1);\n    assert_eq!(files[0].path, \"src/main.rs\");\n    assert_eq!(files[0].operations[0], FileOp::Read { lines: 100 });\n}\n\n#[test]\nfn test_extract_file_operations_write() {\n    let entries = vec![\n        tool_result_with_details(\"write\", json!({\"path\": \"new.txt\", \"bytes_written\": 1234})),\n    ];\n    \n    let files = extract_file_operations(&entries);\n    \n    assert_eq!(files[0].operations[0], FileOp::Write { bytes: 1234 });\n}\n\n#[test]\nfn test_extract_file_operations_edit() {\n    let entries = vec![\n        tool_result_with_details(\"edit\", json!({\n            \"path\": \"src/lib.rs\",\n            \"old_length\": 10,\n            \"new_length\": 15\n        })),\n    ];\n    \n    let files = extract_file_operations(&entries);\n    \n    assert!(matches!(files[0].operations[0], FileOp::Edit { .. }));\n}\n\n#[test]\nfn test_file_operations_grouped_by_path() {\n    let entries = vec![\n        tool_result_with_details(\"read\", json!({\"path\": \"a.txt\"})),\n        tool_result_with_details(\"edit\", json!({\"path\": \"a.txt\"})),\n        tool_result_with_details(\"read\", json!({\"path\": \"b.txt\"})),\n    ];\n    \n    let files = extract_file_operations(&entries);\n    \n    // Files should be deduplicated\n    assert_eq!(files.len(), 2);\n    assert_eq!(files.iter().find(|f| f.path == \"a.txt\").unwrap().operations.len(), 2);\n}\n```\n\n### 4. Summary Prompt Generation Tests\n```rust\n#[test]\nfn test_summary_prompt_includes_messages() {\n    let entries = vec![\n        user_message(\"Help me with X\"),\n        assistant_message(\"I'll help with X by doing Y\"),\n    ];\n    \n    let prompt = generate_summary_prompt(&entries, &[]);\n    \n    assert!(prompt.contains(\"Help me with X\"));\n    assert!(prompt.contains(\"Y\"));\n}\n\n#[test]\nfn test_summary_prompt_includes_file_summary() {\n    let files = vec![\n        FileSummary {\n            path: \"src/main.rs\".into(),\n            operations: vec![FileOp::Read { lines: 100 }, FileOp::Edit { old: 10, new: 15 }],\n        },\n    ];\n    \n    let prompt = generate_summary_prompt(&[], &files);\n    \n    assert!(prompt.contains(\"src/main.rs\"));\n    assert!(prompt.contains(\"read\"));\n    assert!(prompt.contains(\"edit\"));\n}\n```\n\n### 5. Compaction Plan Tests\n```rust\n#[test]\nfn test_prepare_compaction_identifies_entries_to_keep() {\n    let entries = generate_entries(50, 1000);\n    let config = CompactionConfig {\n        max_tokens: 30000,\n        keep_recent: 10000,\n    };\n    \n    let plan = prepare_compaction(&entries, &config);\n    \n    // Should keep recent entries\n    assert!(plan.entries_to_keep.len() < entries.len());\n    assert!(plan.tokens_after_compaction <= config.max_tokens);\n}\n```\n\n## Dependencies\nNone (unit tests only)\n\n## Files\n- src/compaction.rs (add #[cfg(test)] module)\n\n## Acceptance Criteria\n- [ ] 20+ unit tests for compaction\n- [ ] Token estimation tested\n- [ ] Cut point detection tested\n- [ ] File operation extraction tested\n- [ ] Summary prompt generation tested\n- [ ] Edge cases covered\n- [ ] All tests pass","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T03:36:53.592325399Z","created_by":"ubuntu","updated_at":"2026-02-03T05:23:36.355281684Z","closed_at":"2026-02-03T05:23:36.355215541Z","close_reason":"Completed","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2lg","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:36:53.598326111Z","created_by":"ubuntu"}]}
{"id":"bd-2lr","title":"Unit tests: fixture schema + normalization rules","description":"Background:\n- Fixture schema and normalization are the bedrock of conformance stability.\n\nSteps:\n- Schema validation tests with representative fixtures (tools/commands/events).\n- Golden tests for normalization transforms (paths, timestamps, ANSI, randomness).\n- Negative tests for malformed fixtures and invalid normalization hints.\n\nLogging requirements:\n- Test failures must report which rule or schema path failed.\n\nAcceptance:\n- Schema and normalization rules are deterministic with high-coverage tests.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:05:10.743032754Z","created_by":"ubuntu","updated_at":"2026-02-03T03:05:58.026358006Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2lr","depends_on_id":"bd-3s2","type":"blocks","created_at":"2026-02-03T03:05:58.026330705Z","created_by":"ubuntu"},{"issue_id":"bd-2lr","depends_on_id":"bd-yd9","type":"blocks","created_at":"2026-02-03T03:05:52.013324071Z","created_by":"ubuntu"}]}
{"id":"bd-2ni","title":"E2E: Rust extension runtime smoke suite (sample) with verbose logs","description":"Background:\n- We need an end-to-end validation that sampled extensions run in Rust with real wiring.\n\nSteps:\n- Build an E2E script that loads each sampled extension from the manifest and runs its scenarios.\n- Capture stdout/stderr, tool outputs, and event hook logs per extension.\n- Store logs as artifacts for debugging (per-extension log file).\n\nLogging requirements:\n- Structured logs with correlation IDs: extension id, scenario id, tool/command/event type.\n\nAcceptance:\n- E2E script passes for the full sample and produces logs suitable for triage.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:46:59.333523573Z","created_by":"ubuntu","updated_at":"2026-02-03T02:59:30.088394167Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2ni","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:50:03.585226017Z","created_by":"ubuntu"},{"issue_id":"bd-2ni","depends_on_id":"bd-34f","type":"blocks","created_at":"2026-02-03T02:59:19.189101895Z","created_by":"ubuntu"},{"issue_id":"bd-2ni","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-03T02:59:23.294358333Z","created_by":"ubuntu"},{"issue_id":"bd-2ni","depends_on_id":"bd-3rr","type":"blocks","created_at":"2026-02-03T02:59:15.163850386Z","created_by":"ubuntu"},{"issue_id":"bd-2ni","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:59:30.088367136Z","created_by":"ubuntu"},{"issue_id":"bd-2ni","depends_on_id":"bd-ic9","type":"blocks","created_at":"2026-02-03T02:50:14.801243Z","created_by":"ubuntu"}]}
{"id":"bd-2qd","title":"Define per-extension scenario suite for capture","description":"Background:\n- Each extension may expose tools, slash commands, and event hooks; we must test them consistently.\n\nSteps:\n- For each sampled extension, enumerate available features (tools/commands/events).\n- Define minimal smoke scenarios + edge cases (inputs, expected outputs).\n- Document any required configuration or secrets (mocked).\n\nOutput:\n- A scenario specification mapped to each extension in the sample manifest.\n\nAcceptance:\n- Every extension has at least one scenario per supported feature category.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:28.650419393Z","created_by":"ubuntu","updated_at":"2026-02-03T07:47:33.619339695Z","closed_at":"2026-02-03T07:47:33.619279633Z","close_reason":"Completed: added extension capture scenario suite spec","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2qd","depends_on_id":"bd-ic9","type":"blocks","created_at":"2026-02-03T02:34:39.934693450Z","created_by":"ubuntu"}]}
{"id":"bd-2qk","title":"Epic: Complete pi_agent_rust Port to 100% Feature Parity","description":"# Epic: Complete pi_agent_rust Port to 100% Feature Parity\n\n## Goal\nAchieve 100% feature/functionality coverage of the original Pi Agent (TypeScript) with:\n- Complete conformance harness validating behavioral equivalence\n- Comprehensive test coverage without mocks where possible\n- Full integration with sibling libraries (asupersync, rich_rust, charmed_rust)\n- Detailed E2E integration test scripts with verbose logging\n\n## Background\npi_agent_rust is a Rust port of Pi Agent (TypeScript CLI) by Mario Zechner. The port uses\nspec-first methodology: extract behavior from legacy → implement from spec → never translate\nline-by-line. Currently at ~85% feature complete with all core functionality working.\n\n## Current State (as of 2026-02-02)\n- ✅ Core Types: All message types, content blocks, usage tracking\n- ✅ 7 Built-in Tools: read, bash, edit, write, grep, find, ls (122 conformance tests)\n- ✅ Providers: Anthropic, OpenAI, Gemini, Azure (all streaming + tool use)\n- ✅ Agent Runtime: Full loop with tool iteration and event callbacks\n- ✅ Session Management: JSONL v3 format, tree structure, branching\n- ✅ Interactive TUI: Elm Architecture with bubbletea/lipgloss/bubbles/glamour\n- ✅ CLI: Full argument parsing, subcommands, package management\n- ✅ Authentication: auth.json storage, OAuth login/logout\n- ✅ Compaction: Full context compaction with LLM summarization\n- ✅ RPC Mode: Complete JSON protocol implementation\n- ✅ Benchmarks: Truncation, SSE parsing with performance budgets\n\n## Key Gaps Requiring Work\n1. **HTTP Migration**: Providers still use reqwest; asupersync HTTP client stubbed\n2. **Extensions Runtime**: Protocol defined but no WASM loader/runtime\n3. **Session Index Integration**: Implemented but not wired into CLI\n4. **Themes**: Not implemented\n5. **Test Coverage**: Critical gaps in provider streaming, TUI, CLI, compaction\n\n## Success Criteria\n- [ ] All providers use asupersync HTTP client (tokio removed)\n- [ ] Extension runtime loads and executes WASM extensions\n- [ ] Session picker uses SQLite index for fast lookups\n- [ ] Theme system loads and applies themes\n- [ ] 95%+ test coverage without mocks for core paths\n- [ ] E2E tests with real API calls (recorded/VCR style)\n- [ ] All conformance fixtures pass\n- [ ] Performance targets met (startup <100ms, binary <20MB)\n\n## Workstreams (child features)\n1. HTTP Migration (HIGH priority) - Blocks tokio removal\n2. Test Coverage Expansion (HIGH priority) - Quality gate\n3. Session Index Integration (MEDIUM priority) - UX improvement\n4. Themes (LOW priority) - Nice to have\n5. Extensions Runtime (tracked separately in existing beads bd-25q)","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-03T03:31:24.363150202Z","created_by":"ubuntu","updated_at":"2026-02-03T03:31:24.363150202Z","compaction_level":0,"original_size":0}
{"id":"bd-2tf","title":"Unit tests: extension discovery + install resolution","description":"Background:\n- Discovery/install is user-facing and failure-prone; tests prevent regressions.\n\nSteps:\n- Unit tests for package source resolution (global vs project precedence).\n- Tests for CLI flags (--extension/--no-extensions) and conflict handling.\n- Validate diagnostics for missing/invalid extensions (actionable errors).\n- Cover path normalization, symlink handling, and manifest discovery.\n\nLogging requirements:\n- Tests assert diagnostics include source, resolution path, and reason codes.\n\nAcceptance:\n- All discovery/install branches have unit coverage with deterministic outputs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:04:58.361767846Z","created_by":"ubuntu","updated_at":"2026-02-03T03:05:37.400281159Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2tf","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-03T03:05:32.727103737Z","created_by":"ubuntu"},{"issue_id":"bd-2tf","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T03:05:37.400250952Z","created_by":"ubuntu"}]}
{"id":"bd-2tp","title":"Unit tests: extc pipeline + compat scanner","description":"Background:\n- The extc build pipeline is the JS/TS compatibility backbone; correctness is critical.\n\nSteps:\n- Unit tests for JS/TS bundling with deterministic output.\n- Verify shim rewrite passes (legacy API -> connector hostcalls).\n- Compat scan tests: reject Node/Bun globals and forbidden APIs.\n- Cache tests: identical inputs hit cache; changes bust cache.\n\nLogging requirements:\n- Tests assert diagnostics include rejected API name + location.\n\nAcceptance:\n- Pipeline behavior is deterministic and rejects incompatible code with actionable logs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:05:05.088900030Z","created_by":"ubuntu","updated_at":"2026-02-03T03:05:47.667473657Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2tp","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T03:05:47.667444432Z","created_by":"ubuntu"},{"issue_id":"bd-2tp","depends_on_id":"bd-xgo","type":"blocks","created_at":"2026-02-03T03:05:42.547370766Z","created_by":"ubuntu"}]}
{"id":"bd-2tx","title":"No-mock policy enforcement (lint + CI guard)","description":"Goal:\n- Enforce the no-mock policy by adding a lightweight CI guard that flags new mock/fake usage in tests, with actionable logging.\n\nScope:\n- Define explicit allowlist rules (file + rationale) for any exceptional mocks.\n- Add a fast check (rg/ast-grep) that fails CI when Mock/Fake/Stub patterns appear outside allowlist.\n- Emit clear diagnostics (file:line + matched symbol) and guidance to replace with VCR/real deps.\n- Document the policy and how to request/justify exceptions.\n\nAcceptance Criteria:\n- CI fails if new mocks/fakes are introduced without allowlist entry.\n- Output includes exact file:line matches and remediation guidance.\n- Allowlist is minimal, audited, and documented.\n- Guard is fast, deterministic, and runs in CI + locally.\n\nDependencies:\n- Leverages bd-351 audit to seed allowlist and baseline mock inventory.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:59:27.589230634Z","created_by":"ubuntu","updated_at":"2026-02-03T05:27:00.277654862Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2tx","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:59:27.597014240Z","created_by":"ubuntu"},{"issue_id":"bd-2tx","depends_on_id":"bd-351","type":"blocks","created_at":"2026-02-03T04:59:43.626768288Z","created_by":"ubuntu"}]}
{"id":"bd-2uv","title":"Define popularity criteria + target sample size","description":"Background:\n- We must justify *why* each extension is in the sample and ensure diversity (not just what is easy to test).\n\nWhat to decide (document explicitly):\n- Popularity signals (e.g., GitHub stars, npm downloads, community references, official pi docs).\n- Diversity axes (tool-only vs slash commands, event hooks, UI integrations, network usage, file system usage).\n- Minimum and maximum sample size, plus rationale (coverage vs time).\n\nOutput:\n- A written criteria section that later tasks can apply mechanically.\n\nAcceptance:\n- Criteria are precise enough that two people would pick the same sample.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:20:45.780340292Z","created_by":"ubuntu","updated_at":"2026-02-03T03:32:02.804375173Z","closed_at":"2026-02-03T03:32:02.804313057Z","close_reason":"Added deterministic sampling criteria + target size in CONFORMANCE.md","compaction_level":0,"original_size":0}
{"id":"bd-2wo","title":"Define license/redistribution policy for extension artifacts + fixtures","description":"Background:\n- We will archive extension artifacts and include fixtures. Licensing constraints must be honored.\n\nDecisions to document:\n- Which licenses allow redistribution of artifacts and fixture snippets.\n- When to store hashes only vs full artifacts.\n- Procedure for excluded/opt-out extensions.\n\nOutput:\n- A policy note that maps license types to allowed storage actions.\n\nAcceptance:\n- Every sampled extension can be classified as OK / restricted / excluded under this policy.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:21:27.469438600Z","created_by":"ubuntu","updated_at":"2026-02-03T03:45:26.883830816Z","closed_at":"2026-02-03T03:45:26.883767769Z","close_reason":"Documented license/redistribution policy for extension artifacts + fixtures in CONFORMANCE.md","compaction_level":0,"original_size":0}
{"id":"bd-2x7","title":"E2E interactive smoke (tmux) + detailed logs","description":"Goal:\n- Add a scripted E2E smoke test for interactive mode using tmux (per AGENTS.md), with detailed logs and captured panes.\n\nScope:\n- Launch pi in tmux with fixed dimensions (80x24).\n- Send a prompt, capture output, and verify key UI events.\n- Capture logs/pane snapshots as test artifacts.\n- Validate clean shutdown and no orphaned processes.\n\nLogging Requirements:\n- Use CLI E2E harness (bd-1wc) + TestLogger (bd-3ml).\n- Log tmux commands, timings, pane captures, VCR_MODE, and cassette name/path.\n- Save pane snapshots + logs on failure for debugging.\n\nAcceptance Criteria:\n- Deterministic run using VCR playback and stable terminal dimensions.\n- Logs include tmux commands, pane captures, and assertions.\n- Tests pass on CI environments that support tmux (skip with clear log if unavailable).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:59:18.073043109Z","created_by":"ubuntu","updated_at":"2026-02-03T05:43:00.879928578Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2x7","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T05:00:43.457111939Z","created_by":"ubuntu"},{"issue_id":"bd-2x7","depends_on_id":"bd-1wc","type":"blocks","created_at":"2026-02-03T05:00:38.605726695Z","created_by":"ubuntu"},{"issue_id":"bd-2x7","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:59:18.080271631Z","created_by":"ubuntu"},{"issue_id":"bd-2x7","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T05:43:00.879901318Z","created_by":"ubuntu"},{"issue_id":"bd-2x7","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:01:06.669769764Z","created_by":"ubuntu"}]}
{"id":"bd-30u","title":"Record VCR cassettes for Anthropic provider scenarios","description":"# Record VCR cassettes for Anthropic provider scenarios\n\n## Goal\nCreate recorded cassettes for all Anthropic provider test scenarios.\n\n## Scenarios to Record\n\n### Happy Path Scenarios\n1. **Simple text response** - Single text block, stop reason \"stop\"\n2. **Multi-paragraph response** - Multiple text deltas\n3. **Extended thinking** - thinking_start/delta/end + text response\n4. **Tool call single** - Single tool_call in response\n5. **Tool call multiple** - Multiple tool_calls in single response\n6. **Tool result processing** - tool_result message handling\n\n### Error Scenarios\n7. **Rate limit (429)** - With retry-after header\n8. **Auth failure (401)** - Invalid API key\n9. **Forbidden (403)** - Resource access denied\n10. **Bad request (400)** - Malformed request\n11. **Server error (500)** - Internal server error\n12. **Overloaded (529)** - Anthropic overloaded\n\n### Edge Cases\n13. **Empty response** - No content blocks\n14. **Very long response** - Hits max_tokens\n15. **Unicode content** - Emoji, CJK, RTL text\n16. **Large tool call args** - Big JSON in arguments\n17. **Stream interruption** - Partial response simulation\n\n### Extended Thinking Variants\n18. **Thinking only** - No final text, just thinking\n19. **Thinking with tool calls** - Thinking then tool use\n20. **Thinking budget exceeded** - Hits thinking token limit\n\n## Recording Process\n```bash\n# Set API key (not committed)\nexport ANTHROPIC_API_KEY=sk-ant-...\n\n# Record mode\nVCR_MODE=record cargo test provider_streaming::anthropic\n\n# Verify cassettes created\nls tests/fixtures/vcr/anthropic_*.json\n```\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) during recording runs.\n- Log cassette name/path, model, prompt summary hash, and redaction summary.\n- Capture command line + env (redacted) used to record each cassette.\n\n## Determinism + Redaction\n- Keep prompts/tool schemas identical across recordings; store prompt hashes in a manifest.\n- Ensure API keys and any sensitive fields are redacted.\n- Record with fixed model versions + params (temperature, max_tokens, thinking level).\n\n## Files Created\n- tests/fixtures/vcr/anthropic_simple_text.json\n- tests/fixtures/vcr/anthropic_extended_thinking.json\n- tests/fixtures/vcr/anthropic_tool_call.json\n- tests/fixtures/vcr/anthropic_rate_limit.json\n- ... (20 cassettes total)\n- tests/fixtures/vcr/anthropic_manifest.json (scenario → prompt hash + params)\n\n## Dependencies\n- bd-1pf (VCR infrastructure must exist)\n\n## Acceptance Criteria\n- [ ] 20 cassettes recorded\n- [ ] All scenarios covered\n- [ ] Sensitive data redacted\n- [ ] Cassettes valid JSON\n- [ ] Manifest includes prompt hashes + params\n- [ ] Playback matches recording\n- [ ] Recording logs captured with redacted env","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:34:42.752221104Z","created_by":"ubuntu","updated_at":"2026-02-03T05:41:46.052453953Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-30u","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T03:35:07.519020783Z","created_by":"ubuntu"},{"issue_id":"bd-30u","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:34:42.762776734Z","created_by":"ubuntu"}]}
{"id":"bd-31j","title":"Generate per-extension conformance report (machine + human)","description":"Background:\n- We need a consumable summary of results for stakeholders and future self.\n\nSteps:\n- Produce a report that lists each extension, version, runtime tier, and pass/fail.\n- Include failure reasons and links to fixtures/logs.\n- Ensure report can be regenerated automatically.\n\nAcceptance:\n- Report is updated by running a single documented command.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:23.180071849Z","created_by":"ubuntu","updated_at":"2026-02-03T02:38:48.372939252Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-31j","depends_on_id":"bd-16n","type":"blocks","created_at":"2026-02-03T02:38:48.372915528Z","created_by":"ubuntu"},{"issue_id":"bd-31j","depends_on_id":"bd-1nq","type":"blocks","created_at":"2026-02-03T02:38:37.057218072Z","created_by":"ubuntu"}]}
{"id":"bd-320","title":"Implement JS compatibility pipeline (bundle -> runtime)","description":"Background:\n- Many extensions are JS/TS; we need a compatibility tier to run them as-is.\n\nSteps:\n- Choose JS execution strategy (QuickJS bytecode or JS->WASM).\n- Implement build pipeline + caching by hash (extc/SWC).\n- Provide shims for legacy APIs to map into hostcalls.\n- Integrate with the QuickJS runtime and connector dispatcher.\n\nAcceptance:\n- A representative JS extension from the sample runs without source modification.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:23:48.829161504Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:06.958868942Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-320","depends_on_id":"bd-1f5","type":"blocks","created_at":"2026-02-03T02:57:51.102987010Z","created_by":"ubuntu"},{"issue_id":"bd-320","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:36:05.880390018Z","created_by":"ubuntu"},{"issue_id":"bd-320","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:58:06.958842873Z","created_by":"ubuntu"},{"issue_id":"bd-320","depends_on_id":"bd-xgo","type":"blocks","created_at":"2026-02-03T02:57:45.142354946Z","created_by":"ubuntu"}]}
{"id":"bd-33v","title":"Unit tests: configuration loading + overrides","description":"# Unit tests: configuration loading + overrides\n\n## Goal\nAdd comprehensive tests for configuration discovery, precedence, and error handling\nusing real files/env (no mocks).\n\n## Scope\n- Config file discovery order (project, user, global) and precedence.\n- Env var overrides (PI_CONFIG_PATH, provider keys, session dirs).\n- CLI flag overrides vs config file values.\n- Invalid config handling (malformed JSON/TOML, unknown keys, bad types).\n- Default values when config is missing.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml).\n- Log discovered config paths, chosen winner, and resolved values for key fields.\n- On failure, dump parsed config + override stack (redacted).\n\n## Determinism Requirements\n- Use temp dirs with explicit file contents.\n- No network access; avoid relying on real home dir.\n\n## Files\n- tests/config_loading.rs\n\n## Acceptance Criteria\n- [ ] 15+ config tests\n- [ ] Precedence order validated\n- [ ] Env + CLI overrides validated\n- [ ] Error messages are clear and actionable\n- [ ] Logs include path resolution + resolved values","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T05:45:42.762280782Z","created_by":"ubuntu","updated_at":"2026-02-03T08:34:47.598775641Z","closed_at":"2026-02-03T08:34:47.598700090Z","close_reason":"Added config load tests + load_with_roots refactor","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-33v","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T05:45:42.770190069Z","created_by":"ubuntu"},{"issue_id":"bd-33v","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:45:47.186437739Z","created_by":"ubuntu"}]}
{"id":"bd-346","title":"Workstream: Session Index Integration","description":"# Workstream: Session Index Integration\n\n## Goal\nWire the existing SQLite session index (src/session_index.rs) into the CLI flow\nfor fast session discovery and resumption.\n\n## Background\nThe session index module is fully implemented (360+ lines) but not used:\n- SQLite-based index with WAL mode\n- Fast lookups by path or CWD\n- Session metadata extraction (message count, name, file size, mtime)\n- Atomic operations with file locking\n\nCurrently, session operations scan the filesystem directly, which is slow\nfor users with many sessions.\n\n## Current State\n\n### What Exists (src/session_index.rs)\n```rust\npub struct SessionIndex { db: SqliteConnection }\n\nimpl SessionIndex {\n    pub fn open(path: &Path) -> Result<Self>\n    pub fn index_session(&self, session_path: &Path) -> Result<()>\n    pub fn list_sessions(&self, cwd: Option<&str>) -> Result<Vec<SessionMeta>>\n    pub fn find_recent(&self, cwd: &str) -> Result<Option<SessionMeta>>\n    pub fn reindex_all(&self) -> Result<()>\n}\n\npub struct SessionMeta {\n    pub path: PathBuf,\n    pub cwd: String,\n    pub name: Option<String>,\n    pub message_count: u32,\n    pub created_at: DateTime,\n    pub modified_at: DateTime,\n    pub file_size: u64,\n}\n```\n\n### What's Missing\n1. No calls to `index_session()` after session.persist()\n2. No calls to `list_sessions()` in session picker\n3. No calls to `find_recent()` for --continue flag\n4. No index maintenance hooks\n\n## Implementation Plan\n\n### Phase 1: Wire Index on Session Save\n- After session.persist(), call session_index.index_session()\n- Index path stored at ~/.pi/agent/sessions/index.db\n\n### Phase 2: Use Index for Session Listing\n- --resume flag queries index instead of filesystem walk\n- Session picker uses indexed metadata\n- Much faster for users with 100+ sessions\n\n### Phase 3: Use Index for --continue\n- --continue queries index for most recent by CWD\n- Falls back to filesystem if index empty/stale\n\n### Phase 4: Index Maintenance\n- Background reindex on startup (if stale)\n- Handle deleted sessions (prune index)\n- Handle moved sessions (update paths)\n\n## Success Criteria\n- [ ] Sessions indexed on save\n- [ ] Session picker uses index\n- [ ] --continue uses index\n- [ ] Startup remains fast (<100ms)\n- [ ] Handles index corruption gracefully\n\n## Files Affected\n- src/session_index.rs (already implemented)\n- src/session.rs (add indexing calls)\n- src/session_picker.rs (use index queries)\n- src/main.rs (wire up index)","status":"open","priority":2,"issue_type":"feature","created_at":"2026-02-03T03:38:19.943589682Z","created_by":"ubuntu","updated_at":"2026-02-03T03:38:19.950957211Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-346","depends_on_id":"bd-2qk","type":"parent-child","created_at":"2026-02-03T03:38:19.950924399Z","created_by":"ubuntu"}]}
{"id":"bd-34f","title":"Implement extension policy modes + audit logging","description":"Background:\n- Capability policy is required for safe extension execution.\n\nSteps:\n- Implement strict/prompt/permissive policy modes from EXTENSIONS.md.\n- Add audit log entries for allow/deny decisions (logging spec).\n- Expose configuration in settings.json + CLI overrides if needed.\n\nAcceptance:\n- Policy decisions are enforced and traceable; prompt mode works in interactive TUI.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:21.365624736Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:59.092578403Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-34f","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:37:04.173275502Z","created_by":"ubuntu"},{"issue_id":"bd-34f","depends_on_id":"bd-3d1","type":"blocks","created_at":"2026-02-03T02:36:52.814400559Z","created_by":"ubuntu"},{"issue_id":"bd-34f","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:58:59.092547476Z","created_by":"ubuntu"}]}
{"id":"bd-351","title":"Test coverage baseline + gap matrix (no-mock audit)","description":"Goal:\n- Produce a single, self-contained coverage matrix for all core modules (src/*) showing existing tests, whether they are real (no mocks), and gaps for unit + integration + e2e.\n\nScope:\n- Inventory tests under tests/ and #[cfg(test)] in src/.\n- Mark any mocks/fakes/stubs and explain whether they are acceptable or must be replaced.\n- Map each module to test types: unit, integration, conformance, e2e.\n- Identify missing E2E flows and missing unit coverage hotspots (main.rs, config, compaction, session persistence, provider streaming, TUI, resources, package_manager).\n\nDeliverables:\n- docs/TEST_COVERAGE_MATRIX.md (or similar) with a table and brief narrative.\n- A prioritized list of gaps that feeds into downstream beads.\n\nAcceptance Criteria:\n- Matrix is complete for all src/ modules and tests/ files.\n- Explicitly flags all mock usage + recommended replacement path.\n- Includes a minimal prioritized backlog with rationale.\n\nNotes:\n- Planning/audit only; no functional code changes.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:05.803511426Z","created_by":"ubuntu","updated_at":"2026-02-03T05:10:44.449582192Z","closed_at":"2026-02-03T05:10:44.449520877Z","close_reason":"Completed coverage matrix doc","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-351","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:05.814604761Z","created_by":"ubuntu"}],"comments":[{"id":10,"issue_id":"bd-351","author":"Dicklesworthstone","text":"Started coverage audit. Created docs/TEST_COVERAGE_MATRIX.md with full src/tests inventory, mock audit (MockProvider in tests/rpc_mode.rs), and prioritized gaps (E2E CLI, provider VCR, extensions conformance, session_index/compaction/models, TUI snapshots, HTTP client integration).","created_at":"2026-02-03T05:10:06Z"}]}
{"id":"bd-37a","title":"Implement theme file format and loader","description":"# Implement theme file format and loader\n\n## Goal\nDefine theme JSON schema and implement theme file loading.\n\n## Implementation\n\n### Theme Types (src/theme.rs)\n```rust\nuse serde::{Deserialize, Serialize};\nuse std::path::{Path, PathBuf};\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct Theme {\n    pub name: String,\n    pub version: String,\n    pub colors: ThemeColors,\n    pub syntax: SyntaxColors,\n    pub ui: UiColors,\n}\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ThemeColors {\n    pub foreground: String,\n    pub background: String,\n    pub accent: String,\n    pub success: String,\n    pub warning: String,\n    pub error: String,\n    pub muted: String,\n}\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct SyntaxColors {\n    pub keyword: String,\n    pub string: String,\n    pub number: String,\n    pub comment: String,\n    pub function: String,\n}\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct UiColors {\n    pub border: String,\n    pub selection: String,\n    pub cursor: String,\n}\n```\n\n### Theme Discovery\n```rust\nimpl Theme {\n    pub fn discover_themes() -> Vec<PathBuf> {\n        let mut paths = Vec::new();\n        \n        // Global themes\n        if let Some(home) = dirs::home_dir() {\n            let global = home.join(\".pi/agent/themes\");\n            if global.exists() {\n                paths.extend(glob_json(&global));\n            }\n        }\n        \n        // Project themes\n        let project = PathBuf::from(\".pi/themes\");\n        if project.exists() {\n            paths.extend(glob_json(&project));\n        }\n        \n        paths\n    }\n    \n    pub fn load(path: &Path) -> Result<Self, Error> {\n        let content = fs::read_to_string(path)?;\n        let theme: Theme = serde_json::from_str(&content)?;\n        theme.validate()?;\n        Ok(theme)\n    }\n    \n    pub fn load_by_name(name: &str) -> Result<Self, Error> {\n        // Search discovered themes for matching name\n        for path in Self::discover_themes() {\n            if let Ok(theme) = Self::load(&path) {\n                if theme.name == name {\n                    return Ok(theme);\n                }\n            }\n        }\n        Err(Error::ThemeNotFound(name.to_string()))\n    }\n}\n```\n\n### Validation\n```rust\nimpl Theme {\n    fn validate(&self) -> Result<(), Error> {\n        // Validate all color strings are valid hex\n        self.validate_color(&self.colors.foreground)?;\n        self.validate_color(&self.colors.background)?;\n        // ... etc\n        Ok(())\n    }\n    \n    fn validate_color(s: &str) -> Result<(), Error> {\n        if !s.starts_with('#') || s.len() != 7 {\n            return Err(Error::InvalidColor(s.to_string()));\n        }\n        Ok(())\n    }\n}\n```\n\n### Default Themes\n```rust\nimpl Theme {\n    pub fn dark() -> Self {\n        Self {\n            name: \"dark\".into(),\n            version: \"1.0\".into(),\n            colors: ThemeColors {\n                foreground: \"#d4d4d4\".into(),\n                background: \"#1e1e1e\".into(),\n                accent: \"#007acc\".into(),\n                // ...\n            },\n            // ...\n        }\n    }\n    \n    pub fn light() -> Self {\n        // Light theme defaults\n    }\n}\n```\n\n## Testing\n- Test: Load valid theme JSON\n- Test: Reject invalid JSON\n- Test: Reject invalid colors\n- Test: Discover themes from directories\n- Test: Default themes valid\n\n## Acceptance Criteria\n- [ ] Theme struct defined\n- [ ] JSON loading works\n- [ ] Validation catches bad colors\n- [ ] Discovery finds themes\n- [ ] Default themes exist","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-03T03:39:32.688625521Z","created_by":"ubuntu","updated_at":"2026-02-03T03:39:32.695005031Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-37a","depends_on_id":"bd-22p","type":"parent-child","created_at":"2026-02-03T03:39:32.694986045Z","created_by":"ubuntu"}]}
{"id":"bd-37l","title":"Migrate Anthropic provider to asupersync HTTP","description":"# Migrate Anthropic provider to asupersync HTTP\n\n## Goal\nReplace reqwest usage in src/providers/anthropic.rs with asupersync HTTP client.\n\n## Background\nAnthropic is the most complex provider implementation:\n- Extended thinking support (streaming thinking deltas)\n- Cache control headers (ephemeral caching)\n- Tool use with JSON schema\n- Multiple content block types in responses\n- 748 lines of code, 2 unit tests currently\n\nCurrent reqwest usage (lines to change):\n- Line ~200: reqwest::Client creation\n- Line ~250: client.post(url).json(&request)\n- Line ~280: response.bytes_stream() for SSE\n- Various header handling\n\n## Implementation Steps\n\n1. **Replace Client Creation**\n```rust\n// Before (reqwest)\nlet client = reqwest::Client::new();\n\n// After (asupersync)\nuse crate::http::Client;\nlet client = Client::new()?;\n```\n\n2. **Replace Request Building**\n```rust\n// Before\nlet response = client\n    .post(&url)\n    .header(\"x-api-key\", &api_key)\n    .header(\"anthropic-version\", \"2023-06-01\")\n    .json(&request)\n    .send()\n    .await?;\n\n// After\nlet response = client\n    .post(&url)\n    .header(\"x-api-key\", &api_key)\n    .header(\"anthropic-version\", \"2023-06-01\")\n    .json(&request)\n    .send(&cx)\n    .await?;\n```\n\n3. **Replace SSE Streaming**\n```rust\n// Before (reqwest-eventsource or manual)\nlet mut stream = response.bytes_stream();\nwhile let Some(chunk) = stream.next().await { ... }\n\n// After (asupersync SSE adapter)\nuse crate::http::SseStream;\nlet mut sse = SseStream::new(response);\nwhile let Some(event) = sse.next(&cx).await {\n    match event? { ... }\n}\n```\n\n4. **Update Function Signatures**\n```rust\n// Add Cx parameter to stream()\nasync fn stream(\n    &self,\n    cx: &Cx,  // New parameter\n    context: &Context,\n    options: &StreamOptions,\n) -> Result<...>\n```\n\n## Anthropic-Specific Considerations\n1. **Extended Thinking**: Must handle thinking_start/delta/end events correctly\n2. **Cache Headers**: anthropic-beta header for cache control\n3. **Error Responses**: Parse error JSON from non-2xx responses\n4. **Rate Limiting**: Respect 429 responses with retry-after header\n5. **Content Types**: text, thinking, tool_call blocks in single response\n\n## Dependencies\n- bd-9sa (HTTP client wrapper)\n- bd-pwz (SSE streaming adapter)\n\n## Testing\n- Existing 2 unit tests must still pass\n- Add integration test with mock SSE server\n- Test extended thinking stream parsing\n- Test tool call accumulation\n\n## Files\n- src/providers/anthropic.rs (modify ~50 lines)\n- src/provider.rs (update trait if Cx needed)\n\n## Acceptance Criteria\n- [ ] No reqwest imports in anthropic.rs\n- [ ] All existing tests pass\n- [ ] Streaming works end-to-end\n- [ ] Extended thinking parsing works\n- [ ] Tool calls parsed correctly\n- [ ] Error handling preserved","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-03T03:32:48.745145157Z","created_by":"ubuntu","updated_at":"2026-02-03T03:33:40.622471805Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-37l","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:32:48.751457930Z","created_by":"ubuntu"},{"issue_id":"bd-37l","depends_on_id":"bd-pwz","type":"blocks","created_at":"2026-02-03T03:33:40.622444263Z","created_by":"ubuntu"}]}
{"id":"bd-39u","title":"Unit tests: JS runtime + shims + event loop ordering","description":"Background:\n- JS compatibility requires correct promise/microtask ordering and shim behavior.\n\nSteps:\n- Unit tests for JS event loop tick ordering (microtasks vs hostcall responses).\n- Tests for legacy API shims mapping to hostcalls.\n- Cancellation + timeout behavior tests.\n\nLogging requirements:\n- Tests include trace logs for task ordering and promise resolution sequence.\n\nAcceptance:\n- JS runtime semantics are deterministic and match legacy expectations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:46:34.349194940Z","created_by":"ubuntu","updated_at":"2026-02-03T02:49:39.160954478Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-39u","depends_on_id":"bd-1f5","type":"blocks","created_at":"2026-02-03T02:49:19.505526230Z","created_by":"ubuntu"},{"issue_id":"bd-39u","depends_on_id":"bd-320","type":"blocks","created_at":"2026-02-03T02:49:29.019677126Z","created_by":"ubuntu"},{"issue_id":"bd-39u","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:49:39.160923330Z","created_by":"ubuntu"}]}
{"id":"bd-3ap","title":"Implement TUI state transition tests","description":"# Implement TUI state transition tests\n\n## Goal\nTest the interactive TUI's state machine logic - how it responds to messages\nand user input events.\n\n## Background\nPiApp in src/interactive.rs implements the bubbletea Model trait:\n- init() - Initialize state\n- update(msg) - Handle messages, return commands\n- view() - Render current state\n\nThe update() function is the state machine - it needs thorough testing.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml) for each test.\n- Log initial state, input message, and key state deltas.\n- On failure, dump a compact state diff (selected fields) and the rendered view.\n\n## Test Categories\n\n### 1. Keyboard Input Tests\n```rust\n#[test]\nfn test_escape_quits() {\n    let mut app = create_app();\n    let cmd = app.update(KeyMsg::Escape);\n    assert!(matches!(cmd, Cmd::Quit));\n}\n```\n\n### 2. Agent Event Tests\n- Start/end events toggle streaming\n- Text delta accumulation\n- Tool call lifecycle updates\n\n### 3. Slash Command Tests\n- /help, /model, /thinking, /clear\n\n### 4. Error Handling Tests\n- Error display and clear-on-input behavior\n\n### 5. Viewport/Scrolling Tests\n- Scroll to bottom on new output\n- PageUp/PageDown behavior\n\n## Dependencies\n- bd-1d3 (Snapshot infrastructure for view testing)\n\n## Files\n- tests/tui_state.rs\n\n## Acceptance Criteria\n- [ ] 30+ state transition tests\n- [ ] All key handlers tested\n- [ ] All PiMsg variants tested\n- [ ] All slash commands tested\n- [ ] Error handling tested\n- [ ] Scrolling tested\n- [ ] Logs include inputs + state deltas\n- [ ] All tests pass","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:35:51.898944355Z","created_by":"ubuntu","updated_at":"2026-02-03T05:44:50.533804981Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3ap","depends_on_id":"bd-1d3","type":"blocks","created_at":"2026-02-03T03:40:12.062967668Z","created_by":"ubuntu"},{"issue_id":"bd-3ap","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:35:51.907068784Z","created_by":"ubuntu"},{"issue_id":"bd-3ap","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:44:50.533781367Z","created_by":"ubuntu"}]}
{"id":"bd-3b6","title":"Implement RPC mode + conformance harness","description":"Implement rpc mode per EXISTING_PI_STRUCTURE and legacy rpc.md spec; add fixture-based conformance tests for RPC behavior.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:18:37.270311803Z","created_by":"ubuntu","updated_at":"2026-02-03T02:23:53.378860485Z","compaction_level":0,"original_size":0}
{"id":"bd-3d1","title":"Implement WASM host + WIT hostcalls with capability policy","description":"Background:\n- WASM is the default extension runtime tier; hostcalls must be capability-gated.\n\nSteps:\n- Implement WIT interface from docs/wit/extension.wit.\n- Provide hostcall surface for read/write/exec/http/env with policy checks.\n- Add audit logging for each hostcall decision (allow/deny) using the logging spec.\n- Ensure cancellation + error propagation are deterministic.\n\nAcceptance:\n- A simple WASM extension can register and execute tool calls under policy control.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:23:33.779620874Z","created_by":"ubuntu","updated_at":"2026-02-03T05:27:23.136852183Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3d1","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:57:36.850341113Z","created_by":"ubuntu"},{"issue_id":"bd-3d1","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:35:57.325092538Z","created_by":"ubuntu"},{"issue_id":"bd-3d1","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:57:31.896412281Z","created_by":"ubuntu"}],"comments":[{"id":6,"issue_id":"bd-3d1","author":"Dicklesworthstone","text":"Picking this up now. Plan: implement wasmtime component host for docs/wit/extension.wit, wire host::call to ConnectorDispatcher with policy/logging, enforce memory limits, no tokio usage (asupersync only). Will keep runtime deterministic and add minimal smoke path if possible.","created_at":"2026-02-03T04:19:38Z"},{"id":7,"issue_id":"bd-3d1","author":"Dicklesworthstone","text":"Implemented WASM host runtime behind  feature in src/extensions.rs: component instantiation, host.call wiring to ConnectorDispatcher w/ capability policy + evidence-based expected loss logging, resource limiter, and typed wrappers for init/tool/slash/event/shutdown. Still need Cargo.toml dep + feature once Cargo.toml reservation clears.","created_at":"2026-02-03T04:39:24Z"},{"id":8,"issue_id":"bd-3d1","author":"Dicklesworthstone","text":"Note: prior comment used shell backticks by accident. Summary: implemented WASM host runtime behind a wasmtime feature gate in src/extensions.rs (component instantiation, host.call wiring to ConnectorDispatcher with evidence-based expected-loss logging, resource limiter, init/tool/slash/event/shutdown wrappers). Still need Cargo.toml dependency + feature once reservation clears.","created_at":"2026-02-03T04:39:33Z"},{"id":9,"issue_id":"bd-3d1","author":"Dicklesworthstone","text":"Ran bv triage; continuing bd-3d1. cargo check shows: wasmtime gating errors in src/extensions.rs, unsafe env var usage in src/session.rs, StreamingResponse import + const Path issue in src/vcr.rs. Blocked by reservations on src/extensions.rs/Cargo.toml (CyanBasin) and src/vcr.rs/src/session.rs (TopazForest/MagentaPuma); coordination requested.","created_at":"2026-02-03T04:49:44Z"},{"id":11,"issue_id":"bd-3d1","author":"QuietBear","text":"Removed WASM feature gating in src/extensions.rs (WasmExtensionHost + wasm_host module always on; re-exported WasmExtensionInstance) and made wasmtime dependency non-optional in Cargo.toml (feature removed). Updated rpc options to include extensions (src/main.rs, tests/rpc_mode.rs). Ran: CARGO_TARGET_DIR=/tmp/pi_agent_rust_target cargo check --all-targets (pass), cargo fmt --check (pass). cargo clippy --all-targets -- -D warnings still fails due to pre-existing warnings in agent.rs/config.rs/interactive.rs/extensions.rs. Contact requests sent to OrangeBarn/CyanBasin re file conflicts.","created_at":"2026-02-03T05:27:23Z"}]}
{"id":"bd-3d8","title":"Implement /theme slash command","description":"# Implement /theme slash command\n\n## Goal\nAdd /theme command to list available themes and switch between them.\n\n## Command Syntax\n```\n/theme              - List available themes\n/theme dark         - Switch to dark theme\n/theme ocean-dark   - Switch to custom theme\n```\n\n## Implementation\n\n### Command Handler\n```rust\n// src/interactive.rs\n\nfn handle_theme_command(&mut self, args: &str) -> Cmd {\n    if args.is_empty() {\n        // List themes\n        let themes = Theme::discover_themes();\n        let current = &self.theme.name;\n        \n        let mut output = String::from(\"Available themes:\\n\");\n        for path in themes {\n            if let Ok(theme) = Theme::load(&path) {\n                let marker = if theme.name == *current { \"* \" } else { \"  \" };\n                output.push_str(&format!(\"{}{}\\n\", marker, theme.name));\n            }\n        }\n        output.push_str(\"\\nUse /theme <name> to switch\");\n        \n        self.status_message = Some(output);\n        Cmd::None\n    } else {\n        // Switch theme\n        match Theme::load_by_name(args.trim()) {\n            Ok(theme) => {\n                self.theme = theme.clone();\n                self.styles = create_styles(&theme);\n                self.status_message = Some(format!(\"Switched to theme: {}\", theme.name));\n                \n                // Persist preference\n                if let Err(e) = self.save_theme_preference(&theme.name) {\n                    tracing::warn!(\"Failed to save theme preference: {}\", e);\n                }\n                \n                Cmd::None\n            }\n            Err(_) => {\n                self.status_message = Some(format!(\"Theme not found: {}\", args.trim()));\n                Cmd::None\n            }\n        }\n    }\n}\n```\n\n### Persist Theme Preference\n```rust\nfn save_theme_preference(&self, theme_name: &str) -> Result<()> {\n    // Update settings.json with theme preference\n    let settings_path = Config::settings_path();\n    let mut settings = Config::load_from_file(&settings_path)?;\n    settings.theme = Some(theme_name.to_string());\n    settings.save_to_file(&settings_path)?;\n    Ok(())\n}\n```\n\n### Add to Slash Command Router\n```rust\nfn handle_slash_command(&mut self, input: &str) -> Cmd {\n    let (cmd, args) = parse_slash_command(input);\n    \n    match cmd {\n        \"theme\" => self.handle_theme_command(args),\n        \"help\" => self.handle_help_command(),\n        // ... other commands\n    }\n}\n```\n\n### Update /help Output\n```\nCommands:\n  /help      - Show this help\n  /model     - Switch model\n  /thinking  - Set thinking level\n  /theme     - List/switch themes  <-- NEW\n  /clear     - Clear conversation\n  /exit      - Exit Pi\n```\n\n## Dependencies\n- bd-37a (theme loader)\n- bd-qpm (theme application)\n\n## Testing\n- Test: /theme lists themes\n- Test: /theme <name> switches\n- Test: Theme persists across restarts\n- Test: Invalid theme shows error\n\n## Acceptance Criteria\n- [ ] /theme lists available themes\n- [ ] /theme <name> switches theme\n- [ ] Current theme marked in list\n- [ ] Preference saved to settings\n- [ ] Invalid theme handled gracefully","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-03T03:40:04.810223066Z","created_by":"ubuntu","updated_at":"2026-02-03T03:40:11.743557350Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3d8","depends_on_id":"bd-22p","type":"parent-child","created_at":"2026-02-03T03:40:04.817104772Z","created_by":"ubuntu"},{"issue_id":"bd-3d8","depends_on_id":"bd-qpm","type":"blocks","created_at":"2026-02-03T03:40:11.743531843Z","created_by":"ubuntu"}]}
{"id":"bd-3ie","title":"Resolve UBS hardcoded-secret false positives for api_key usage","description":"UBS flags api_key assignments as hardcoded secrets; decide on renaming or ignore strategy.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-03T01:26:13.673637977Z","created_by":"ubuntu","updated_at":"2026-02-03T01:36:37.565377394Z","closed_at":"2026-02-03T01:36:37.565316170Z","close_reason":"UBS no longer shows hardcoded-secret false positives for api_key - issue may have been fixed in a UBS update or codebase changes","compaction_level":0,"original_size":0}
{"id":"bd-3im","title":"Unit tests: manifest loader + compatibility scan","description":"Background:\n- Manifest parsing and compat decisions drive runtime behavior; bugs are user-facing.\n\nSteps:\n- Unit tests for manifest parsing (valid/invalid, missing fields, unknown fields).\n- Tests for runtime tier selection (WASM/JS/MCP) based on manifest hints + policy.\n- Diagnostics tests (ensure error messages are actionable).\n\nLogging requirements:\n- Tests should capture and assert diagnostic strings for invalid manifests.\n\nAcceptance:\n- Coverage for all manifest fields and compatibility decision branches.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:45:52.022954042Z","created_by":"ubuntu","updated_at":"2026-02-03T07:51:07.742028719Z","closed_at":"2026-02-03T07:51:07.741969218Z","close_reason":"Added integration tests for ExtensionMessage parsing + ExtensionPolicy/hostcall capability mapping","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3im","depends_on_id":"bd-gqf","type":"blocks","created_at":"2026-02-03T02:48:16.633815031Z","created_by":"ubuntu"}]}
{"id":"bd-3ml","title":"Implement verbose test logging infrastructure","description":"# Implement verbose test logging infrastructure\n\n## Goal\nCreate shared infrastructure for detailed logging in all integration tests,\nenabling easy debugging when tests fail.\n\n## Background\nE2E and integration tests need detailed logging to debug failures:\n- Every test action should be logged\n- Timestamps for timing analysis\n- Context (file paths, values) for reproduction\n- Logs dumped automatically on test failure\n\n## Implementation\n\n### Log Infrastructure\n```rust\n// tests/common/logging.rs\n\nuse std::sync::Mutex;\nuse std::time::Instant;\n\n#[derive(Debug, Clone)]\npub struct LogEntry {\n    pub timestamp: Instant,\n    pub level: LogLevel,\n    pub category: &'static str,\n    pub message: String,\n    pub context: Vec<(String, String)>,\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum LogLevel {\n    Debug,\n    Info,\n    Warn,\n    Error,\n}\n\npub struct TestLogger {\n    entries: Mutex<Vec<LogEntry>>,\n    start: Instant,\n}\n```\n\n### Redaction + Artifacts\n- Add helpers to redact sensitive values in env/header/context keys (API keys, auth headers).\n- Add a simple artifact registry: `record_artifact(name, path)` so tests can attach outputs.\n- On panic, dump logs + artifact list (paths) to stderr.\n\n### Test Harness Integration\n```rust\n// tests/common/harness.rs\n\npub struct TestHarness {\n    pub logger: TestLogger,\n    pub temp_dir: TempDir,\n}\n\nimpl Drop for TestHarness {\n    fn drop(&mut self) {\n        if std::thread::panicking() {\n            eprintln!(\"\\n=== TEST LOGS ===\\n{}\", self.logger.dump());\n            eprintln!(\"=== ARTIFACTS ===\\n{}\", self.logger.dump_artifacts());\n        }\n    }\n}\n```\n\n### Optional File Output\n- If `TEST_LOG_PATH` is set, write logs to that path in addition to stderr.\n\n## Files\n- tests/common/mod.rs\n- tests/common/logging.rs\n- tests/common/harness.rs\n\n## Acceptance Criteria\n- [ ] TestLogger captures all levels\n- [ ] Context key-values supported\n- [ ] Timestamps included\n- [ ] Redaction helpers present\n- [ ] Artifact registry present\n- [ ] Auto-dump on test failure\n- [ ] Optional file output works\n- [ ] All integration tests use harness","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-03T03:40:54.070756084Z","created_by":"ubuntu","updated_at":"2026-02-03T05:48:33.124493922Z","closed_at":"2026-02-03T05:48:33.124430233Z","close_reason":"Implemented redaction helpers, artifact registry + dump, and TEST_LOG_PATH file output in test logging; harness now dumps artifacts on panic and provides record_artifact. Acceptance criteria satisfied.","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3ml","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:40:54.080417065Z","created_by":"ubuntu"}],"comments":[{"id":16,"issue_id":"bd-3ml","author":"QuietBear","text":"Reviewed existing tests/common logger/harness: core logging already present but missing redaction, artifact registry, and TEST_LOG_PATH dump. Implementing those now in tests/common/logging.rs + tests/common/harness.rs (record_artifact, dump_artifacts, redaction helper, env-based file output, artifact dump on panic).","created_at":"2026-02-03T05:48:22Z"}]}
{"id":"bd-3nz","title":"Wire session indexing into session.persist()","description":"# Wire session indexing into session.persist()\n\n## Goal\nAutomatically update the SQLite index when sessions are saved.\n\n## Implementation\n\n### Add Index Update to persist()\n```rust\n// src/session.rs\n\nimpl Session {\n    pub async fn persist(&self, path: &Path) -> Result<()> {\n        // Existing JSONL write logic\n        self.write_jsonl(path).await?;\n        \n        // NEW: Update index\n        if let Ok(index) = SessionIndex::open_default() {\n            if let Err(e) = index.index_session(path) {\n                // Log warning but don't fail persist\n                tracing::warn!(\"Failed to update session index: {}\", e);\n            }\n        }\n        \n        Ok(())\n    }\n}\n```\n\n### Default Index Path\n```rust\n// src/session_index.rs\n\nimpl SessionIndex {\n    pub fn open_default() -> Result<Self> {\n        let path = dirs::data_dir()\n            .unwrap_or_else(|| PathBuf::from(\".\"))\n            .join(\".pi/agent/sessions/index.db\");\n        Self::open(&path)\n    }\n}\n```\n\n### Handle Index Creation\n- Create index.db if not exists\n- Use WAL mode for concurrent access\n- Handle permission errors gracefully\n\n## Considerations\n1. **Performance**: Index update should be fast (<10ms)\n2. **Reliability**: Don't fail persist if index fails\n3. **Concurrency**: Handle multiple pi instances\n4. **Migration**: Handle existing sessions without index entries\n\n## Testing\n- Test: persist() updates index\n- Test: persist() succeeds even if index fails\n- Test: Index contains session after persist\n\n## Acceptance Criteria\n- [ ] persist() calls index_session()\n- [ ] Index created if not exists\n- [ ] Errors logged but don't fail persist\n- [ ] Performance impact <10ms","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-03T03:38:32.093344392Z","created_by":"ubuntu","updated_at":"2026-02-03T04:40:58.620167946Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3nz","depends_on_id":"bd-346","type":"parent-child","created_at":"2026-02-03T03:38:32.099125014Z","created_by":"ubuntu"}]}
{"id":"bd-3on","title":"Implement legacy capture pipeline (run + record outputs)","description":"Background:\n- We need golden fixtures from legacy pi for each scenario.\n\nSteps:\n- Build a capture runner that executes scenarios and records raw outputs (stdout/stderr, JSON results).\n- Record metadata: pi-mono commit, extension version, environment snapshot.\n- Ensure the runner can be re-run deterministically.\n- Emit structured capture logs per the logging spec for traceability.\n\nAcceptance:\n- For a small pilot subset, the capture output is repeatable and complete.\n- Logs enable debugging without rerunning capture.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:37.848853767Z","created_by":"ubuntu","updated_at":"2026-02-03T08:03:43.982680780Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3on","depends_on_id":"bd-2qd","type":"blocks","created_at":"2026-02-03T02:35:06.569454464Z","created_by":"ubuntu"},{"issue_id":"bd-3on","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:58:45.777576081Z","created_by":"ubuntu"},{"issue_id":"bd-3on","depends_on_id":"bd-7l6","type":"blocks","created_at":"2026-02-03T02:34:48.585575300Z","created_by":"ubuntu"},{"issue_id":"bd-3on","depends_on_id":"bd-u4r","type":"blocks","created_at":"2026-02-03T02:34:59.235697095Z","created_by":"ubuntu"}]}
{"id":"bd-3oq","title":"Workstream: legacy pi reference capture complete","description":"Purpose:\n- Run the *legacy* pi agent extension system and capture outputs for each sampled extension to create golden fixtures.\n\nOutputs (artifacts):\n- Deterministic capture runner and environment settings.\n- Golden JSON fixtures per extension (tools, slash commands, events).\n- Capture log + provenance (pi-mono commit, dependency versions, timestamps).\n\nDefinition of done:\n- Every sampled extension has reference outputs captured for its supported behaviors.\n- Fixtures are normalized and reproducible.\n- Capture methodology documented so it can be repeated later.\n\nDependencies:\n- Requires finalized sample list + archived artifacts.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:19:54.749923176Z","created_by":"ubuntu","updated_at":"2026-02-03T02:41:14.457295080Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3oq","depends_on_id":"bd-16n","type":"blocks","created_at":"2026-02-03T02:29:15.561118322Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-1oz","type":"blocks","created_at":"2026-02-03T02:29:05.470187289Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-29c","type":"blocks","created_at":"2026-02-03T02:41:14.457267759Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-2qd","type":"blocks","created_at":"2026-02-03T02:28:48.062075981Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-3on","type":"blocks","created_at":"2026-02-03T02:28:56.287437343Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-7l6","type":"blocks","created_at":"2026-02-03T02:28:26.716944160Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-u4r","type":"blocks","created_at":"2026-02-03T02:28:34.410022362Z","created_by":"ubuntu"},{"issue_id":"bd-3oq","depends_on_id":"bd-vbs","type":"blocks","created_at":"2026-02-03T02:29:24.772659253Z","created_by":"ubuntu"}]}
{"id":"bd-3qo","title":"Test infra: mock services + secrets redaction for deterministic runs","description":"Background:\n- Extensions often touch network/secrets; tests must be deterministic and safe.\n\nSteps:\n- Provide mock HTTP server with canned responses for networked extensions.\n- Define secrets injection strategy (env vars + redaction in logs).\n- Add helpers to create isolated temp workspaces per scenario.\n- Provide deterministic time and random seeds for repeatable runs.\n\nLogging requirements:\n- Logs must redact secrets and include mock server request traces.\n\nAcceptance:\n- Tests run offline with deterministic outputs and safe logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:47:27.653755790Z","created_by":"ubuntu","updated_at":"2026-02-03T08:35:06.270356554Z","closed_at":"2026-02-03T08:35:06.270295750Z","close_reason":"Implemented deterministic TestEnv + MockHttpServer (offline), secret redaction, and harness helpers","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3qo","depends_on_id":"bd-7l6","type":"blocks","created_at":"2026-02-03T02:59:10.172932583Z","created_by":"ubuntu"},{"issue_id":"bd-3qo","depends_on_id":"bd-u4r","type":"blocks","created_at":"2026-02-03T02:59:03.761035897Z","created_by":"ubuntu"}]}
{"id":"bd-3rr","title":"Acquire extension artifacts + checksums (archive)","description":"Background:\n- Conformance must be reproducible offline; store artifacts and checksums.\n\nSteps:\n- Download or export each extension artifact as specified in the manifest.\n- Compute checksums (sha256) and record them in the manifest.\n- Store artifacts in a dedicated fixtures directory; respect license policy (hash-only if restricted).\n\nAcceptance:\n- Every selected extension has a checksum recorded.\n- Artifacts are archived or hash-only per policy.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:21:52.812780208Z","created_by":"ubuntu","updated_at":"2026-02-03T06:36:45.487971144Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3rr","depends_on_id":"bd-2wo","type":"blocks","created_at":"2026-02-03T02:34:25.845524630Z","created_by":"ubuntu"},{"issue_id":"bd-3rr","depends_on_id":"bd-ic9","type":"blocks","created_at":"2026-02-03T02:34:16.852084061Z","created_by":"ubuntu"}]}
{"id":"bd-3s2","title":"Implement normalization + diff rules for harness","description":"Background:\n- Minor non-determinism must be normalized without hiding real mismatches.\n\nSteps:\n- Implement normalization transforms (paths, timestamps, randomness, ANSI).\n- Provide per-fixture override rules if needed.\n- Ensure diffs highlight semantic changes, not noise.\n- Add golden normalization fixtures to prevent regressions.\n\nLogging requirements:\n- Normalization should emit trace logs in test mode for debugging diffs.\n\nAcceptance:\n- Fixture diffs are stable and actionable across reruns.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:52.984753311Z","created_by":"ubuntu","updated_at":"2026-02-03T07:36:13.855756425Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-3s2","depends_on_id":"bd-yd9","type":"blocks","created_at":"2026-02-03T02:37:34.653870325Z","created_by":"ubuntu"}]}
{"id":"bd-3so","title":"Logging spec: structured logs + correlation IDs for extensions","description":"Background:\n- Capture/harness/runtime logs must be consistent, searchable, and safe.\n\nSteps:\n- Define a structured JSON log schema for extension execution (fields + types).\n- Standardize correlation IDs (extension id, scenario id, tool/command/event id).\n- Specify redaction rules for secrets/PII and normalization for tests.\n- Document where logs are emitted and how to consume them in CI.\n\nAcceptance:\n- Extension-related logs across capture/harness/runtime follow the schema.\n- Deterministic logs enable fixture diffs and triage.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:47:40.485700214Z","created_by":"ubuntu","updated_at":"2026-02-03T03:07:34.207573243Z","closed_at":"2026-02-03T03:07:34.207512710Z","close_reason":"Structured log schema + correlation IDs documented; protocol + Rust types aligned","compaction_level":0,"original_size":0}
{"id":"bd-3tu","title":"Crates publishing workflow for pi_agent_rust + libs","description":"Add crates.io publish workflows/metadata for pi_agent_rust, asupersync, rich_rust, charmed_rust; plan migration from path deps to versioned crates.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:18:50.598149638Z","created_by":"ubuntu","updated_at":"2026-02-03T02:18:50.598149638Z","compaction_level":0,"original_size":0}
{"id":"bd-576","title":"Align extension protocol schema + Rust types with legacy","description":"Background:\n- The schema and Rust types must faithfully represent legacy protocol behavior.\n\nSteps:\n- Compare docs/schema/extension_protocol.json + docs/wit/extension.wit to legacy behavior.\n- Identify missing fields or mismatched semantics.\n- Update Rust types and validators to match the legacy protocol (no breaking changes).\n\nAcceptance:\n- Protocol messages round-trip correctly and validate against the schema.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:23:14.647850470Z","created_by":"ubuntu","updated_at":"2026-02-03T03:57:48.128206644Z","closed_at":"2026-02-03T03:57:48.128142655Z","close_reason":"Schema/types aligned to legacy extension API","compaction_level":0,"original_size":0,"comments":[{"id":2,"issue_id":"bd-576","author":"Dicklesworthstone","text":"Aligned extension protocol schema + Rust types: added ToolSpec/SlashCommandSpec, ToolContent (text/image), ExtensionEventName enum. Updated validation + register parsing test. Checks run: cargo check/clippy/fmt still failing due to existing http/asupersync and formatting issues unrelated to this bead.","created_at":"2026-02-03T03:57:31Z"}]}
{"id":"bd-7al","title":"Implement Rust extension conformance runner (exec + diff)","description":"Background:\n- The harness must run extensions under the Rust runtime and compare to fixtures.\n\nSteps:\n- Build runner that loads extension artifacts and executes scenarios.\n- Compare outputs to fixture expectations with clear diffs + normalization.\n- Emit per-case pass/fail with context and structured logs.\n\nLogging requirements:\n- Logs must follow the logging spec and include fixture IDs.\n\nAcceptance:\n- Running `cargo test` executes the harness and reports failures meaningfully.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:44.064207426Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:55.052282685Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-7al","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T02:37:24.460271765Z","created_by":"ubuntu"},{"issue_id":"bd-7al","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-03T02:58:55.052253491Z","created_by":"ubuntu"},{"issue_id":"bd-7al","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:58:51.011258841Z","created_by":"ubuntu"},{"issue_id":"bd-7al","depends_on_id":"bd-yd9","type":"blocks","created_at":"2026-02-03T02:37:16.948809733Z","created_by":"ubuntu"}]}
{"id":"bd-7cs","title":"Bench: extension connector dispatch overhead","description":"Background:\n- Connector dispatch overhead is a critical latency path for extension tool calls.\n\nSteps:\n- Add Criterion benchmarks for hostcall dispatch, event-loop tick, and policy decision overhead.\n- Include cold vs warm cache scenarios and varying payload sizes.\n- Report p50/p95/p99 with budgets from bd-1ii.\n\nLogging requirements:\n- Bench output must include hardware profile and config hash.\n\nAcceptance:\n- Benchmarks run via `cargo bench` and produce stable numbers.\n- Regressions are detectable vs budgets.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:24:44.769218734Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:16.114299Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-7cs","depends_on_id":"bd-1ii","type":"blocks","created_at":"2026-02-03T02:58:16.114273422Z","created_by":"ubuntu"},{"issue_id":"bd-7cs","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:25:17.392303657Z","created_by":"ubuntu"}]}
{"id":"bd-7l6","title":"Set up legacy pi-mono extension runner (pinned)","description":"Background:\n- We must capture reference outputs from the original implementation.\n\nSteps:\n- Pin pi-mono commit and dependency versions used for capture.\n- Verify extension tooling and sample installation workflow.\n- Document exact commands to run captures.\n\nAcceptance:\n- A pinned legacy environment can be recreated reliably.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:04.994412150Z","created_by":"ubuntu","updated_at":"2026-02-03T05:35:06.243003159Z","closed_at":"2026-02-03T05:35:06.242941915Z","close_reason":"Pinned legacy runner and capture commands documented","compaction_level":0,"original_size":0,"comments":[{"id":14,"issue_id":"bd-7l6","author":"Dicklesworthstone","text":"Created docs/LEGACY_EXTENSION_RUNNER.md with pinned pi-mono commit (df5b0f76...), Node>=20, npm ci/build steps, pi-test.sh usage, extension loading + package install commands, and capture workflow.","created_at":"2026-02-03T05:34:54Z"}]}
{"id":"bd-9sa","title":"Implement asupersync HTTP client wrapper","description":"# Implement asupersync HTTP client wrapper\n\n## Goal\nCreate a functional HTTP client in src/http/client.rs using asupersync APIs.\n\n## Current State\nsrc/http/client.rs has:\n- Client struct (empty)\n- RequestBuilder struct with method/url/headers/body\n- RequestBuilder::send() returns Err(\"asupersync HTTP client not yet implemented\")\n- RequestBuilder::json() silently ignores serialization errors\n\n## Implementation Requirements\n\n### Client API\n```rust\nuse asupersync::{Cx, http::client::HttpClient};\nuse asupersync::tls::TlsConnectorBuilder;\n\npub struct Client {\n    inner: HttpClient,\n}\n\nimpl Client {\n    pub fn new() -> Result<Self, Error> {\n        // Create TLS connector with native roots\n        let tls = TlsConnectorBuilder::new()\n            .with_native_roots()?\n            .build()?;\n        let inner = HttpClient::new(tls);\n        Ok(Self { inner })\n    }\n    \n    pub fn request(&self, method: Method, url: &str) -> RequestBuilder {\n        RequestBuilder::new(self, method, url)\n    }\n    \n    pub fn get(&self, url: &str) -> RequestBuilder { ... }\n    pub fn post(&self, url: &str) -> RequestBuilder { ... }\n}\n```\n\n### RequestBuilder API\n```rust\nimpl RequestBuilder {\n    pub fn header(mut self, key: &str, value: &str) -> Self { ... }\n    pub fn json<T: Serialize>(mut self, body: &T) -> Self { ... }\n    pub fn body(mut self, bytes: Vec<u8>) -> Self { ... }\n    pub fn timeout(mut self, duration: Duration) -> Self { ... }\n    \n    pub async fn send(self, cx: &Cx) -> Result<Response, Error> {\n        // Actually send the request using asupersync\n    }\n}\n```\n\n### Response API\n```rust\npub struct Response {\n    status: StatusCode,\n    headers: Headers,\n    body: BodyReader,  // Async streaming body\n}\n\nimpl Response {\n    pub fn status(&self) -> StatusCode { ... }\n    pub fn headers(&self) -> &Headers { ... }\n    pub async fn text(self, cx: &Cx) -> Result<String, Error> { ... }\n    pub async fn json<T: DeserializeOwned>(self, cx: &Cx) -> Result<T, Error> { ... }\n    pub fn bytes_stream(self) -> impl Stream<Item = Result<Bytes, Error>> { ... }\n}\n```\n\n## Key Considerations\n1. **TLS**: Use rustls with native root certificates (no openssl)\n2. **Timeout**: Support per-request timeout via asupersync Budget\n3. **Streaming**: Response body must support async streaming for SSE\n4. **Headers**: Support standard headers (Content-Type, Authorization, etc.)\n5. **Error handling**: Wrap asupersync errors in pi's Error type\n\n## Testing\n- Unit test: Client creation succeeds\n- Unit test: RequestBuilder builds correct request\n- Integration test: GET request to httpbin.org/get\n- Integration test: POST with JSON body\n- Integration test: Timeout behavior\n\n## Files\n- src/http/client.rs (modify)\n- src/http/mod.rs (update re-exports)\n- src/error.rs (add HTTP error variants)\n\n## Acceptance Criteria\n- [ ] Client::new() creates working HTTP client\n- [ ] GET/POST requests work\n- [ ] JSON body serialization works\n- [ ] Response streaming works\n- [ ] Timeout respected\n- [ ] TLS verification works\n- [ ] All unit tests pass","status":"in_progress","priority":0,"issue_type":"task","created_at":"2026-02-03T03:32:01.120130883Z","created_by":"ubuntu","updated_at":"2026-02-03T04:05:06.102723720Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-9sa","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:32:01.127860687Z","created_by":"ubuntu"}],"comments":[{"id":1,"issue_id":"bd-9sa","author":"AmberForest","text":"Taking this bead: implement asupersync HTTP client wrapper (no tokio/reqwest). Will wire streaming + TLS + timeout per spec.","created_at":"2026-02-03T03:45:33Z"},{"id":3,"issue_id":"bd-9sa","author":"AmberForest","text":"Implemented asupersync HTTP wrapper updates (Cx-aware send + timeout + StatusCode + bytes_stream). Migrated auth + npm registry calls to wrapper with Cx::for_request. Added http module re-exports.","created_at":"2026-02-03T04:05:06Z"}]}
{"id":"bd-ah1","title":"Implement session persistence cycle tests","description":"# Implement session persistence cycle tests\n\n## Goal\nTest the full session lifecycle: create → save → reload → verify integrity, with detailed logs.\n\n## Background\nSession persistence involves:\n- JSONL file format (one JSON object per line)\n- Header with metadata (version, cwd, timestamp)\n- Message entries with parent/child relationships\n- Tree structure for conversation branching\n- File locking for concurrent access\n\nCurrent tests cover serialization but not full I/O cycles.\n\n## Runtime + Determinism\n- Do not introduce new tokio-only tests; use `#[asupersync::test]` or a runtime wrapper.\n- Use temp dirs and deterministic paths; avoid asserting exact timestamps.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml).\n- Log session path, header fields, message IDs, tree shape, and file sizes.\n- On failure, dump the JSONL contents (redacted) and parsed header.\n\n## Test Categories\n\n### 1. Basic Persistence Cycle Tests\n```rust\n#[asupersync::test]\nasync fn test_session_save_and_reload() {\n    let temp = TempDir::new().unwrap();\n    let session_path = temp.path().join(\"test.jsonl\");\n\n    let mut session = Session::new(\"/project/path\");\n    session.add_user_message(\"Hello\");\n    session.add_assistant_message(\"Hi there!\");\n\n    session.persist(&session_path).await.unwrap();\n\n    let loaded = Session::load(&session_path).await.unwrap();\n    assert_eq!(loaded.messages().len(), 2);\n}\n```\n\n### 2. Tree Structure Persistence Tests\n```rust\n#[asupersync::test]\nasync fn test_branching_persists() {\n    let temp = TempDir::new().unwrap();\n    let session_path = temp.path().join(\"test.jsonl\");\n\n    let mut session = Session::new(\"/project\");\n    let root_id = session.add_user_message(\"Root\");\n    session.add_assistant_message(\"Branch A\");\n\n    session.navigate_to(root_id.clone());\n    session.add_assistant_message(\"Branch B\");\n\n    session.persist(&session_path).await.unwrap();\n\n    let loaded = Session::load(&session_path).await.unwrap();\n    let children = loaded.children_of(&root_id);\n    assert_eq!(children.len(), 2);\n}\n```\n\n### 3. Header Metadata Tests\n```rust\n#[asupersync::test]\nasync fn test_header_metadata_preserved() {\n    let temp = TempDir::new().unwrap();\n    let session_path = temp.path().join(\"test.jsonl\");\n\n    let mut session = Session::new(\"/my/project/path\");\n    session.set_provider(\"anthropic\");\n    session.set_model(\"claude-opus-4\");\n    session.set_thinking_level(ThinkingLevel::High);\n    session.persist(&session_path).await.unwrap();\n\n    let loaded = Session::load(&session_path).await.unwrap();\n    assert_eq!(loaded.cwd(), \"/my/project/path\");\n}\n```\n\n### 4. Entry Type Persistence Tests\n- ModelChange entries\n- ThinkingLevel entries\n- Compaction entries\n- Tool invocation entries (if serialized)\n\n### 5. Error Handling Tests\n- Missing file\n- Corrupted JSONL\n- Partial corruption (valid header + bad line)\n\n### 6. Concurrent Access Tests\n```rust\n#[asupersync::test]\nasync fn test_concurrent_writes_locked() {\n    let temp = TempDir::new().unwrap();\n    let session_path = temp.path().join(\"test.jsonl\");\n\n    let session1 = Session::new(\"/project\");\n    session1.persist(&session_path).await.unwrap();\n\n    let path = session_path.clone();\n    let handle1 = spawn(async move {\n        let mut s = Session::load(&path).await.unwrap();\n        s.add_user_message(\"From task 1\");\n        s.persist(&path).await\n    });\n\n    let path = session_path.clone();\n    let handle2 = spawn(async move {\n        let mut s = Session::load(&path).await.unwrap();\n        s.add_user_message(\"From task 2\");\n        s.persist(&path).await\n    });\n\n    let (r1, r2) = join(handle1, handle2);\n    assert!(r1.unwrap().is_ok() || r2.unwrap().is_ok());\n}\n```\n\n### 7. Directory Structure Tests\n- Persist creates nested directories when needed\n\n## Dependencies\nNone (uses existing session module)\n\n## Files\n- tests/session_persistence.rs\n\n## Acceptance Criteria\n- [ ] 15+ session persistence tests\n- [ ] Save/reload cycle tested\n- [ ] Tree structure preserved\n- [ ] All entry types tested\n- [ ] Error handling tested\n- [ ] Concurrent access tested\n- [ ] Logs include paths + header fields\n- [ ] All tests pass","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-03T03:38:00.745045518Z","created_by":"ubuntu","updated_at":"2026-02-03T07:33:57.212399249Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-ah1","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:38:00.753607302Z","created_by":"ubuntu"},{"issue_id":"bd-ah1","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:44:12.670095866Z","created_by":"ubuntu"}]}
{"id":"bd-doi","title":"Coverage tooling + CI gating (llvm-cov)","description":"Goal:\n- Add repeatable coverage tooling (llvm-cov) and CI gating that enforces agreed coverage thresholds and the no-mock policy.\n\nWhy this matters:\n- Coverage is only meaningful if it reflects real behavior (no mocks) and is stable in CI.\n- We need artifacts + logs to debug coverage regressions quickly.\n\nScope:\n- Choose tool (cargo llvm-cov preferred) and pin exact command(s).\n- Add local + CI commands for coverage runs (text + optional HTML).\n- Define thresholds (overall + per-module if feasible) based on bd-351 output.\n- Force VCR playback in CI (no network) and ensure secrets are redacted.\n- Emit detailed logging for coverage runs (command, env, duration, artifacts).\n\nDeliverables:\n- Documented coverage command in README/CONFORMANCE.md or docs/testing.\n- CI step that fails when coverage drops below threshold.\n- Coverage artifacts (summary + HTML) and logs stored as CI artifacts.\n\nAcceptance Criteria:\n- Running the coverage command locally produces a report without network calls.\n- CI fails on threshold breach and passes with current baseline.\n- Logs clearly show command, env (redacted), duration, artifact paths, and summary.\n- No mocks/fakes are used to raise coverage (enforced by policy check).\n\nDependencies:\n- Uses bd-351 coverage matrix for thresholds/scope.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T04:58:14.468787870Z","created_by":"ubuntu","updated_at":"2026-02-03T08:37:33.106372716Z","closed_at":"2026-02-03T08:37:33.106312804Z","close_reason":"Coverage baseline captured; CI gate set to 30%","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-doi","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:58:14.476592506Z","created_by":"ubuntu"},{"issue_id":"bd-doi","depends_on_id":"bd-351","type":"blocks","created_at":"2026-02-03T04:59:38.905246954Z","created_by":"ubuntu"}]}
{"id":"bd-gi3","title":"Workstream: HTTP Migration to asupersync","description":"# Workstream: HTTP Migration to asupersync\n\n## Goal\nReplace reqwest + tokio with asupersync HTTP client across all providers, enabling:\n- Structured concurrency with cancel-correct operations\n- Deterministic testing via LabRuntime\n- Removal of tokio dependency (smaller binary, simpler runtime)\n- Unified HTTP/TLS/SQLite stack from asupersync\n\n## Background\nasupersync is a sibling library at ../asupersync providing:\n- Capability-based context (Cx) for async operations\n- Built-in HTTP client with rustls TLS\n- Structured cancellation (no orphaned futures)\n- Deterministic LabRuntime for testing\n\nCurrently, pi_agent_rust has:\n- src/http/mod.rs - Module stub\n- src/http/client.rs - RequestBuilder that returns \"not implemented\" error\n- src/http/sse.rs - SSE parser ready for integration\n- All 4 providers (Anthropic, OpenAI, Gemini, Azure) use reqwest directly\n\n## Technical Approach\n1. Implement asupersync HTTP client wrapper in src/http/client.rs\n2. Create SSE streaming adapter using existing src/http/sse.rs parser\n3. Migrate Anthropic provider first (most complex, has extended thinking)\n4. Migrate remaining providers (OpenAI, Gemini, Azure)\n5. Remove reqwest + tokio dependencies from Cargo.toml\n6. Update all async code to use Cx context\n\n## Dependencies\n- asupersync must compile (currently has 3 unused import warnings, otherwise OK)\n- SSE parser (src/sse.rs) already exists and is well-tested (9 tests)\n\n## Success Criteria\n- [ ] All HTTP requests go through asupersync client\n- [ ] SSE streaming works for all providers\n- [ ] tokio removed from Cargo.toml\n- [ ] reqwest removed from Cargo.toml\n- [ ] Tests pass with deterministic LabRuntime\n- [ ] No performance regression (benchmark streaming throughput)\n\n## Risks\n- asupersync HTTP API may differ from reqwest\n- TLS certificate handling may need attention\n- Streaming may have subtle behavior differences\n\n## Files Affected\n- src/http/mod.rs\n- src/http/client.rs\n- src/http/sse.rs\n- src/providers/anthropic.rs\n- src/providers/openai.rs\n- src/providers/gemini.rs\n- src/providers/azure.rs\n- Cargo.toml","status":"open","priority":0,"issue_type":"feature","created_at":"2026-02-03T03:31:41.845664872Z","created_by":"ubuntu","updated_at":"2026-02-03T03:31:41.852370167Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-gi3","depends_on_id":"bd-2qk","type":"parent-child","created_at":"2026-02-03T03:31:41.852346893Z","created_by":"ubuntu"}]}
{"id":"bd-gqf","title":"Implement extension manifest loader + compatibility scan","description":"Background:\n- The runtime must interpret extension.json and determine how to run each extension.\n\nSteps:\n- Parse manifest fields (name, version, entrypoints, capabilities, runtime hints).\n- Validate against schema and emit actionable diagnostics.\n- Decide runtime tier (WASM/JS/MCP) per manifest + policy.\n\nAcceptance:\n- Invalid manifests fail fast with clear errors; valid ones map to a runtime plan.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:23:24.816332375Z","created_by":"ubuntu","updated_at":"2026-02-03T04:28:59.514230602Z","closed_at":"2026-02-03T04:28:59.514158708Z","close_reason":"Completed","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-gqf","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:35:48.941976469Z","created_by":"ubuntu"}]}
{"id":"bd-gx1","title":"Enumerate sources + build raw candidate extension list","description":"Background:\n- We need a broad candidate pool before sampling.\n\nSteps (document results):\n- Identify sources: official pi docs, pi-mono examples, GitHub repos, npm packages, community lists.\n- Capture candidate metadata (name, repo URL, package name, last update, declared capabilities).\n- Note any duplicates or forks.\n\nOutput:\n- A raw candidate list (not yet filtered) with metadata sufficient for sampling.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:20:56.490314686Z","created_by":"ubuntu","updated_at":"2026-02-03T06:01:46.598725958Z","closed_at":"2026-02-03T06:01:46.598664503Z","close_reason":"Updated EXTENSION_CANDIDATES.md with new sources + gist candidates","compaction_level":0,"original_size":0,"comments":[{"id":12,"issue_id":"bd-gx1","author":"Dicklesworthstone","text":"Created docs/EXTENSION_CANDIDATES.md with raw candidate list + sources + inferred metadata. Includes pi-mono example extensions, badlogic gists, and community/npm candidates (agentsbox, pi-doom).","created_at":"2026-02-03T05:30:19Z"},{"id":13,"issue_id":"bd-gx1","author":"Dicklesworthstone","text":"Added repo-local .pi/extensions candidates to docs/EXTENSION_CANDIDATES.md (diff.ts, files.ts, prompt-url-widget.ts, redraws.ts).","created_at":"2026-02-03T05:34:17Z"}]}
{"id":"bd-gz6","title":"E2E: extension install/update workflow (package sources)","description":"Background:\n- Users install/update extensions via package sources; we must validate this end-to-end.\n\nSteps:\n- Install the sample extensions from their package sources (local + remote) using the CLI.\n- Verify discovery and manifest resolution post-install.\n- Run a minimal scenario per extension (tool or command) to confirm wiring.\n- Capture stdout/stderr and structured logs per extension.\n\nLogging requirements:\n- Logs must include extension id, install source, version, and scenario id.\n\nAcceptance:\n- Full install/update workflow succeeds with deterministic logs and actionable failures.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:05:16.740536695Z","created_by":"ubuntu","updated_at":"2026-02-03T03:06:24.274350171Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-gz6","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-03T03:06:03.004110192Z","created_by":"ubuntu"},{"issue_id":"bd-gz6","depends_on_id":"bd-2i5","type":"blocks","created_at":"2026-02-03T03:06:24.274326557Z","created_by":"ubuntu"},{"issue_id":"bd-gz6","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-03T03:06:15.195816015Z","created_by":"ubuntu"},{"issue_id":"bd-gz6","depends_on_id":"bd-3rr","type":"blocks","created_at":"2026-02-03T03:06:11.319254630Z","created_by":"ubuntu"},{"issue_id":"bd-gz6","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T03:06:20.170559538Z","created_by":"ubuntu"},{"issue_id":"bd-gz6","depends_on_id":"bd-ic9","type":"blocks","created_at":"2026-02-03T03:06:07.339928303Z","created_by":"ubuntu"}]}
{"id":"bd-h04","title":"Extensions: connector dispatcher + capability policy","description":"Background:\n- Connector dispatcher is the security boundary for all extension runtimes (WASM/JS).\n- It defines the canonical host_call/host_result protocol and enforces capability policy.\n\nScope:\n- Implement dispatcher core, capability checks, error mapping, and structured audit logging per the logging spec.\n- Provide hooks for policy modes (strict/prompt/permissive) and test harness instrumentation.\n\nSteps:\n- Define connector message types + validation; map to internal tool/command/env/fs/http calls.\n- Implement allow/deny decision flow with reason codes; enforce timeouts + cancellation (asupersync).\n- Emit structured logs (correlation IDs, capability, decision, elapsed).\n- Provide deterministic test hooks/mocks for unit + conformance tests.\n\nAcceptance:\n- All hostcalls route through the dispatcher with consistent policy enforcement.\n- Logs follow the extension logging schema and redact secrets.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:23:49.329723505Z","created_by":"ubuntu","updated_at":"2026-02-03T04:14:35.827372808Z","closed_at":"2026-02-03T04:14:35.827308398Z","close_reason":"Dispatcher: policy enforcement, timeout handling, redacted logging, test hooks","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-h04","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:57:23.511568828Z","created_by":"ubuntu"}],"comments":[{"id":4,"issue_id":"bd-h04","author":"Dicklesworthstone","text":"Implemented hostcall timeouts + redaction + deterministic log overrides in connector dispatcher. Added  overrides (time/host/pid), redacts sensitive keys in log payloads, adds host_call timeout handling with , and includes timeout metadata in logs. No tokio usage added.","created_at":"2026-02-03T04:14:20Z"},{"id":5,"issue_id":"bd-h04","author":"Dicklesworthstone","text":"Dispatcher update: added hostcall timeout handling, log redaction for sensitive keys, and deterministic log overrides via DispatchContext time/host/pid fields. Logs include timeout metadata; no tokio usage added.","created_at":"2026-02-03T04:14:29Z"}]}
{"id":"bd-hqq","title":"Unit tests: compaction pipeline + summary invariants","description":"# Unit tests: compaction pipeline + summary invariants\n\n## Goal\nAdd comprehensive tests for compaction logic to ensure summaries are correct,\nmessage windows are respected, and session invariants hold — without mocks.\n\n## Scope\n- Compaction window selection (token budget, message count, system prompt rules).\n- Summary insertion semantics (where summary is injected, ordering preserved).\n- Handling of tool calls, thinking blocks, and image/content blocks.\n- Edge cases: tiny budgets, already-compacted sessions, empty assistant response.\n- Session integrity: parent/child IDs, current leaf, and compaction entry metadata.\n\n## Logging Requirements\n- Use TestLogger (bd-3ml).\n- Log input message count, token budget, selected span indices, and summary length.\n- On failure, dump the compacted timeline (message IDs + types + brief text).\n\n## Determinism Requirements\n- Use fixed fixtures for token counts and message content (no randomness).\n- No network usage; temp dirs only if persistence is exercised.\n\n## Files\n- tests/compaction.rs\n\n## Acceptance Criteria\n- [ ] 15+ compaction tests\n- [ ] Window selection respects budget and role ordering\n- [ ] Summary entry inserted correctly\n- [ ] Tool + thinking blocks preserved or summarized as specified\n- [ ] Session tree invariants preserved\n- [ ] Logs include compaction selection + summary metadata","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T05:45:29.310486765Z","created_by":"ubuntu","updated_at":"2026-02-03T09:16:21.984938067Z","closed_at":"2026-02-03T09:16:21.984876392Z","close_reason":"Implemented compaction tests + invariants; gates green","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-hqq","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T05:45:29.317387163Z","created_by":"ubuntu"},{"issue_id":"bd-hqq","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:45:34.801055578Z","created_by":"ubuntu"}]}
{"id":"bd-ic9","title":"Finalize sample list with pinned versions + manifest","description":"Background:\n- The sample must be frozen to make conformance reproducible.\n\nSteps:\n- Apply popularity criteria + sampling matrix to the candidate list.\n- Pin exact versions (tags, npm versions, commit hashes).\n- Record capabilities, runtime tier, and any required configuration.\n\nOutput:\n- A manifest file (e.g., docs/extension-sample.json) listing all selected extensions with version + checksum fields.\n\nAcceptance:\n- Sample list is stable and complete; future work can use the manifest as the single source of truth.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:21:39.102966724Z","created_by":"ubuntu","updated_at":"2026-02-03T05:59:05.028968917Z","closed_at":"2026-02-03T05:59:05.028906571Z","close_reason":"Completed","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-ic9","depends_on_id":"bd-22h","type":"blocks","created_at":"2026-02-03T02:33:56.006583211Z","created_by":"ubuntu"},{"issue_id":"bd-ic9","depends_on_id":"bd-2wo","type":"blocks","created_at":"2026-02-03T02:34:05.300453383Z","created_by":"ubuntu"}]}
{"id":"bd-idw","title":"E2E CLI scenarios: session lifecycle (continue/resume/export)","description":"Goal:\n- Add E2E tests for session lifecycle flows with verbose logging and artifact checks.\n\nScope:\n- New session creation (default) and JSONL header validation.\n- `--continue` and `--session` with explicit path.\n- `--export` HTML output integrity.\n- Session dir override via `--session-dir` + env (PI_SESSIONS_DIR).\n\nLogging Requirements:\n- Use CLI E2E harness (bd-1wc) + TestLogger (bd-3ml).\n- Log session paths, file sizes, header fields, VCR_MODE, and cassette name/path.\n- Capture exported HTML and session JSONL as artifacts on failure.\n\nAcceptance Criteria:\n- Tests validate session JSONL creation + tree integrity.\n- Logs include file paths, sizes, parsed headers, cassette id, and export metadata.\n- No network access; VCR playback for provider output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T04:59:01.970345925Z","created_by":"ubuntu","updated_at":"2026-02-03T05:42:57.023110772Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-idw","depends_on_id":"bd-1pf","type":"blocks","created_at":"2026-02-03T05:00:20.457874893Z","created_by":"ubuntu"},{"issue_id":"bd-idw","depends_on_id":"bd-1wc","type":"blocks","created_at":"2026-02-03T05:00:14.406792160Z","created_by":"ubuntu"},{"issue_id":"bd-idw","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T04:59:01.979111782Z","created_by":"ubuntu"},{"issue_id":"bd-idw","depends_on_id":"bd-30u","type":"blocks","created_at":"2026-02-03T05:42:57.023081016Z","created_by":"ubuntu"},{"issue_id":"bd-idw","depends_on_id":"bd-3ml","type":"blocks","created_at":"2026-02-03T05:00:56.507537877Z","created_by":"ubuntu"}]}
{"id":"bd-ivj","title":"Migrate Azure OpenAI provider to asupersync HTTP","description":"# Migrate Azure OpenAI provider to asupersync HTTP\n\n## Goal\nReplace reqwest usage in src/providers/azure.rs with asupersync HTTP client.\n\n## Background\nAzure OpenAI provider:\n- Azure-hosted OpenAI API\n- Custom endpoint URLs (resource.openai.azure.com)\n- API version query parameter\n- 654 lines, 5 unit tests\n\n## Azure-Specific Considerations\n1. **Endpoint**: Custom Azure resource URLs\n2. **API Version**: ?api-version=2024-02-01 query param\n3. **Authentication**: api-key header (not Bearer token)\n4. **Compatible**: Same response format as OpenAI\n\n## Dependencies\n- bd-9sa, bd-pwz\n- bd-1vo (OpenAI migration - nearly identical)\n\n## Acceptance Criteria\n- [ ] No reqwest imports\n- [ ] 5 tests pass\n- [ ] Streaming works with Azure endpoints","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T03:33:17.223664792Z","created_by":"ubuntu","updated_at":"2026-02-03T03:33:41.925483754Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-ivj","depends_on_id":"bd-1vo","type":"blocks","created_at":"2026-02-03T03:33:41.925461983Z","created_by":"ubuntu"},{"issue_id":"bd-ivj","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:33:17.233362232Z","created_by":"ubuntu"}]}
{"id":"bd-k7i","title":"Extensions: conformance fixtures + parity report","description":"Background:\n- Built-in legacy extensions provide a controlled, known-good subset for early parity.\n\nSteps:\n- Identify built-in extensions under legacy_pi_mono_code/pi-mono/.pi/extensions.\n- Capture observable behaviors (tools, slash commands, event ordering, connector calls).\n- Generate fixtures using the shared fixture schema and normalization rules.\n- Run Rust runtime against the same scenarios and produce a parity report.\n\nLogging requirements:\n- Per-extension logs must follow the logging spec and include scenario IDs.\n\nAcceptance:\n- Built-in extensions pass parity with clear diffs on failure.\n- Results feed FEATURE_PARITY.md for extension API coverage.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:39.351669370Z","created_by":"ubuntu","updated_at":"2026-02-03T02:58:38.765410885Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-k7i","depends_on_id":"bd-3oq","type":"blocks","created_at":"2026-02-03T02:58:24.838987137Z","created_by":"ubuntu"},{"issue_id":"bd-k7i","depends_on_id":"bd-7al","type":"blocks","created_at":"2026-02-03T02:58:38.765386399Z","created_by":"ubuntu"},{"issue_id":"bd-k7i","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:25:09.480333407Z","created_by":"ubuntu"},{"issue_id":"bd-k7i","depends_on_id":"bd-yd9","type":"blocks","created_at":"2026-02-03T02:58:34.091906333Z","created_by":"ubuntu"}]}
{"id":"bd-nom","title":"Extensions: WASM host (component model) using connector layer","description":"Implement WASM component runtime (wasmtime) for extensions, importing pi:extension/host.call and exporting pi:extension/extension per docs/wit/extension.wit. Must route all I/O via connector dispatcher.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-03T02:24:02.809593081Z","created_by":"ubuntu","updated_at":"2026-02-03T02:57:41.255820559Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-nom","depends_on_id":"bd-3d1","type":"blocks","created_at":"2026-02-03T02:57:41.255796474Z","created_by":"ubuntu"},{"issue_id":"bd-nom","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:24:51.781952277Z","created_by":"ubuntu"}]}
{"id":"bd-pwz","title":"Implement SSE streaming adapter for asupersync","description":"# Implement SSE streaming adapter for asupersync\n\n## Goal\nBridge asupersync HTTP streaming response to the existing SSE parser (src/sse.rs).\n\n## Background\nThe SSE parser in src/sse.rs is already complete and well-tested:\n- SseParser::new() creates parser\n- SseParser::feed(&str) returns Vec<SseEvent>\n- Handles: event types, data fields, IDs, comments, multiline data\n- 9 unit tests covering all edge cases\n\nThe challenge is connecting asupersync's streaming response body to this parser.\n\n## Implementation\n\n### Streaming Adapter\n```rust\n// src/http/sse.rs (new file or extend existing)\n\nuse crate::sse::{SseParser, SseEvent};\nuse asupersync::Cx;\n\npub struct SseStream {\n    parser: SseParser,\n    body: BodyReader,\n    buffer: String,\n}\n\nimpl SseStream {\n    pub fn new(response: Response) -> Self {\n        Self {\n            parser: SseParser::new(),\n            body: response.into_body(),\n            buffer: String::new(),\n        }\n    }\n    \n    pub async fn next(&mut self, cx: &Cx) -> Option<Result<SseEvent, Error>> {\n        loop {\n            // Try to parse buffered data first\n            let events = self.parser.feed(&self.buffer);\n            if !events.is_empty() {\n                self.buffer.clear();\n                return Some(Ok(events.remove(0)));\n            }\n            \n            // Read more data from body stream\n            match self.body.read_chunk(cx).await {\n                Ok(Some(chunk)) => {\n                    self.buffer.push_str(&String::from_utf8_lossy(&chunk));\n                }\n                Ok(None) => return None,  // Stream ended\n                Err(e) => return Some(Err(e.into())),\n            }\n        }\n    }\n}\n\n// Or implement as a proper Stream trait for use with async iteration\nimpl Stream for SseStream {\n    type Item = Result<SseEvent, Error>;\n    \n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        // ...\n    }\n}\n```\n\n### Usage Pattern (in providers)\n```rust\n// In anthropic.rs\nlet response = client.post(url).json(&request).send(cx).await?;\nlet mut sse = SseStream::new(response);\n\nwhile let Some(event) = sse.next(cx).await {\n    match event? {\n        SseEvent { data, event_type, .. } => {\n            // Process Anthropic streaming event\n        }\n    }\n}\n```\n\n## Considerations\n1. **Backpressure**: Don't buffer entire response; process incrementally\n2. **Error recovery**: Handle malformed events gracefully (log and continue)\n3. **Cancellation**: Support clean shutdown via Cx cancellation\n4. **Memory**: Limit buffer size to prevent OOM on malicious servers\n\n## Dependencies\n- bd-9sa (HTTP client wrapper must exist first)\n\n## Testing\n- Unit test: SseStream parses single event\n- Unit test: SseStream handles multiline data\n- Unit test: SseStream handles stream interruption\n- Integration test: Stream from mock HTTP server\n\n## Files\n- src/http/sse.rs (new or extend)\n- src/http/mod.rs (add re-export)\n\n## Acceptance Criteria\n- [ ] SseStream wraps Response and yields SseEvent\n- [ ] Incremental parsing works (no full buffering)\n- [ ] Cancellation handled cleanly\n- [ ] Memory bounded\n- [ ] All tests pass","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-03T03:32:22.790834667Z","created_by":"ubuntu","updated_at":"2026-02-03T03:32:29.283967395Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-pwz","depends_on_id":"bd-9sa","type":"blocks","created_at":"2026-02-03T03:32:29.283945494Z","created_by":"ubuntu"},{"issue_id":"bd-pwz","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:32:22.801694914Z","created_by":"ubuntu"}]}
{"id":"bd-qpm","title":"Apply theme colors to TUI components","description":"# Apply theme colors to TUI components\n\n## Goal\nWire theme colors into lipgloss styles and glamour markdown rendering.\n\n## Implementation\n\n### Create Themed Styles\n```rust\n// src/interactive.rs\n\nfn create_styles(theme: &Theme) -> Styles {\n    Styles {\n        message_user: lipgloss::Style::new()\n            .foreground(lipgloss::Color::hex(&theme.colors.accent)),\n        \n        message_assistant: lipgloss::Style::new()\n            .foreground(lipgloss::Color::hex(&theme.colors.foreground)),\n        \n        thinking: lipgloss::Style::new()\n            .foreground(lipgloss::Color::hex(&theme.colors.muted))\n            .italic(true),\n        \n        error: lipgloss::Style::new()\n            .foreground(lipgloss::Color::hex(&theme.colors.error))\n            .bold(true),\n        \n        success: lipgloss::Style::new()\n            .foreground(lipgloss::Color::hex(&theme.colors.success)),\n        \n        border: lipgloss::Style::new()\n            .border_foreground(lipgloss::Color::hex(&theme.ui.border)),\n        \n        // ... more styles\n    }\n}\n```\n\n### Apply to PiApp\n```rust\nimpl PiApp {\n    pub fn new(config: Config) -> Self {\n        let theme = config.theme()\n            .map(|name| Theme::load_by_name(&name).ok())\n            .flatten()\n            .unwrap_or_else(Theme::dark);\n        \n        let styles = create_styles(&theme);\n        \n        Self {\n            theme,\n            styles,\n            // ...\n        }\n    }\n}\n```\n\n### Apply to Glamour (Markdown)\n```rust\nfn create_glamour_style(theme: &Theme) -> glamour::Style {\n    glamour::Style {\n        document: glamour::StyleBlock {\n            color: Some(theme.colors.foreground.clone()),\n            background_color: Some(theme.colors.background.clone()),\n            ..Default::default()\n        },\n        heading: glamour::StyleBlock {\n            color: Some(theme.colors.accent.clone()),\n            bold: Some(true),\n            ..Default::default()\n        },\n        code: glamour::StyleBlock {\n            color: Some(theme.syntax.string.clone()),\n            ..Default::default()\n        },\n        // ... more elements\n    }\n}\n```\n\n## Components to Update\n1. Message display (user/assistant)\n2. Thinking block\n3. Status line\n4. Input field border\n5. Error messages\n6. Tool status\n7. Markdown rendering\n8. Code blocks\n\n## Dependencies\n- bd-37a (theme loader must exist)\n\n## Testing\n- Test: Styles created from theme\n- Test: Default theme applies\n- Test: Custom theme applies\n\n## Acceptance Criteria\n- [ ] All TUI components use theme colors\n- [ ] Glamour uses syntax colors\n- [ ] Default theme looks good\n- [ ] Custom themes render correctly","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-03T03:39:49.017934733Z","created_by":"ubuntu","updated_at":"2026-02-03T03:40:04.490308576Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-qpm","depends_on_id":"bd-22p","type":"parent-child","created_at":"2026-02-03T03:39:49.030473820Z","created_by":"ubuntu"},{"issue_id":"bd-qpm","depends_on_id":"bd-37a","type":"blocks","created_at":"2026-02-03T03:40:04.490283188Z","created_by":"ubuntu"}]}
{"id":"bd-rhl","title":"Remove tokio and reqwest dependencies","description":"# Remove tokio and reqwest dependencies\n\n## Goal\nComplete the HTTP migration by removing tokio and reqwest from Cargo.toml.\n\n## Background\nAfter all providers migrate to asupersync, these dependencies become unused:\n- tokio (async runtime)\n- tokio-stream (stream utilities)\n- reqwest (HTTP client)\n\nThis reduces binary size and simplifies the dependency tree.\n\n## Implementation Steps\n\n1. **Update Cargo.toml**\n```toml\n# Remove these lines:\ntokio = { version = \"1\", features = [\"full\"] }\ntokio-stream = \"0.1\"\nreqwest = { version = \"0.13\", ... }\n\n# Ensure asupersync is enabled (currently commented out):\nasupersync = { path = \"../asupersync\", features = [\"tls\", \"tls-native-roots\", \"sqlite\"] }\n```\n\n2. **Update main.rs**\n```rust\n// Before\n#[tokio::main]\nasync fn main() { ... }\n\n// After - use asupersync runtime\nfn main() {\n    asupersync::runtime::Runtime::new()\n        .block_on(async_main())\n}\n```\n\n3. **Update all async code**\n- Replace tokio::spawn with asupersync::spawn\n- Replace tokio::time::sleep with asupersync equivalents\n- Replace tokio::select! with asupersync patterns\n- Update channel usage (if tokio channels used)\n\n4. **Update test harness**\n```rust\n// Before\n#[tokio::test]\nasync fn test_foo() { ... }\n\n// After\n#[asupersync::test]\nasync fn test_foo() { ... }\n```\n\n## Files Affected\n- Cargo.toml\n- src/main.rs\n- src/agent.rs (spawn, select)\n- src/tools.rs (bash timeout)\n- All test files\n\n## Dependencies\n- bd-37l (Anthropic migrated)\n- bd-1vo (OpenAI migrated)\n- bd-1iy (Gemini migrated)\n- bd-ivj (Azure migrated)\n\n## Testing\n- cargo build must succeed without tokio\n- All tests must pass\n- Binary size should decrease (~500KB-1MB)\n\n## Risks\n- Some tokio-specific features may need alternatives\n- Test harness changes may be extensive\n\n## Acceptance Criteria\n- [ ] tokio not in Cargo.toml\n- [ ] reqwest not in Cargo.toml\n- [ ] cargo build succeeds\n- [ ] All tests pass\n- [ ] Binary size reduced","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-03T03:33:32.853980666Z","created_by":"ubuntu","updated_at":"2026-02-03T08:37:48.931741249Z","closed_at":"2026-02-03T08:37:48.931668013Z","close_reason":"Completed: tokio/reqwest fully removed; tests+clippy green","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-rhl","depends_on_id":"bd-1iy","type":"blocks","created_at":"2026-02-03T03:33:42.693811991Z","created_by":"ubuntu"},{"issue_id":"bd-rhl","depends_on_id":"bd-1vo","type":"blocks","created_at":"2026-02-03T03:33:42.436282419Z","created_by":"ubuntu"},{"issue_id":"bd-rhl","depends_on_id":"bd-37l","type":"blocks","created_at":"2026-02-03T03:33:42.179760124Z","created_by":"ubuntu"},{"issue_id":"bd-rhl","depends_on_id":"bd-gi3","type":"parent-child","created_at":"2026-02-03T03:33:32.861092228Z","created_by":"ubuntu"},{"issue_id":"bd-rhl","depends_on_id":"bd-ivj","type":"blocks","created_at":"2026-02-03T03:33:42.951519334Z","created_by":"ubuntu"}]}
{"id":"bd-u4r","title":"Define deterministic capture environment (paths/time/env)","description":"Background:\n- Extension outputs may include timestamps, absolute paths, or random IDs.\n\nDecide and document:\n- Fixed working directory + fixture temp paths.\n- Environment variable whitelist and standard values.\n- Time/freezing strategy (mock clock or fixed timestamp).\n- Randomness policy (seeded RNG or sanitized outputs).\n\nAcceptance:\n- Capture outputs are deterministic across runs on the same machine class.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:22:15.777902009Z","created_by":"ubuntu","updated_at":"2026-02-03T03:34:02.949898411Z","closed_at":"2026-02-03T03:34:02.949838310Z","close_reason":"Documented deterministic capture env (paths/time/env/randomness) in CONFORMANCE.md","compaction_level":0,"original_size":0}
{"id":"bd-uah","title":"Compare extension performance vs legacy pi baseline","description":"Background:\n- We must show Rust meets or improves performance relative to legacy.\n\nSteps:\n- Run the same scenarios on legacy pi and capture timing stats.\n- Compare to Rust benchmarks; compute deltas and percent improvements.\n- Document any regressions with hypotheses.\n\nAcceptance:\n- A comparison table exists and is included in documentation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:25:55.844538937Z","created_by":"ubuntu","updated_at":"2026-02-03T02:39:30.616057230Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-uah","depends_on_id":"bd-1fg","type":"blocks","created_at":"2026-02-03T02:39:20.783898749Z","created_by":"ubuntu"},{"issue_id":"bd-uah","depends_on_id":"bd-7l6","type":"blocks","created_at":"2026-02-03T02:39:30.616028426Z","created_by":"ubuntu"}]}
{"id":"bd-vbs","title":"Document legacy capture process + provenance","description":"Background:\n- Future runs must reproduce the same fixtures and explain any drift.\n\nSteps:\n- Document capture commands, environment, and normalization.\n- Include version pins for pi-mono and extension sources.\n- Add a troubleshooting section for common capture failures.\n\nAcceptance:\n- A new maintainer can regenerate fixtures using only the doc.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-03T02:23:03.676906157Z","created_by":"ubuntu","updated_at":"2026-02-03T02:35:36.960388313Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-vbs","depends_on_id":"bd-16n","type":"blocks","created_at":"2026-02-03T02:35:36.960362635Z","created_by":"ubuntu"}]}
{"id":"bd-vmm","title":"E2E: legacy vs Rust parity runner (fixtures + diff logs)","description":"Background:\n- We must prove parity by running identical scenarios in legacy and Rust and diffing outputs.\n\nSteps:\n- Build a runner that executes scenarios in both runtimes (legacy + Rust).\n- Normalize outputs using the harness rules (paths/time/ANSI) before diffing.\n- Emit per-scenario diff logs with context, including raw vs normalized output.\n- Store diff artifacts for CI review and triage.\n\nLogging requirements:\n- Structured logs with correlation IDs (extension id, scenario id, runtime).\n\nAcceptance:\n- Parity runner completes for the full sample and produces deterministic diffs.\n- Failures are actionable with minimal manual digging.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-03T02:47:11.638706880Z","created_by":"ubuntu","updated_at":"2026-02-03T02:59:58.553997960Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-vmm","depends_on_id":"bd-16n","type":"blocks","created_at":"2026-02-03T02:59:36.025190918Z","created_by":"ubuntu"},{"issue_id":"bd-vmm","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-03T02:59:58.553968786Z","created_by":"ubuntu"},{"issue_id":"bd-vmm","depends_on_id":"bd-3s2","type":"blocks","created_at":"2026-02-03T02:59:50.448234186Z","created_by":"ubuntu"},{"issue_id":"bd-vmm","depends_on_id":"bd-3so","type":"blocks","created_at":"2026-02-03T02:59:54.640846590Z","created_by":"ubuntu"},{"issue_id":"bd-vmm","depends_on_id":"bd-7al","type":"blocks","created_at":"2026-02-03T02:59:40.204782716Z","created_by":"ubuntu"}]}
{"id":"bd-xgo","title":"Extensions: extc pipeline (SWC) + cache + compat scanner","description":"Background:\n- JS/TS extensions need a deterministic build pipeline to run as-is without Node/Bun.\n- The pipeline must rewrite legacy APIs into connector hostcalls and enforce compatibility.\n\nSteps:\n- Implement extc build pipeline with SWC: bundle, tree-shake, and emit target artifact (QuickJS bytecode or JS->WASM).\n- Run a static compatibility scan (forbidden APIs, Node/Bun globals, unsafe patterns).\n- Apply protocol shims/rewrite passes to map legacy APIs to pi connector calls.\n- Add artifact cache keyed by sha256(manifest + bundle + engine_version).\n- Emit build report metadata (warnings, compatibility flags, required capabilities).\n\nLogging requirements:\n- Build logs must include extension id, input hash, and any rejected APIs.\n\nAcceptance:\n- A representative JS extension bundles deterministically with cache hits on repeat.\n- Compatibility violations are reported with actionable diagnostics.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-02-03T02:24:33.029915380Z","created_by":"ubuntu","updated_at":"2026-02-03T02:57:27.809200249Z","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-xgo","depends_on_id":"bd-576","type":"blocks","created_at":"2026-02-03T02:57:27.809161367Z","created_by":"ubuntu"},{"issue_id":"bd-xgo","depends_on_id":"bd-h04","type":"blocks","created_at":"2026-02-03T02:25:02.648692771Z","created_by":"ubuntu"}]}
{"id":"bd-yd9","title":"Define extension fixture schema + normalization contract","description":"Background:\n- Extension conformance requires a fixture schema that captures inputs and expected outputs precisely.\n\nSteps:\n- Define JSON schema for extension fixtures (inputs, outputs, metadata, normalization hints).\n- Specify normalization rules (paths/time/ANSI/UUID) and how hints are applied.\n- Provide example fixtures for tools, slash commands, and event hooks.\n- Document how to add new cases and validate fixtures.\n\nAcceptance:\n- Schema can represent tools, slash commands, and event hooks uniformly.\n- Fixture validation is deterministic and ready for unit tests.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T02:24:33.255817422Z","created_by":"ubuntu","updated_at":"2026-02-03T03:29:56.253845738Z","closed_at":"2026-02-03T03:29:56.253765719Z","close_reason":"Defined extension fixture schema + normalization contract in CONFORMANCE.md","compaction_level":0,"original_size":0}
{"id":"bd-yfs","title":"Implement configuration loading tests","description":"# Implement configuration loading tests\n\n## Goal\nAdd unit tests for src/config.rs (332 lines, currently 0 tests).\n\n## Background\nConfiguration affects all aspects of behavior:\n- Default provider/model selection\n- Compaction settings\n- Retry behavior\n- Shell path and prefix\n- Terminal display options\n- Thinking budgets\n\n## Test Categories\n\n### 1. Default Value Tests\n```rust\n#[test]\nfn test_default_config() {\n    let config = Config::default();\n    \n    assert_eq!(config.default_provider(), \"anthropic\");\n    assert_eq!(config.default_model(), \"claude-sonnet-4-20250514\");\n    assert_eq!(config.default_thinking_level(), ThinkingLevel::Off);\n}\n\n#[test]\nfn test_compaction_defaults() {\n    let config = Config::default();\n    let comp = config.compaction();\n    \n    assert!(comp.enabled);\n    assert_eq!(comp.reserve_tokens, 16384);\n    assert_eq!(comp.keep_recent_tokens, 20000);\n}\n\n#[test]\nfn test_retry_defaults() {\n    let config = Config::default();\n    let retry = config.retry();\n    \n    assert!(retry.enabled);\n    assert_eq!(retry.max_retries, 3);\n    assert_eq!(retry.base_delay_ms, 2000);\n    assert_eq!(retry.max_delay_ms, 60000);\n}\n```\n\n### 2. JSON Loading Tests\n```rust\n#[test]\nfn test_load_config_from_json() {\n    let json = r#\"{\n        \"defaultProvider\": \"openai\",\n        \"defaultModel\": \"gpt-4\",\n        \"defaultThinkingLevel\": \"high\"\n    }\"#;\n    \n    let config = Config::from_json(json).unwrap();\n    \n    assert_eq!(config.default_provider(), \"openai\");\n    assert_eq!(config.default_model(), \"gpt-4\");\n    assert_eq!(config.default_thinking_level(), ThinkingLevel::High);\n}\n\n#[test]\nfn test_load_config_partial_json() {\n    // Only some fields set - rest should use defaults\n    let json = r#\"{\"defaultProvider\": \"openai\"}\"#;\n    \n    let config = Config::from_json(json).unwrap();\n    \n    assert_eq!(config.default_provider(), \"openai\");\n    // Defaults for unset fields\n    assert_eq!(config.default_model(), \"claude-sonnet-4-20250514\");\n}\n\n#[test]\nfn test_load_config_invalid_json() {\n    let json = \"not valid json {\";\n    let result = Config::from_json(json);\n    assert!(result.is_err());\n}\n\n#[test]\nfn test_load_config_unknown_fields_ignored() {\n    let json = r#\"{\"unknownField\": \"value\", \"defaultProvider\": \"anthropic\"}\"#;\n    let config = Config::from_json(json).unwrap();\n    assert_eq!(config.default_provider(), \"anthropic\");\n}\n```\n\n### 3. File Loading Tests\n```rust\n#[test]\nfn test_load_config_from_file() {\n    let temp = TempDir::new().unwrap();\n    let config_path = temp.path().join(\"settings.json\");\n    fs::write(&config_path, r#\"{\"defaultProvider\": \"gemini\"}\"#).unwrap();\n    \n    let config = Config::load_from_file(&config_path).unwrap();\n    assert_eq!(config.default_provider(), \"gemini\");\n}\n\n#[test]\nfn test_load_config_missing_file() {\n    let result = Config::load_from_file(Path::new(\"/nonexistent/config.json\"));\n    // Should return default config, not error\n    assert!(result.is_ok());\n    assert_eq!(result.unwrap().default_provider(), \"anthropic\");\n}\n```\n\n### 4. Merge Logic Tests\n```rust\n#[test]\nfn test_merge_configs_project_overrides_global() {\n    let global = Config::from_json(r#\"{\"defaultProvider\": \"openai\"}\"#).unwrap();\n    let project = Config::from_json(r#\"{\"defaultProvider\": \"anthropic\"}\"#).unwrap();\n    \n    let merged = global.merge(&project);\n    \n    // Project should override global\n    assert_eq!(merged.default_provider(), \"anthropic\");\n}\n\n#[test]\nfn test_merge_configs_partial_override() {\n    let global = Config::from_json(r#\"{\n        \"defaultProvider\": \"openai\",\n        \"defaultModel\": \"gpt-4\"\n    }\"#).unwrap();\n    let project = Config::from_json(r#\"{\n        \"defaultProvider\": \"anthropic\"\n    }\"#).unwrap();\n    \n    let merged = global.merge(&project);\n    \n    assert_eq!(merged.default_provider(), \"anthropic\");  // Overridden\n    assert_eq!(merged.default_model(), \"gpt-4\");  // Inherited from global\n}\n```\n\n### 5. Environment Variable Tests\n```rust\n#[test]\nfn test_env_override_config_path() {\n    std::env::set_var(\"PI_CONFIG_PATH\", \"/custom/path\");\n    let path = Config::config_path();\n    assert_eq!(path, PathBuf::from(\"/custom/path\"));\n    std::env::remove_var(\"PI_CONFIG_PATH\");\n}\n\n#[test]\nfn test_env_api_keys() {\n    std::env::set_var(\"ANTHROPIC_API_KEY\", \"sk-test\");\n    let key = Config::api_key_for_provider(\"anthropic\");\n    assert_eq!(key, Some(\"sk-test\".to_string()));\n    std::env::remove_var(\"ANTHROPIC_API_KEY\");\n}\n```\n\n### 6. Validation Tests\n```rust\n#[test]\nfn test_invalid_thinking_level() {\n    let json = r#\"{\"defaultThinkingLevel\": \"invalid\"}\"#;\n    let result = Config::from_json(json);\n    // Should either error or use default\n}\n\n#[test]\nfn test_negative_retry_values() {\n    let json = r#\"{\"retry\": {\"maxRetries\": -1}}\"#;\n    let config = Config::from_json(json).unwrap();\n    // Should clamp to 0 or use default\n    assert!(config.retry().max_retries >= 0);\n}\n```\n\n## Dependencies\nNone (unit tests only)\n\n## Files\n- src/config.rs (add #[cfg(test)] module)\n\n## Acceptance Criteria\n- [ ] 20+ configuration tests\n- [ ] Default values tested\n- [ ] JSON loading tested\n- [ ] File loading tested\n- [ ] Merge logic tested\n- [ ] Environment variables tested\n- [ ] Validation tested\n- [ ] All tests pass","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-03T03:37:25.520841161Z","created_by":"ubuntu","updated_at":"2026-02-03T05:10:20.631979052Z","closed_at":"2026-02-03T05:10:20.631914241Z","close_reason":"Completed","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-yfs","depends_on_id":"bd-26s","type":"parent-child","created_at":"2026-02-03T03:37:25.529374192Z","created_by":"ubuntu"}]}
