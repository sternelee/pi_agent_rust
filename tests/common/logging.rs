//! Verbose test logging infrastructure.
//!
//! Provides detailed logging for integration and E2E tests to enable
//! easy debugging when tests fail. All log entries capture:
//! - Timestamps (elapsed time from test start)
//! - Log level (Debug, Info, Warn, Error)
//! - Category (setup, action, verify, etc.)
//! - Message with optional key-value context
//!
//! # Example
//!
//! ```ignore
//! let logger = TestLogger::new();
//! logger.info("setup", "Creating test file");
//! logger.with_context(LogLevel::Info, "action", "Calling tool", |ctx| {
//!     ctx.push(("tool".into(), "read".into()));
//!     ctx.push(("path".into(), "/tmp/test.txt".into()));
//! });
//!
//! // On test failure, logs are automatically dumped:
//! // [   0.001s] INFO  [setup]  Creating test file
//! // [   0.002s] INFO  [action] Calling tool
//! //            tool = read
//! //            path = /tmp/test.txt
//! ```

#![allow(dead_code)]

use chrono::{DateTime, SecondsFormat, Utc};
use regex::Regex;
use serde::Serialize;
use sha2::{Digest, Sha256};
use std::collections::BTreeMap;
use std::fmt::Write as _;
use std::fs;
use std::io::Read as _;
use std::path::Path;
use std::sync::{Mutex, OnceLock};
use std::time::{Duration, Instant, SystemTime};

const REDACTED_VALUE: &str = "[REDACTED]";
const REDACTION_KEYS: [&str; 10] = [
    "api_key",
    "api-key",
    "authorization",
    "bearer",
    "cookie",
    "credential",
    "password",
    "private_key",
    "secret",
    "token",
];

const TEST_LOG_SCHEMA: &str = "pi.test.log.v1";
const TEST_ARTIFACT_SCHEMA: &str = "pi.test.artifact.v1";
const PLACEHOLDER_TIMESTAMP: &str = "<TIMESTAMP>";
const PLACEHOLDER_PROJECT_ROOT: &str = "<PROJECT_ROOT>";
const PLACEHOLDER_TEST_ROOT: &str = "<TEST_ROOT>";
const PLACEHOLDER_RUN_ID: &str = "<RUN_ID>";
const PLACEHOLDER_UUID: &str = "<UUID>";
const PLACEHOLDER_PORT: &str = "<PORT>";

static ANSI_REGEX: OnceLock<Regex> = OnceLock::new();
static RUN_ID_REGEX: OnceLock<Regex> = OnceLock::new();
static UUID_REGEX: OnceLock<Regex> = OnceLock::new();
static LOCAL_PORT_REGEX: OnceLock<Regex> = OnceLock::new();

fn ansi_regex() -> &'static Regex {
    ANSI_REGEX.get_or_init(|| Regex::new(r"\x1b\[[0-9;]*[A-Za-z]").expect("ansi regex"))
}

fn run_id_regex() -> &'static Regex {
    RUN_ID_REGEX.get_or_init(|| Regex::new(r"\brun-[0-9a-fA-F-]{36}\b").expect("run id regex"))
}

fn uuid_regex() -> &'static Regex {
    UUID_REGEX.get_or_init(|| {
        Regex::new(
            r"\b[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\b",
        )
        .expect("uuid regex")
    })
}

fn local_port_regex() -> &'static Regex {
    LOCAL_PORT_REGEX.get_or_init(|| Regex::new(r"http://127\\.0\\.0\\.1:\\d+").expect("port regex"))
}

/// Log entry severity level.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LogLevel {
    /// Detailed debugging information.
    Debug,
    /// General information about test progress.
    Info,
    /// Warnings about unexpected but non-fatal conditions.
    Warn,
    /// Errors that may cause test failure.
    Error,
}

impl LogLevel {
    /// Returns the display string for this log level.
    pub const fn as_str(self) -> &'static str {
        match self {
            Self::Debug => "DEBUG",
            Self::Info => "INFO ",
            Self::Warn => "WARN ",
            Self::Error => "ERROR",
        }
    }

    /// Returns the ANSI color code for this log level.
    pub const fn color_code(self) -> &'static str {
        match self {
            Self::Debug => "\x1b[90m", // Gray
            Self::Info => "\x1b[32m",  // Green
            Self::Warn => "\x1b[33m",  // Yellow
            Self::Error => "\x1b[31m", // Red
        }
    }

    pub const fn as_json_str(self) -> &'static str {
        match self {
            Self::Debug => "debug",
            Self::Info => "info",
            Self::Warn => "warn",
            Self::Error => "error",
        }
    }
}

/// A single log entry with timestamp, level, category, message, and context.
#[derive(Debug, Clone)]
pub struct LogEntry {
    /// Elapsed milliseconds from logger creation.
    pub elapsed_ms: u64,
    /// Severity level.
    pub level: LogLevel,
    /// Category tag (e.g., "setup", "action", "verify").
    pub category: String,
    /// Human-readable message.
    pub message: String,
    /// Optional key-value context pairs.
    pub context: Vec<(String, String)>,
}

impl LogEntry {
    /// Format this entry as a string (without colors).
    pub fn format(&self) -> String {
        let elapsed = format_elapsed_ms(self.elapsed_ms);
        let mut output = format!(
            "[{elapsed}s] {} [{}] {}\n",
            self.level.as_str(),
            self.category,
            self.message
        );

        for (key, value) in &self.context {
            let _ = writeln!(output, "           {key} = {value}");
        }

        output
    }

    /// Format this entry with ANSI colors.
    pub fn format_colored(&self) -> String {
        const RESET: &str = "\x1b[0m";
        const DIM: &str = "\x1b[2m";

        let elapsed = format_elapsed_ms(self.elapsed_ms);
        let mut output = format!(
            "{DIM}[{elapsed}s]{RESET} {}{}{RESET} {DIM}[{}]{RESET} {}\n",
            self.level.color_code(),
            self.level.as_str(),
            self.category,
            self.message
        );

        for (key, value) in &self.context {
            let _ = writeln!(output, "{DIM}           {key}{RESET} = {value}");
        }

        output
    }
}

/// Artifact entry captured during a test run.
#[derive(Debug, Clone)]
pub struct ArtifactEntry {
    /// Elapsed milliseconds from logger creation.
    pub elapsed_ms: u64,
    /// Logical name of the artifact.
    pub name: String,
    /// Path to the artifact on disk.
    pub path: String,
}

impl ArtifactEntry {
    /// Format this artifact entry as a string.
    pub fn format(&self) -> String {
        let elapsed = format_elapsed_ms(self.elapsed_ms);
        format!("[{elapsed}s] {} -> {}\n", self.name, self.path)
    }
}

fn format_elapsed_ms(elapsed_ms: u64) -> String {
    let secs = elapsed_ms / 1000;
    let millis = elapsed_ms % 1000;
    let raw = format!("{secs}.{millis:03}");
    format!("{raw:>8}")
}

#[derive(Debug, Clone, Serialize)]
struct TestLogJsonRecord {
    schema: &'static str,
    #[serde(rename = "type")]
    record_type: &'static str,
    #[serde(skip_serializing_if = "Option::is_none")]
    test: Option<String>,
    seq: usize,
    ts: String,
    t_ms: u64,
    level: &'static str,
    category: String,
    message: String,
    #[serde(skip_serializing_if = "BTreeMap::is_empty")]
    context: BTreeMap<String, String>,
}

#[derive(Debug, Clone, Serialize)]
struct TestArtifactJsonRecord {
    schema: &'static str,
    #[serde(rename = "type")]
    record_type: &'static str,
    #[serde(skip_serializing_if = "Option::is_none")]
    test: Option<String>,
    seq: usize,
    ts: String,
    t_ms: u64,
    name: String,
    path: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    size_bytes: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    sha256: Option<String>,
}

#[derive(Debug, Clone)]
struct NormalizationContext {
    project_root: String,
    test_root: Option<String>,
}

impl NormalizationContext {
    fn new(test_root: Option<&Path>) -> Self {
        let project_root = Path::new(env!("CARGO_MANIFEST_DIR"))
            .canonicalize()
            .unwrap_or_else(|_| Path::new(env!("CARGO_MANIFEST_DIR")).to_path_buf())
            .display()
            .to_string();
        let test_root = test_root.map(|root| {
            root.canonicalize()
                .unwrap_or_else(|_| root.to_path_buf())
                .display()
                .to_string()
        });
        Self {
            project_root,
            test_root,
        }
    }

    fn normalize_string(&self, input: &str) -> String {
        let without_ansi = ansi_regex().replace_all(input, "");
        let mut out =
            replace_path_variants(&without_ansi, &self.project_root, PLACEHOLDER_PROJECT_ROOT);
        if let Some(test_root) = &self.test_root {
            out = replace_path_variants(&out, test_root, PLACEHOLDER_TEST_ROOT);
        }
        out = run_id_regex()
            .replace_all(&out, PLACEHOLDER_RUN_ID)
            .into_owned();
        out = uuid_regex()
            .replace_all(&out, PLACEHOLDER_UUID)
            .into_owned();
        out = local_port_regex()
            .replace_all(&out, format!("http://127.0.0.1:{PLACEHOLDER_PORT}"))
            .into_owned();
        out
    }
}

fn replace_path_variants(input: &str, path: &str, placeholder: &str) -> String {
    if path.is_empty() {
        return input.to_string();
    }
    let mut out = input.replace(path, placeholder);
    let path_backslashes = path.replace('/', "\\");
    if path_backslashes != path {
        out = out.replace(&path_backslashes, placeholder);
    }
    out
}

/// Thread-safe test logger that captures all log entries.
///
/// Entries are stored in memory and can be dumped on test failure.
/// The logger is designed to have minimal overhead during normal test execution.
pub struct TestLogger {
    /// All captured log entries.
    entries: Mutex<Vec<LogEntry>>,
    /// Captured artifacts produced during the test.
    artifacts: Mutex<Vec<ArtifactEntry>>,
    /// Timestamp when the logger was created.
    start: Instant,
    /// Wall-clock timestamp when the logger was created.
    start_wall: SystemTime,
    /// Minimum log level to capture (entries below this are ignored).
    min_level: LogLevel,
    /// Optional test name for JSONL output.
    test_name: Mutex<Option<String>>,
    /// Optional root path to normalize in JSONL dumps (e.g. harness temp dir).
    normalize_root: Mutex<Option<String>>,
}

impl Default for TestLogger {
    fn default() -> Self {
        Self::new()
    }
}

impl TestLogger {
    /// Create a new test logger with default settings.
    ///
    /// By default, captures all log levels (Debug and above).
    #[must_use]
    pub fn new() -> Self {
        Self {
            entries: Mutex::new(Vec::with_capacity(256)),
            artifacts: Mutex::new(Vec::with_capacity(16)),
            start: Instant::now(),
            start_wall: SystemTime::now(),
            min_level: LogLevel::Debug,
            test_name: Mutex::new(None),
            normalize_root: Mutex::new(None),
        }
    }

    /// Create a logger that only captures entries at or above the given level.
    #[must_use]
    pub fn with_min_level(min_level: LogLevel) -> Self {
        Self {
            entries: Mutex::new(Vec::with_capacity(256)),
            artifacts: Mutex::new(Vec::with_capacity(16)),
            start: Instant::now(),
            start_wall: SystemTime::now(),
            min_level,
            test_name: Mutex::new(None),
            normalize_root: Mutex::new(None),
        }
    }

    /// Configure a root path for normalization in JSONL dumps.
    ///
    /// This is intended for deterministic, portable artifacts (e.g. CI logs) where
    /// temp directories should not leak into diffs.
    pub fn set_normalization_root(&self, root: impl AsRef<Path>) {
        let root = root.as_ref().display().to_string();
        *self.normalize_root.lock().unwrap() = Some(root);
    }

    /// Set the test name for JSONL output.
    pub fn set_test_name(&self, name: impl Into<String>) {
        *self.test_name.lock().unwrap() = Some(name.into());
    }

    fn elapsed_ms(&self) -> u64 {
        u64::try_from(self.start.elapsed().as_millis()).unwrap_or(u64::MAX)
    }

    /// Log an entry with the given level and category.
    pub fn log(&self, level: LogLevel, category: &str, message: impl Into<String>) {
        if (level as u8) < (self.min_level as u8) {
            return;
        }

        let entry = LogEntry {
            elapsed_ms: self.elapsed_ms(),
            level,
            category: category.to_string(),
            message: message.into(),
            context: Vec::new(),
        };

        self.entries.lock().unwrap().push(entry);
    }

    /// Log a debug message.
    pub fn debug(&self, category: &str, message: impl Into<String>) {
        self.log(LogLevel::Debug, category, message);
    }

    /// Log an info message.
    pub fn info(&self, category: &str, message: impl Into<String>) {
        self.log(LogLevel::Info, category, message);
    }

    /// Log a warning message.
    pub fn warn(&self, category: &str, message: impl Into<String>) {
        self.log(LogLevel::Warn, category, message);
    }

    /// Log an error message.
    pub fn error(&self, category: &str, message: impl Into<String>) {
        self.log(LogLevel::Error, category, message);
    }

    /// Log an entry with additional key-value context.
    ///
    /// The closure receives a mutable reference to the context vector,
    /// allowing you to add key-value pairs that will be displayed with the entry.
    ///
    /// # Example
    ///
    /// ```ignore
    /// logger.with_context(LogLevel::Info, "action", "Executing tool", |ctx| {
    ///     ctx.push(("tool".into(), "bash".into()));
    ///     ctx.push(("command".into(), "ls -la".into()));
    /// });
    /// ```
    pub fn with_context<F>(&self, level: LogLevel, category: &str, message: impl Into<String>, f: F)
    where
        F: FnOnce(&mut Vec<(String, String)>),
    {
        if (level as u8) < (self.min_level as u8) {
            return;
        }

        let mut context = Vec::new();
        f(&mut context);
        redact_context(&mut context);

        let entry = LogEntry {
            elapsed_ms: self.elapsed_ms(),
            level,
            category: category.to_string(),
            message: message.into(),
            context,
        };

        self.entries.lock().unwrap().push(entry);
    }

    /// Log an info entry with context.
    pub fn info_ctx<F>(&self, category: &str, message: impl Into<String>, f: F)
    where
        F: FnOnce(&mut Vec<(String, String)>),
    {
        self.with_context(LogLevel::Info, category, message, f);
    }

    /// Log an error entry with context.
    #[allow(dead_code)]
    pub fn error_ctx<F>(&self, category: &str, message: impl Into<String>, f: F)
    where
        F: FnOnce(&mut Vec<(String, String)>),
    {
        self.with_context(LogLevel::Error, category, message, f);
    }

    /// Get the number of logged entries.
    pub fn entry_count(&self) -> usize {
        self.entries.lock().unwrap().len()
    }

    /// Get the elapsed time since logger creation.
    pub fn elapsed(&self) -> std::time::Duration {
        self.start.elapsed()
    }

    /// Dump all log entries as a plain text string.
    pub fn dump(&self) -> String {
        let entries = self.entries.lock().unwrap();
        let mut output = String::with_capacity(entries.len() * 100);

        for entry in entries.iter() {
            output.push_str(&entry.format());
        }

        drop(entries);
        output
    }

    /// Dump all log entries with ANSI color codes.
    pub fn dump_colored(&self) -> String {
        let entries = self.entries.lock().unwrap();
        let mut output = String::with_capacity(entries.len() * 120);

        for entry in entries.iter() {
            output.push_str(&entry.format_colored());
        }

        drop(entries);
        output
    }

    /// Record an artifact produced during the test (e.g. exported files).
    pub fn record_artifact(&self, name: impl Into<String>, path: impl AsRef<Path>) {
        let entry = ArtifactEntry {
            elapsed_ms: self.elapsed_ms(),
            name: name.into(),
            path: path.as_ref().display().to_string(),
        };
        self.artifacts.lock().unwrap().push(entry);
    }

    /// Returns true if any artifacts were recorded.
    pub fn has_artifacts(&self) -> bool {
        !self.artifacts.lock().unwrap().is_empty()
    }

    /// Dump artifact entries as a plain text string.
    pub fn dump_artifacts(&self) -> String {
        let artifacts = self.artifacts.lock().unwrap();
        let mut output = String::with_capacity(artifacts.len() * 80);
        for entry in artifacts.iter() {
            output.push_str(&entry.format());
        }
        drop(artifacts);
        output
    }

    /// Dump logs and artifacts to a file path.
    pub fn write_dump_to_path(&self, path: impl AsRef<Path>) -> std::io::Result<()> {
        let path = path.as_ref();
        if let Some(parent) = path.parent() {
            if !parent.as_os_str().is_empty() {
                fs::create_dir_all(parent)?;
            }
        }

        let mut output = self.dump();
        if self.has_artifacts() {
            output.push_str("\n=== ARTIFACTS ===\n");
            output.push_str(&self.dump_artifacts());
            output.push_str("=== END ARTIFACTS ===\n");
        }

        fs::write(path, output)
    }

    /// Dump logs and artifacts as JSONL (one JSON object per line).
    ///
    /// This output is intended for machine parsing and deterministic diffs. It:
    /// - includes a schema tag (`pi.test.log.v1` / `pi.test.artifact.v1`)
    /// - includes sequence numbers + ISO-8601 timestamps
    /// - uses elapsed milliseconds for ordering
    ///
    /// Use `dump_jsonl_normalized()` for deterministic placeholder normalization.
    pub fn dump_jsonl(&self) -> String {
        let normalize_root = self.normalize_root.lock().unwrap().clone();
        let test_name = self.test_name.lock().unwrap().clone();
        self.dump_jsonl_internal(true, false, test_name.as_deref(), normalize_root.as_deref())
    }

    /// Dump normalized log records as JSONL (deterministic placeholders).
    pub fn dump_jsonl_normalized(&self) -> String {
        let normalize_root = self.normalize_root.lock().unwrap().clone();
        let test_name = self.test_name.lock().unwrap().clone();
        self.dump_jsonl_internal(true, true, test_name.as_deref(), normalize_root.as_deref())
    }

    /// Dump only artifact index records as JSONL.
    pub fn dump_artifact_index_jsonl(&self) -> String {
        let normalize_root = self.normalize_root.lock().unwrap().clone();
        let test_name = self.test_name.lock().unwrap().clone();
        self.dump_jsonl_internal(
            false,
            false,
            test_name.as_deref(),
            normalize_root.as_deref(),
        )
    }

    /// Dump normalized artifact index records as JSONL.
    pub fn dump_artifact_index_jsonl_normalized(&self) -> String {
        let normalize_root = self.normalize_root.lock().unwrap().clone();
        let test_name = self.test_name.lock().unwrap().clone();
        self.dump_jsonl_internal(false, true, test_name.as_deref(), normalize_root.as_deref())
    }

    fn dump_jsonl_internal(
        &self,
        include_logs: bool,
        normalized: bool,
        test_name: Option<&str>,
        normalize_root: Option<&str>,
    ) -> String {
        let entries = self.entries.lock().unwrap();
        let artifacts = self.artifacts.lock().unwrap();

        let mut out = String::with_capacity((entries.len() + artifacts.len()).saturating_mul(160));
        let ctx = if normalized {
            Some(NormalizationContext::new(normalize_root.map(Path::new)))
        } else {
            None
        };

        let mut seq: usize = 1;
        if include_logs {
            for entry in entries.iter() {
                let record = build_log_record(
                    entry,
                    seq,
                    test_name,
                    ctx.as_ref(),
                    self.start_wall,
                    normalized,
                );
                seq = seq.saturating_add(1);
                let line = serde_json::to_string(&record)
                    .unwrap_or_else(|_| "{\"schema\":\"pi.test.log.v1\"}".to_string());
                out.push_str(&line);
                out.push('\n');
            }
        }

        for artifact in artifacts.iter() {
            let record = build_artifact_record(
                artifact,
                seq,
                test_name,
                ctx.as_ref(),
                self.start_wall,
                normalized,
            );
            seq = seq.saturating_add(1);
            let line = serde_json::to_string(&record)
                .unwrap_or_else(|_| "{\"schema\":\"pi.test.artifact.v1\"}".to_string());
            out.push_str(&line);
            out.push('\n');
        }

        drop(artifacts);
        drop(entries);

        out
    }

    /// Write JSONL dump to a file path.
    pub fn write_jsonl_to_path(&self, path: impl AsRef<Path>) -> std::io::Result<()> {
        write_string_to_path(path.as_ref(), &self.dump_jsonl())
    }

    /// Write normalized JSONL dump to a file path.
    pub fn write_jsonl_normalized_to_path(&self, path: impl AsRef<Path>) -> std::io::Result<()> {
        write_string_to_path(path.as_ref(), &self.dump_jsonl_normalized())
    }

    /// Write artifact index JSONL to a file path.
    pub fn write_artifact_index_jsonl_to_path(
        &self,
        path: impl AsRef<Path>,
    ) -> std::io::Result<()> {
        write_string_to_path(path.as_ref(), &self.dump_artifact_index_jsonl())
    }

    /// Write normalized artifact index JSONL to a file path.
    pub fn write_artifact_index_jsonl_normalized_to_path(
        &self,
        path: impl AsRef<Path>,
    ) -> std::io::Result<()> {
        write_string_to_path(path.as_ref(), &self.dump_artifact_index_jsonl_normalized())
    }

    /// Clear all log entries.
    #[allow(dead_code)]
    pub fn clear(&self) {
        self.entries.lock().unwrap().clear();
        self.artifacts.lock().unwrap().clear();
    }

    /// Get a copy of all entries (useful for assertions).
    pub fn entries(&self) -> Vec<LogEntry> {
        self.entries.lock().unwrap().clone()
    }

    /// Get a copy of all artifacts (useful for assertions).
    pub fn artifacts(&self) -> Vec<ArtifactEntry> {
        self.artifacts.lock().unwrap().clone()
    }

    /// Check if any error-level entries were logged.
    pub fn has_errors(&self) -> bool {
        self.entries
            .lock()
            .unwrap()
            .iter()
            .any(|e| e.level == LogLevel::Error)
    }

    /// Get all error messages.
    pub fn error_messages(&self) -> Vec<String> {
        self.entries
            .lock()
            .unwrap()
            .iter()
            .filter(|e| e.level == LogLevel::Error)
            .map(|e| e.message.clone())
            .collect()
    }
}

fn redact_context(context: &mut [(String, String)]) {
    for (key, value) in context.iter_mut() {
        if is_sensitive_key(key) {
            *value = REDACTED_VALUE.to_string();
        }
    }
}

fn is_sensitive_key(key: &str) -> bool {
    let key = key.trim().to_ascii_lowercase();
    REDACTION_KEYS.iter().any(|needle| key.contains(needle))
}

fn build_log_record(
    entry: &LogEntry,
    seq: usize,
    test_name: Option<&str>,
    ctx: Option<&NormalizationContext>,
    start_wall: SystemTime,
    normalized: bool,
) -> TestLogJsonRecord {
    let (ts, t_ms) = if normalized {
        (PLACEHOLDER_TIMESTAMP.to_string(), 0)
    } else {
        (
            format_timestamp(start_wall, entry.elapsed_ms),
            entry.elapsed_ms,
        )
    };

    let message = ctx.map_or_else(
        || entry.message.clone(),
        |ctx| ctx.normalize_string(&entry.message),
    );
    let category = ctx.map_or_else(
        || entry.category.clone(),
        |ctx| ctx.normalize_string(&entry.category),
    );

    let mut context = BTreeMap::new();
    for (key, value) in &entry.context {
        let value = ctx.map_or_else(|| value.clone(), |ctx| ctx.normalize_string(value));
        context.insert(key.clone(), value);
    }

    TestLogJsonRecord {
        schema: TEST_LOG_SCHEMA,
        record_type: "log",
        test: test_name.map(ToString::to_string),
        seq,
        ts,
        t_ms,
        level: entry.level.as_json_str(),
        category,
        message,
        context,
    }
}

fn build_artifact_record(
    artifact: &ArtifactEntry,
    seq: usize,
    test_name: Option<&str>,
    ctx: Option<&NormalizationContext>,
    start_wall: SystemTime,
    normalized: bool,
) -> TestArtifactJsonRecord {
    let (ts, t_ms) = if normalized {
        (PLACEHOLDER_TIMESTAMP.to_string(), 0)
    } else {
        (
            format_timestamp(start_wall, artifact.elapsed_ms),
            artifact.elapsed_ms,
        )
    };
    let path = ctx.map_or_else(
        || artifact.path.clone(),
        |ctx| ctx.normalize_string(&artifact.path),
    );
    let name = ctx.map_or_else(
        || artifact.name.clone(),
        |ctx| ctx.normalize_string(&artifact.name),
    );
    let (size_bytes, sha256) = artifact_metadata(Path::new(&artifact.path));

    TestArtifactJsonRecord {
        schema: TEST_ARTIFACT_SCHEMA,
        record_type: "artifact",
        test: test_name.map(ToString::to_string),
        seq,
        ts,
        t_ms,
        name,
        path,
        size_bytes,
        sha256,
    }
}

fn format_timestamp(start_wall: SystemTime, elapsed_ms: u64) -> String {
    let ts = start_wall
        .checked_add(Duration::from_millis(elapsed_ms))
        .unwrap_or(start_wall);
    let ts: DateTime<Utc> = ts.into();
    ts.to_rfc3339_opts(SecondsFormat::Millis, true)
}

fn artifact_metadata(path: &Path) -> (Option<u64>, Option<String>) {
    let size_bytes = fs::metadata(path).map(|meta| meta.len()).ok();
    let sha256 = sha256_file(path).ok();
    (size_bytes, sha256)
}

fn sha256_file(path: &Path) -> std::io::Result<String> {
    let mut file = fs::File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buf = [0u8; 8192];
    loop {
        let read = file.read(&mut buf)?;
        if read == 0 {
            break;
        }
        hasher.update(&buf[..read]);
    }
    let digest = hasher.finalize();
    Ok(to_hex(&digest))
}

fn to_hex(bytes: &[u8]) -> String {
    let mut out = String::with_capacity(bytes.len() * 2);
    for byte in bytes {
        let _ = write!(out, "{byte:02x}");
    }
    out
}

fn write_string_to_path(path: &Path, contents: &str) -> std::io::Result<()> {
    if let Some(parent) = path.parent() {
        if !parent.as_os_str().is_empty() {
            fs::create_dir_all(parent)?;
        }
    }
    fs::write(path, contents)
}

// ============================================================================
// JSONL Schema Validation
// ============================================================================

/// Required fields for a `pi.test.log.v1` JSONL record.
const LOG_RECORD_REQUIRED_FIELDS: [&str; 8] = [
    "schema", "type", "seq", "ts", "t_ms", "level", "category", "message",
];

/// Required fields for a `pi.test.artifact.v1` JSONL record.
const ARTIFACT_RECORD_REQUIRED_FIELDS: [&str; 7] =
    ["schema", "type", "seq", "ts", "t_ms", "name", "path"];

/// Validation error for a single JSONL record.
#[derive(Debug, Clone)]
pub struct JsonlValidationError {
    /// 1-based line number in the JSONL output.
    pub line: usize,
    /// The field that failed validation (or `<parse>` / `<root>`).
    pub field: String,
    /// Human-readable description of the problem.
    pub message: String,
}

impl std::fmt::Display for JsonlValidationError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "line {}: field '{}': {}",
            self.line, self.field, self.message
        )
    }
}

/// Validate a single JSONL line against the appropriate schema.
///
/// Returns `Ok(())` if the record has all required fields with correct types,
/// or an error describing the first problem found.
pub fn validate_jsonl_line(line: &str, line_number: usize) -> Result<(), JsonlValidationError> {
    let value: serde_json::Value =
        serde_json::from_str(line).map_err(|err| JsonlValidationError {
            line: line_number,
            field: "<parse>".to_string(),
            message: format!("invalid JSON: {err}"),
        })?;

    let obj = value.as_object().ok_or_else(|| JsonlValidationError {
        line: line_number,
        field: "<root>".to_string(),
        message: "expected JSON object".to_string(),
    })?;

    let schema = obj.get("schema").and_then(|v| v.as_str()).unwrap_or("");
    let required: &[&str] = match schema {
        "pi.test.log.v1" => &LOG_RECORD_REQUIRED_FIELDS,
        "pi.test.artifact.v1" => &ARTIFACT_RECORD_REQUIRED_FIELDS,
        _ => {
            return Err(JsonlValidationError {
                line: line_number,
                field: "schema".to_string(),
                message: format!("unknown schema: {schema:?}"),
            });
        }
    };

    for &field in required {
        if !obj.contains_key(field) {
            return Err(JsonlValidationError {
                line: line_number,
                field: field.to_string(),
                message: "required field missing".to_string(),
            });
        }
    }

    // Type checks for numeric/string fields.
    if let Some(seq) = obj.get("seq") {
        if !seq.is_number() {
            return Err(JsonlValidationError {
                line: line_number,
                field: "seq".to_string(),
                message: format!("expected number, got {seq}"),
            });
        }
    }
    if let Some(ts) = obj.get("ts") {
        if !ts.is_string() {
            return Err(JsonlValidationError {
                line: line_number,
                field: "ts".to_string(),
                message: format!("expected string, got {ts}"),
            });
        }
    }
    if let Some(t_ms) = obj.get("t_ms") {
        if !t_ms.is_number() {
            return Err(JsonlValidationError {
                line: line_number,
                field: "t_ms".to_string(),
                message: format!("expected number, got {t_ms}"),
            });
        }
    }

    Ok(())
}

/// Validate every non-empty line in a JSONL string.
///
/// Returns a (possibly empty) list of validation errors.
pub fn validate_jsonl(content: &str) -> Vec<JsonlValidationError> {
    let mut errors = Vec::new();
    for (i, line) in content.lines().enumerate() {
        let trimmed = line.trim();
        if trimmed.is_empty() {
            continue;
        }
        if let Err(err) = validate_jsonl_line(trimmed, i + 1) {
            errors.push(err);
        }
    }
    errors
}

// ============================================================================
// Deep JSON Redaction
// ============================================================================

/// Recursively redact sensitive keys inside a JSON value at any depth.
///
/// This is useful for sanitizing request/response bodies that may contain
/// API keys, bearer tokens, or credentials nested inside JSON payloads.
pub fn redact_json_value(value: &mut serde_json::Value) {
    match value {
        serde_json::Value::Object(map) => {
            for (key, val) in map.iter_mut() {
                if is_sensitive_key(key) {
                    *val = serde_json::Value::String(REDACTED_VALUE.to_string());
                } else {
                    redact_json_value(val);
                }
            }
        }
        serde_json::Value::Array(arr) => {
            for val in arr.iter_mut() {
                redact_json_value(val);
            }
        }
        _ => {}
    }
}

/// Scan a JSON value and return paths to any sensitive keys whose values
/// are not the redaction placeholder.
///
/// Useful as a test assertion: `assert!(find_unredacted_keys(&val).is_empty())`.
pub fn find_unredacted_keys(value: &serde_json::Value) -> Vec<String> {
    let mut unredacted = Vec::new();
    find_unredacted_keys_inner(value, "", &mut unredacted);
    unredacted
}

fn find_unredacted_keys_inner(value: &serde_json::Value, path: &str, unredacted: &mut Vec<String>) {
    match value {
        serde_json::Value::Object(map) => {
            for (key, val) in map {
                let field_path = if path.is_empty() {
                    key.clone()
                } else {
                    format!("{path}.{key}")
                };
                if is_sensitive_key(key) {
                    if val.as_str() != Some(REDACTED_VALUE) {
                        unredacted.push(field_path);
                    }
                } else {
                    find_unredacted_keys_inner(val, &field_path, unredacted);
                }
            }
        }
        serde_json::Value::Array(arr) => {
            for (i, val) in arr.iter().enumerate() {
                let field_path = format!("{path}[{i}]");
                find_unredacted_keys_inner(val, &field_path, unredacted);
            }
        }
        _ => {}
    }
}

// ============================================================================
// Cost-Budget Telemetry
// ============================================================================

/// Per-provider cost threshold (in US dollars).
#[derive(Debug, Clone)]
pub struct CostThreshold {
    /// Provider name (e.g., `"anthropic"`, `"openai"`).
    pub provider: String,
    /// Soft limit: log a warning when exceeded.
    pub warn_dollars: f64,
    /// Hard limit: fail the test when exceeded.
    pub fail_dollars: f64,
}

/// Outcome of a cost-budget check.
#[derive(Debug, Clone, PartialEq)]
pub enum CostBudgetOutcome {
    /// Cost is within budget.
    Ok,
    /// Cost exceeded the warning threshold but not the failure threshold.
    Warn {
        provider: String,
        cost: f64,
        threshold: f64,
    },
    /// Cost exceeded the hard failure threshold.
    Fail {
        provider: String,
        cost: f64,
        threshold: f64,
    },
}

impl std::fmt::Display for CostBudgetOutcome {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Ok => write!(f, "cost within budget"),
            Self::Warn {
                provider,
                cost,
                threshold,
            } => write!(
                f,
                "WARNING: {provider} cost ${cost:.6} exceeds warn threshold ${threshold:.6}"
            ),
            Self::Fail {
                provider,
                cost,
                threshold,
            } => write!(
                f,
                "FAIL: {provider} cost ${cost:.6} exceeds fail threshold ${threshold:.6}"
            ),
        }
    }
}

/// Default per-call cost thresholds for live E2E tests.
///
/// These are conservative: a single "say hello" prompt with `max_tokens=64`
/// should cost well under $0.01.
#[must_use]
pub fn default_cost_thresholds() -> Vec<CostThreshold> {
    vec![
        CostThreshold {
            provider: "anthropic".to_string(),
            warn_dollars: 0.05,
            fail_dollars: 0.25,
        },
        CostThreshold {
            provider: "openai".to_string(),
            warn_dollars: 0.05,
            fail_dollars: 0.25,
        },
        CostThreshold {
            provider: "google".to_string(),
            warn_dollars: 0.05,
            fail_dollars: 0.25,
        },
        CostThreshold {
            provider: "openrouter".to_string(),
            warn_dollars: 0.10,
            fail_dollars: 0.50,
        },
        CostThreshold {
            provider: "xai".to_string(),
            warn_dollars: 0.05,
            fail_dollars: 0.25,
        },
        CostThreshold {
            provider: "deepseek".to_string(),
            warn_dollars: 0.05,
            fail_dollars: 0.25,
        },
    ]
}

/// Check a provider run's total cost against budget thresholds.
///
/// Returns [`CostBudgetOutcome::Ok`] if `total_cost` is under both limits,
/// [`CostBudgetOutcome::Warn`] if it exceeds the soft limit, or
/// [`CostBudgetOutcome::Fail`] if it exceeds the hard limit.
///
/// If no threshold is configured for the given provider, returns `Ok`.
#[must_use]
pub fn check_cost_budget(
    provider: &str,
    total_cost: f64,
    thresholds: &[CostThreshold],
) -> CostBudgetOutcome {
    let Some(threshold) = thresholds.iter().find(|t| t.provider == provider) else {
        return CostBudgetOutcome::Ok;
    };
    if total_cost >= threshold.fail_dollars {
        CostBudgetOutcome::Fail {
            provider: provider.to_string(),
            cost: total_cost,
            threshold: threshold.fail_dollars,
        }
    } else if total_cost >= threshold.warn_dollars {
        CostBudgetOutcome::Warn {
            provider: provider.to_string(),
            cost: total_cost,
            threshold: threshold.warn_dollars,
        }
    } else {
        CostBudgetOutcome::Ok
    }
}

/// Macro for logging with automatic context capture.
///
/// # Example
///
/// ```ignore
/// log_ctx!(logger, Info, "action", "Processing file",
///     "path" => file_path.display(),
///     "size" => file_size
/// );
/// ```
#[macro_export]
macro_rules! log_ctx {
    ($logger:expr, $level:ident, $category:expr, $message:expr, $($key:expr => $value:expr),* $(,)?) => {
        $logger.with_context(
            $crate::common::logging::LogLevel::$level,
            $category,
            $message,
            |ctx| {
                $(
                    ctx.push(($key.to_string(), format!("{}", $value)));
                )*
            }
        );
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_basic_logging() {
        let logger = TestLogger::new();

        logger.info("setup", "Test started");
        logger.debug("details", "Extra info");
        logger.warn("check", "Something suspicious");
        logger.error("fail", "Something broke");

        assert_eq!(logger.entry_count(), 4);
        assert!(logger.has_errors());

        let dump = logger.dump();
        assert!(dump.contains("Test started"));
        assert!(dump.contains("Something broke"));
    }

    #[test]
    fn test_context_logging() {
        let logger = TestLogger::new();

        logger.info_ctx("action", "Processing", |ctx| {
            ctx.push(("file".into(), "test.txt".into()));
            ctx.push(("size".into(), "1024".into()));
        });

        let dump = logger.dump();
        assert!(dump.contains("Processing"));
        assert!(dump.contains("file = test.txt"));
        assert!(dump.contains("size = 1024"));
    }

    #[test]
    fn test_min_level_filtering() {
        let logger = TestLogger::with_min_level(LogLevel::Warn);

        logger.debug("test", "Debug message");
        logger.info("test", "Info message");
        logger.warn("test", "Warn message");
        logger.error("test", "Error message");

        assert_eq!(logger.entry_count(), 2);

        let dump = logger.dump();
        assert!(!dump.contains("Debug message"));
        assert!(!dump.contains("Info message"));
        assert!(dump.contains("Warn message"));
        assert!(dump.contains("Error message"));
    }

    #[test]
    fn test_colored_output() {
        let logger = TestLogger::new();
        logger.info("test", "Colored message");

        let colored = logger.dump_colored();
        assert!(colored.contains("\x1b[")); // Contains ANSI codes
    }

    #[test]
    fn test_error_messages() {
        let logger = TestLogger::new();

        logger.error("fail", "First error");
        logger.info("ok", "Some info");
        logger.error("fail", "Second error");

        let errors = logger.error_messages();
        assert_eq!(errors.len(), 2);
        assert_eq!(errors[0], "First error");
        assert_eq!(errors[1], "Second error");
    }

    #[test]
    fn test_redaction() {
        let logger = TestLogger::new();
        logger.info_ctx("auth", "Headers", |ctx| {
            ctx.push(("Authorization".into(), "Bearer secret".into()));
            ctx.push(("path".into(), "/tmp/file.txt".into()));
        });

        let dump = logger.dump();
        assert!(dump.contains("Authorization = [REDACTED]"));
        assert!(dump.contains("path = /tmp/file.txt"));
    }

    #[test]
    fn test_artifact_logging() {
        let logger = TestLogger::new();
        logger.record_artifact("trace", "/tmp/trace.json");

        let artifacts = logger.dump_artifacts();
        assert!(artifacts.contains("trace"));
        assert!(artifacts.contains("/tmp/trace.json"));
    }

    #[test]
    fn jsonl_dump_includes_logs_and_artifacts_with_normalization() {
        let logger = TestLogger::new();
        logger.set_normalization_root("/tmp/my-root");

        logger.info_ctx("harness", "created", |ctx| {
            ctx.push(("path".into(), "/tmp/my-root/work.txt".into()));
        });
        logger.record_artifact("log", "/tmp/my-root/log.txt");

        let jsonl = logger.dump_jsonl_normalized();
        let mut lines = jsonl.lines();
        let first: serde_json::Value = serde_json::from_str(lines.next().unwrap()).unwrap();
        let second: serde_json::Value = serde_json::from_str(lines.next().unwrap()).unwrap();

        assert_eq!(first["schema"], TEST_LOG_SCHEMA);
        assert_eq!(second["schema"], TEST_ARTIFACT_SCHEMA);
        assert_eq!(first["type"], "log");
        assert_eq!(second["type"], "artifact");
        assert_eq!(first["seq"], 1);
        assert_eq!(second["seq"], 2);
        assert_eq!(first["ts"], PLACEHOLDER_TIMESTAMP);
        assert_eq!(second["ts"], PLACEHOLDER_TIMESTAMP);
        assert!(jsonl.contains(PLACEHOLDER_TEST_ROOT));
    }

    // ====================================================================
    // JSONL Schema Validation
    // ====================================================================

    #[test]
    fn validate_jsonl_valid_log_record() {
        let record = r#"{"schema":"pi.test.log.v1","type":"log","seq":1,"ts":"2026-01-01T00:00:00.000Z","t_ms":0,"level":"info","category":"setup","message":"hello"}"#;
        assert!(validate_jsonl_line(record, 1).is_ok());
    }

    #[test]
    fn validate_jsonl_valid_artifact_record() {
        let record = r#"{"schema":"pi.test.artifact.v1","type":"artifact","seq":2,"ts":"2026-01-01T00:00:00.000Z","t_ms":0,"name":"trace","path":"/tmp/trace.json"}"#;
        assert!(validate_jsonl_line(record, 1).is_ok());
    }

    #[test]
    fn validate_jsonl_rejects_unknown_schema() {
        let record = r#"{"schema":"pi.test.unknown.v2","type":"log","seq":1,"ts":"x","t_ms":0}"#;
        let err = validate_jsonl_line(record, 1).unwrap_err();
        assert_eq!(err.field, "schema");
        assert!(err.message.contains("unknown schema"));
    }

    #[test]
    fn validate_jsonl_rejects_missing_required_field() {
        // Missing "message" field for a log record.
        let record = r#"{"schema":"pi.test.log.v1","type":"log","seq":1,"ts":"x","t_ms":0,"level":"info","category":"setup"}"#;
        let err = validate_jsonl_line(record, 1).unwrap_err();
        assert_eq!(err.field, "message");
        assert!(err.message.contains("required field missing"));
    }

    #[test]
    fn validate_jsonl_rejects_wrong_type_for_seq() {
        let record = r#"{"schema":"pi.test.log.v1","type":"log","seq":"not-a-number","ts":"x","t_ms":0,"level":"info","category":"setup","message":"hi"}"#;
        let err = validate_jsonl_line(record, 1).unwrap_err();
        assert_eq!(err.field, "seq");
        assert!(err.message.contains("expected number"));
    }

    #[test]
    fn validate_jsonl_rejects_invalid_json() {
        let err = validate_jsonl_line("{broken", 1).unwrap_err();
        assert_eq!(err.field, "<parse>");
    }

    #[test]
    fn validate_jsonl_rejects_non_object() {
        let err = validate_jsonl_line("[1,2,3]", 1).unwrap_err();
        assert_eq!(err.field, "<root>");
    }

    #[test]
    fn validate_jsonl_full_output_from_logger() {
        let logger = TestLogger::new();
        logger.info("setup", "test started");
        logger.warn("check", "something suspicious");
        logger.record_artifact("trace", "/tmp/trace.json");

        let jsonl = logger.dump_jsonl();
        let errors = validate_jsonl(&jsonl);
        assert!(
            errors.is_empty(),
            "logger output failed validation: {errors:?}"
        );
    }

    #[test]
    fn validate_jsonl_normalized_output_from_logger() {
        let logger = TestLogger::new();
        logger.set_normalization_root("/tmp/norm-root");
        logger.info("setup", "testing in /tmp/norm-root/workspace");
        logger.record_artifact("log", "/tmp/norm-root/run.log");

        let jsonl = logger.dump_jsonl_normalized();
        let errors = validate_jsonl(&jsonl);
        assert!(
            errors.is_empty(),
            "normalized logger output failed validation: {errors:?}"
        );
    }

    #[test]
    fn validate_jsonl_batch_collects_all_errors() {
        let bad_content = "{broken}\n[1,2]\n{\"schema\":\"pi.test.log.v1\",\"type\":\"log\",\"seq\":1,\"ts\":\"x\",\"t_ms\":0,\"level\":\"info\",\"category\":\"c\",\"message\":\"m\"}\n";
        let errors = validate_jsonl(bad_content);
        // First two lines are bad, third is valid.
        assert_eq!(errors.len(), 2);
        assert_eq!(errors[0].line, 1);
        assert_eq!(errors[1].line, 2);
    }

    // ====================================================================
    // Deep JSON Redaction
    // ====================================================================

    #[test]
    fn redact_json_value_flat_object() {
        let mut val: serde_json::Value = serde_json::json!({
            "api_key": "sk-abc123",
            "model": "gpt-4",
            "authorization": "Bearer tok"
        });
        redact_json_value(&mut val);

        assert_eq!(val["api_key"], REDACTED_VALUE);
        assert_eq!(val["authorization"], REDACTED_VALUE);
        assert_eq!(val["model"], "gpt-4");
    }

    #[test]
    fn redact_json_value_nested_object() {
        let mut val: serde_json::Value = serde_json::json!({
            "request": {
                "headers": {
                    "Authorization": "Bearer secret-value",
                    "Content-Type": "application/json"
                },
                "body": {
                    "config": {
                        "api_key": "sk-live-nested-key",
                        "temperature": 0.7
                    }
                }
            }
        });
        redact_json_value(&mut val);

        assert_eq!(val["request"]["headers"]["Authorization"], REDACTED_VALUE);
        assert_eq!(
            val["request"]["headers"]["Content-Type"],
            "application/json"
        );
        assert_eq!(val["request"]["body"]["config"]["api_key"], REDACTED_VALUE);
        assert_eq!(val["request"]["body"]["config"]["temperature"], 0.7);
    }

    #[test]
    fn redact_json_value_array_with_nested_secrets() {
        let mut val: serde_json::Value = serde_json::json!([
            {"provider": "openai", "api_key": "sk-111"},
            {"provider": "anthropic", "api_key": "sk-222"},
            {"provider": "google", "token": "tok-333"}
        ]);
        redact_json_value(&mut val);

        assert_eq!(val[0]["api_key"], REDACTED_VALUE);
        assert_eq!(val[1]["api_key"], REDACTED_VALUE);
        assert_eq!(val[2]["token"], REDACTED_VALUE);
        assert_eq!(val[0]["provider"], "openai");
    }

    #[test]
    fn redact_json_value_all_sensitive_key_patterns() {
        let mut val: serde_json::Value = serde_json::json!({
            "api_key": "v1",
            "api-key": "v2",
            "authorization": "v3",
            "bearer": "v4",
            "cookie": "v5",
            "credential": "v6",
            "password": "v7",
            "private_key": "v8",
            "secret": "v9",
            "token": "v10"
        });
        redact_json_value(&mut val);

        for key in &REDACTION_KEYS {
            assert_eq!(
                val[key].as_str().unwrap(),
                REDACTED_VALUE,
                "key '{key}' was not redacted"
            );
        }
    }

    #[test]
    fn find_unredacted_keys_detects_leaks() {
        let val: serde_json::Value = serde_json::json!({
            "request": {
                "headers": {
                    "Authorization": "Bearer sk-live-leaked",
                    "Host": "api.openai.com"
                },
                "body": {
                    "api_key": "sk-also-leaked"
                }
            }
        });
        let leaks = find_unredacted_keys(&val);
        assert_eq!(leaks.len(), 2);
        assert!(leaks.iter().any(|p| p.contains("Authorization")));
        assert!(leaks.iter().any(|p| p.contains("api_key")));
    }

    #[test]
    fn find_unredacted_keys_empty_when_redacted() {
        let val: serde_json::Value = serde_json::json!({
            "api_key": REDACTED_VALUE,
            "authorization": REDACTED_VALUE,
            "model": "claude-3.5-sonnet"
        });
        assert!(find_unredacted_keys(&val).is_empty());
    }

    #[test]
    fn find_unredacted_keys_in_arrays() {
        let val: serde_json::Value = serde_json::json!({
            "items": [
                {"name": "a", "secret": "exposed"},
                {"name": "b", "secret": REDACTED_VALUE}
            ]
        });
        let leaks = find_unredacted_keys(&val);
        assert_eq!(leaks.len(), 1);
        assert!(leaks[0].contains("[0]"));
    }

    // ====================================================================
    // Cost-Budget Telemetry
    // ====================================================================

    #[test]
    fn cost_budget_ok_when_under_threshold() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("anthropic", 0.001, &thresholds);
        assert_eq!(outcome, CostBudgetOutcome::Ok);
    }

    #[test]
    fn cost_budget_warn_when_above_soft_limit() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("anthropic", 0.06, &thresholds);
        assert!(
            matches!(outcome, CostBudgetOutcome::Warn { .. }),
            "expected Warn, got {outcome:?}"
        );
    }

    #[test]
    fn cost_budget_fail_when_above_hard_limit() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("anthropic", 0.30, &thresholds);
        assert!(
            matches!(outcome, CostBudgetOutcome::Fail { .. }),
            "expected Fail, got {outcome:?}"
        );
    }

    #[test]
    fn cost_budget_ok_for_unknown_provider() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("some-unknown-provider", 999.0, &thresholds);
        assert_eq!(outcome, CostBudgetOutcome::Ok);
    }

    #[test]
    fn cost_budget_openrouter_has_higher_threshold() {
        let thresholds = default_cost_thresholds();
        // $0.08 is under openrouter's warn ($0.10) but above anthropic's ($0.05).
        let openrouter = check_cost_budget("openrouter", 0.08, &thresholds);
        let anthropic = check_cost_budget("anthropic", 0.08, &thresholds);
        assert_eq!(openrouter, CostBudgetOutcome::Ok);
        assert!(matches!(anthropic, CostBudgetOutcome::Warn { .. }));
    }

    #[test]
    fn cost_budget_exactly_at_warn_triggers_warn() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("openai", 0.05, &thresholds);
        assert!(
            matches!(outcome, CostBudgetOutcome::Warn { .. }),
            "expected Warn at exact threshold, got {outcome:?}"
        );
    }

    #[test]
    fn cost_budget_exactly_at_fail_triggers_fail() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("openai", 0.25, &thresholds);
        assert!(
            matches!(outcome, CostBudgetOutcome::Fail { .. }),
            "expected Fail at exact threshold, got {outcome:?}"
        );
    }

    #[test]
    fn cost_budget_zero_cost_ok() {
        let thresholds = default_cost_thresholds();
        let outcome = check_cost_budget("anthropic", 0.0, &thresholds);
        assert_eq!(outcome, CostBudgetOutcome::Ok);
    }

    #[test]
    fn cost_budget_display_format() {
        assert_eq!(CostBudgetOutcome::Ok.to_string(), "cost within budget");

        let warn = CostBudgetOutcome::Warn {
            provider: "openai".to_string(),
            cost: 0.06,
            threshold: 0.05,
        };
        let warn_str = warn.to_string();
        assert!(warn_str.contains("WARNING"));
        assert!(warn_str.contains("openai"));

        let fail = CostBudgetOutcome::Fail {
            provider: "anthropic".to_string(),
            cost: 0.30,
            threshold: 0.25,
        };
        let fail_str = fail.to_string();
        assert!(fail_str.contains("FAIL"));
        assert!(fail_str.contains("anthropic"));
    }

    #[test]
    fn cost_budget_custom_thresholds() {
        let custom = vec![CostThreshold {
            provider: "custom".to_string(),
            warn_dollars: 0.001,
            fail_dollars: 0.002,
        }];
        assert_eq!(
            check_cost_budget("custom", 0.0005, &custom),
            CostBudgetOutcome::Ok
        );
        assert!(matches!(
            check_cost_budget("custom", 0.0015, &custom),
            CostBudgetOutcome::Warn { .. }
        ));
        assert!(matches!(
            check_cost_budget("custom", 0.003, &custom),
            CostBudgetOutcome::Fail { .. }
        ));
    }

    #[test]
    fn default_cost_thresholds_covers_all_live_providers() {
        let thresholds = default_cost_thresholds();
        let expected = [
            "anthropic",
            "openai",
            "google",
            "openrouter",
            "xai",
            "deepseek",
        ];
        for provider in &expected {
            assert!(
                thresholds.iter().any(|t| t.provider == *provider),
                "missing threshold for provider '{provider}'"
            );
        }
    }

    // ====================================================================
    // Redaction + Context (existing context-level) additional coverage
    // ====================================================================

    #[test]
    fn redaction_case_insensitive_key_matching() {
        let logger = TestLogger::new();
        logger.info_ctx("auth", "Case test", |ctx| {
            ctx.push(("API_KEY".into(), "sk-123".into()));
            ctx.push(("Api-Key".into(), "sk-456".into()));
            ctx.push(("AUTHORIZATION".into(), "Bearer tok".into()));
            ctx.push(("Token".into(), "abc".into()));
        });
        let dump = logger.dump();
        assert!(dump.contains("API_KEY = [REDACTED]"));
        assert!(dump.contains("Api-Key = [REDACTED]"));
        assert!(dump.contains("AUTHORIZATION = [REDACTED]"));
        assert!(dump.contains("Token = [REDACTED]"));
    }

    #[test]
    fn redaction_partial_key_match() {
        // Keys that *contain* a sensitive pattern should also redact.
        let logger = TestLogger::new();
        logger.info_ctx("auth", "Partial match", |ctx| {
            ctx.push(("x-api-key-header".into(), "value".into()));
            ctx.push(("my_secret_value".into(), "value".into()));
            ctx.push(("safe_key".into(), "visible".into()));
        });
        let dump = logger.dump();
        assert!(dump.contains("x-api-key-header = [REDACTED]"));
        assert!(dump.contains("my_secret_value = [REDACTED]"));
        assert!(dump.contains("safe_key = visible"));
    }
}
